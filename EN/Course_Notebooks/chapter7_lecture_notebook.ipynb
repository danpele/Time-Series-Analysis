{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/danpele/Time-Series-Analysis/blob/main/EN/Course_Notebooks/chapter7_lecture_notebook.ipynb)\n\n---"
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": "# Chapter 7: Cointegration and VECM\n\n**Course:** Time Series Analysis and Forecasting  \n**Program:** Bachelor program, Faculty of Cybernetics, Statistics and Economic Informatics, Bucharest University of Economic Studies, Romania  \n**Academic Year:** 2025-2026\n\n---\n\n## Learning Objectives\n\nBy the end of this notebook, you will be able to:\n1. Understand the concept of cointegration and its economic interpretation\n2. Identify and avoid spurious regression problems\n3. Apply Engle-Granger and Johansen cointegration tests\n4. Estimate and interpret Vector Error Correction Models (VECM)\n5. Analyze adjustment coefficients and weak exogeneity\n6. Apply cointegration analysis to real financial data"
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Statistical tests and models\n",
    "from statsmodels.tsa.stattools import adfuller, coint\n",
    "from statsmodels.tsa.vector_ar.vecm import coint_johansen, VECM\n",
    "from statsmodels.tsa.api import VAR\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from scipy import stats\n",
    "\n",
    "# For fetching real data\n",
    "try:\n",
    "    import pandas_datareader.data as web\n",
    "    HAS_PDR = True\n",
    "except ImportError:\n",
    "    HAS_PDR = False\n",
    "    print(\"Note: pandas_datareader not installed. Install with: pip install pandas-datareader\")\n",
    "\n",
    "# Plotting style - clean, professional, transparent\n",
    "plt.rcParams['figure.figsize'] = (12, 5)\n",
    "plt.rcParams['font.size'] = 11\n",
    "plt.rcParams['axes.facecolor'] = 'none'\n",
    "plt.rcParams['figure.facecolor'] = 'none'\n",
    "plt.rcParams['savefig.facecolor'] = 'none'\n",
    "plt.rcParams['savefig.transparent'] = True\n",
    "plt.rcParams['axes.grid'] = False\n",
    "plt.rcParams['axes.spines.top'] = False\n",
    "plt.rcParams['axes.spines.right'] = False\n",
    "plt.rcParams['legend.frameon'] = False\n",
    "plt.rcParams['legend.loc'] = 'upper center'\n",
    "\n",
    "# Colors (IDA color scheme)\n",
    "COLORS = {\n",
    "    'blue': '#1A3A6E',\n",
    "    'red': '#DC3545',\n",
    "    'green': '#2E7D32',\n",
    "    'orange': '#E67E22',\n",
    "    'gray': '#666666'\n",
    "}\n",
    "\n",
    "print(\"All libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## 1. The Problem: Non-Stationary Time Series\n",
    "\n",
    "Many economic and financial variables are **non-stationary** (I(1)):\n",
    "- Stock prices, GDP, consumption, investment\n",
    "- Exchange rates, interest rates\n",
    "- Price indices, wages\n",
    "\n",
    "**The challenge:**\n",
    "- Standard regression with I(1) variables leads to **spurious results**\n",
    "- Simply differencing loses **long-run information**\n",
    "\n",
    "**The solution: Cointegration**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## 2. Spurious Regression Problem\n",
    "\n",
    "**Granger & Newbold (1974):** Regressing one random walk on another independent random walk gives:\n",
    "- High R² (often > 0.9)\n",
    "- Significant t-statistics\n",
    "- Very low Durbin-Watson statistic (DW ≈ 0)\n",
    "\n",
    "**Rule of thumb:** If R² > DW, suspect spurious regression!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate spurious regression\n",
    "np.random.seed(42)\n",
    "n = 200\n",
    "\n",
    "# Two INDEPENDENT random walks\n",
    "y1 = np.cumsum(np.random.randn(n))  # Random walk 1\n",
    "y2 = np.cumsum(np.random.randn(n))  # Random walk 2 (independent!)\n",
    "\n",
    "# Run OLS regression\n",
    "X = add_constant(y2)\n",
    "model = OLS(y1, X).fit()\n",
    "\n",
    "# Calculate Durbin-Watson\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "dw = durbin_watson(model.resid)\n",
    "\n",
    "print(\"Spurious Regression Example\")\n",
    "print(\"=\"*60)\n",
    "print(f\"R-squared: {model.rsquared:.4f}\")\n",
    "print(f\"Coefficient on Y2: {model.params[1]:.4f} (t-stat: {model.tvalues[1]:.2f})\")\n",
    "print(f\"P-value: {model.pvalues[1]:.6f}\")\n",
    "print(f\"Durbin-Watson: {dw:.4f}\")\n",
    "print()\n",
    "print(f\"R² > DW? {model.rsquared:.4f} > {dw:.4f} = {model.rsquared > dw}\")\n",
    "print(\"\\n⚠️ WARNING: These series are COMPLETELY INDEPENDENT!\")\n",
    "print(\"   High R² and significant coefficient are SPURIOUS!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize spurious regression\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Plot both series\n",
    "axes[0].plot(y1, color=COLORS['blue'], label='Y1 (Random Walk)', linewidth=1)\n",
    "axes[0].plot(y2, color=COLORS['orange'], label='Y2 (Random Walk)', linewidth=1)\n",
    "axes[0].set_title('Two Independent Random Walks', fontweight='bold')\n",
    "axes[0].set_xlabel('Time')\n",
    "axes[0].legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=2)\n",
    "\n",
    "# Scatter plot\n",
    "axes[1].scatter(y2, y1, alpha=0.5, s=20, color=COLORS['blue'])\n",
    "axes[1].plot(y2, model.fittedvalues, color=COLORS['red'], linewidth=2, label=f'OLS fit (R²={model.rsquared:.3f})')\n",
    "axes[1].set_xlabel('Y2')\n",
    "axes[1].set_ylabel('Y1')\n",
    "axes[1].set_title('Spurious Regression', fontweight='bold', color=COLORS['red'])\n",
    "axes[1].legend(loc='upper center', bbox_to_anchor=(0.5, -0.15))\n",
    "\n",
    "# Residuals (clearly non-stationary!)\n",
    "axes[2].plot(model.resid, color=COLORS['green'], linewidth=1)\n",
    "axes[2].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "axes[2].set_title('Residuals (Non-Stationary!)', fontweight='bold', color=COLORS['red'])\n",
    "axes[2].set_xlabel('Time')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## 3. Cointegration: The Key Concept\n",
    "\n",
    "**Definition (Engle & Granger, 1987):**\n",
    "\n",
    "Variables $Y_{1t}, Y_{2t}, \\ldots, Y_{kt}$ are **cointegrated** if:\n",
    "1. All variables are I(1) (non-stationary with unit root)\n",
    "2. There exists a linear combination $\\beta_1 Y_{1t} + \\beta_2 Y_{2t} + \\cdots + \\beta_k Y_{kt}$ that is I(0) (stationary)\n",
    "\n",
    "**Intuition:** The variables share a **common stochastic trend** and move together in the long run.\n",
    "\n",
    "**Economic interpretation:** Cointegration represents a **long-run equilibrium relationship**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cointegrated series\n",
    "np.random.seed(123)\n",
    "n = 200\n",
    "\n",
    "# Common stochastic trend (random walk)\n",
    "common_trend = np.cumsum(np.random.randn(n))\n",
    "\n",
    "# Two cointegrated series sharing the common trend\n",
    "beta = 0.8  # Cointegrating coefficient\n",
    "y1 = common_trend + np.random.randn(n) * 0.5\n",
    "y2 = beta * common_trend + np.random.randn(n) * 0.5\n",
    "\n",
    "# The spread (cointegrating relationship) should be stationary\n",
    "spread = y1 - (1/beta) * y2\n",
    "\n",
    "print(\"Cointegrated Series Example\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Y1 and Y2 share a common trend with β ≈ {1/beta:.2f}\")\n",
    "print(f\"\\nSpread (Y1 - {1/beta:.2f}*Y2) should be stationary:\")\n",
    "\n",
    "# ADF test on spread\n",
    "adf_spread = adfuller(spread)\n",
    "print(f\"  ADF statistic: {adf_spread[0]:.4f}\")\n",
    "print(f\"  P-value: {adf_spread[1]:.4f}\")\n",
    "print(f\"  Stationary? {'Yes ✓' if adf_spread[1] < 0.05 else 'No'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize cointegrated series\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Both series\n",
    "axes[0].plot(y1, color=COLORS['blue'], label='Y1', linewidth=1)\n",
    "axes[0].plot(y2 * (1/beta), color=COLORS['orange'], label=f'Y2 × {1/beta:.1f}', linewidth=1, alpha=0.7)\n",
    "axes[0].set_title('Cointegrated Series (Move Together)', fontweight='bold')\n",
    "axes[0].set_xlabel('Time')\n",
    "axes[0].legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=2)\n",
    "\n",
    "# Scatter plot\n",
    "axes[1].scatter(y2, y1, alpha=0.5, s=20, color=COLORS['blue'])\n",
    "z = np.polyfit(y2, y1, 1)\n",
    "axes[1].plot(y2, np.poly1d(z)(y2), color=COLORS['red'], linewidth=2, label=f'Coint. relation')\n",
    "axes[1].set_xlabel('Y2')\n",
    "axes[1].set_ylabel('Y1')\n",
    "axes[1].set_title('Long-Run Equilibrium', fontweight='bold')\n",
    "axes[1].legend(loc='upper center', bbox_to_anchor=(0.5, -0.15))\n",
    "\n",
    "# Spread (stationary!)\n",
    "axes[2].plot(spread, color=COLORS['green'], linewidth=1)\n",
    "axes[2].axhline(y=np.mean(spread), color='red', linestyle='--', alpha=0.7)\n",
    "axes[2].fill_between(range(n), np.mean(spread) - 2*np.std(spread), \n",
    "                     np.mean(spread) + 2*np.std(spread), alpha=0.2, color='green')\n",
    "axes[2].set_title('Spread: Stationary I(0)', fontweight='bold', color=COLORS['green'])\n",
    "axes[2].set_xlabel('Time')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## 4. Engle-Granger Two-Step Method\n",
    "\n",
    "**Step 1:** Estimate the cointegrating regression\n",
    "$$Y_t = \\alpha + \\beta X_t + e_t$$\n",
    "\n",
    "**Step 2:** Test if residuals $\\hat{e}_t$ are stationary using ADF test\n",
    "- $H_0$: Residuals have unit root (no cointegration)\n",
    "- $H_1$: Residuals are stationary (cointegration exists)\n",
    "\n",
    "**Important:** Use Engle-Granger critical values, not standard ADF critical values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Engle-Granger test using statsmodels\n",
    "# Create data array for testing\n",
    "data_coint = pd.DataFrame({'Y1': y1, 'Y2': y2})\n",
    "\n",
    "print(\"Engle-Granger Cointegration Test\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Using statsmodels coint function\n",
    "coint_stat, pvalue, crit_values = coint(y1, y2)\n",
    "\n",
    "print(f\"\\nTest Statistic: {coint_stat:.4f}\")\n",
    "print(f\"P-value: {pvalue:.4f}\")\n",
    "print(f\"\\nCritical Values:\")\n",
    "print(f\"  1%: {crit_values[0]:.4f}\")\n",
    "print(f\"  5%: {crit_values[1]:.4f}\")\n",
    "print(f\"  10%: {crit_values[2]:.4f}\")\n",
    "print(f\"\\nConclusion: {'Reject H0 - Cointegrated!' if pvalue < 0.05 else 'Cannot reject H0 - Not cointegrated'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual Engle-Granger procedure\n",
    "print(\"Manual Engle-Granger Procedure\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Step 1: Estimate cointegrating regression\n",
    "X_coint = add_constant(y2)\n",
    "coint_reg = OLS(y1, X_coint).fit()\n",
    "\n",
    "print(\"\\nStep 1: Cointegrating Regression\")\n",
    "print(f\"  Y1 = {coint_reg.params[0]:.4f} + {coint_reg.params[1]:.4f} × Y2\")\n",
    "print(f\"  R-squared: {coint_reg.rsquared:.4f}\")\n",
    "\n",
    "# Step 2: Test residuals for stationarity\n",
    "residuals = coint_reg.resid\n",
    "adf_result = adfuller(residuals, regression='c')\n",
    "\n",
    "print(\"\\nStep 2: ADF Test on Residuals\")\n",
    "print(f\"  ADF Statistic: {adf_result[0]:.4f}\")\n",
    "print(f\"  P-value: {adf_result[1]:.4f}\")\n",
    "print(f\"  Critical Values:\")\n",
    "for key, value in adf_result[4].items():\n",
    "    print(f\"    {key}: {value:.4f}\")\n",
    "\n",
    "# Note about critical values\n",
    "print(\"\\n⚠️ Note: For cointegration tests, use Engle-Granger critical values\")\n",
    "print(\"   (more negative than standard ADF because residuals are estimated)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## 5. Johansen Cointegration Test\n",
    "\n",
    "**Advantages over Engle-Granger:**\n",
    "- Tests for **multiple** cointegrating relationships\n",
    "- Maximum likelihood estimation (more efficient)\n",
    "- No need to choose dependent variable\n",
    "\n",
    "**Key concept:** Test the rank of matrix $\\Pi$ in the VECM:\n",
    "- rank($\\Pi$) = 0: No cointegration\n",
    "- 0 < rank($\\Pi$) = r < k: r cointegrating vectors\n",
    "- rank($\\Pi$) = k: All variables are I(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Johansen cointegration test\n",
    "print(\"Johansen Cointegration Test\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Prepare data\n",
    "data_johansen = np.column_stack([y1, y2])\n",
    "\n",
    "# Run Johansen test\n",
    "johansen_result = coint_johansen(data_johansen, det_order=0, k_ar_diff=1)\n",
    "\n",
    "print(\"\\nTrace Test:\")\n",
    "print(f\"{'Rank':>6} {'Trace Stat':>12} {'Crit 90%':>10} {'Crit 95%':>10} {'Crit 99%':>10}\")\n",
    "print(\"-\"*55)\n",
    "for i in range(2):\n",
    "    sig = \" **\" if johansen_result.lr1[i] > johansen_result.cvt[i, 1] else \"\"\n",
    "    print(f\"r = {i:>2} {johansen_result.lr1[i]:>12.2f} {johansen_result.cvt[i, 0]:>10.2f} \"\n",
    "          f\"{johansen_result.cvt[i, 1]:>10.2f} {johansen_result.cvt[i, 2]:>10.2f}{sig}\")\n",
    "\n",
    "print(\"\\nMax Eigenvalue Test:\")\n",
    "print(f\"{'Rank':>6} {'Max Eig':>12} {'Crit 90%':>10} {'Crit 95%':>10} {'Crit 99%':>10}\")\n",
    "print(\"-\"*55)\n",
    "for i in range(2):\n",
    "    sig = \" **\" if johansen_result.lr2[i] > johansen_result.cvm[i, 1] else \"\"\n",
    "    print(f\"r = {i:>2} {johansen_result.lr2[i]:>12.2f} {johansen_result.cvm[i, 0]:>10.2f} \"\n",
    "          f\"{johansen_result.cvm[i, 1]:>10.2f} {johansen_result.cvm[i, 2]:>10.2f}{sig}\")\n",
    "\n",
    "print(\"\\nEigenvalues:\", johansen_result.eig.round(4))\n",
    "print(\"\\nCointegrating vector (β):\")\n",
    "print(johansen_result.evec[:, 0].round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## 6. Vector Error Correction Model (VECM)\n",
    "\n",
    "When variables are cointegrated, we use VECM instead of VAR in differences:\n",
    "\n",
    "$$\\Delta \\mathbf{Y}_t = \\mathbf{c} + \\boldsymbol{\\alpha}\\boldsymbol{\\beta}'\\mathbf{Y}_{t-1} + \\sum_{j=1}^{p-1} \\boldsymbol{\\Gamma}_j \\Delta \\mathbf{Y}_{t-j} + \\boldsymbol{\\varepsilon}_t$$\n",
    "\n",
    "where:\n",
    "- $\\boldsymbol{\\beta}$ = cointegrating vectors (define equilibrium)\n",
    "- $\\boldsymbol{\\alpha}$ = adjustment coefficients (speed of adjustment)\n",
    "- $\\boldsymbol{\\beta}'\\mathbf{Y}_{t-1}$ = error correction term (deviation from equilibrium)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate VECM\n",
    "print(\"Vector Error Correction Model (VECM)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Prepare data as DataFrame\n",
    "data_vecm = pd.DataFrame({'Y1': y1, 'Y2': y2})\n",
    "\n",
    "# Fit VECM with 1 cointegrating relationship\n",
    "vecm_model = VECM(data_vecm, k_ar_diff=1, coint_rank=1, deterministic='ci')\n",
    "vecm_results = vecm_model.fit()\n",
    "\n",
    "print(vecm_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and interpret VECM parameters\n",
    "print(\"VECM Parameter Interpretation\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get alpha (adjustment coefficients)\n",
    "alpha = vecm_results.alpha\n",
    "print(f\"\\nAdjustment Coefficients (α):\")\n",
    "print(f\"  α₁ (Y1): {alpha[0, 0]:.4f}\")\n",
    "print(f\"  α₂ (Y2): {alpha[1, 0]:.4f}\")\n",
    "\n",
    "# Interpretation\n",
    "print(f\"\\nInterpretation:\")\n",
    "if alpha[0, 0] < 0:\n",
    "    print(f\"  Y1 adjusts by {abs(alpha[0, 0])*100:.1f}% of disequilibrium per period\")\n",
    "if alpha[1, 0] != 0:\n",
    "    print(f\"  Y2 adjusts by {abs(alpha[1, 0])*100:.1f}% of disequilibrium per period\")\n",
    "\n",
    "# Weak exogeneity\n",
    "print(f\"\\nWeak Exogeneity:\")\n",
    "if abs(alpha[0, 0]) < 0.01:\n",
    "    print(f\"  Y1 is weakly exogenous (does not adjust to equilibrium)\")\n",
    "if abs(alpha[1, 0]) < 0.01:\n",
    "    print(f\"  Y2 is weakly exogenous (does not adjust to equilibrium)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## 7. Real-World Example: Interest Rates\n",
    "\n",
    "**Expectations Hypothesis of Term Structure:**\n",
    "- Short-term and long-term interest rates should be cointegrated\n",
    "- The spread (term premium) should be stationary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch real interest rate data\n",
    "if HAS_PDR:\n",
    "    try:\n",
    "        # 3-month Treasury Bill and 10-year Treasury yield\n",
    "        short_rate = web.DataReader('TB3MS', 'fred', '1990-01-01', '2024-12-31')\n",
    "        long_rate = web.DataReader('GS10', 'fred', '1990-01-01', '2024-12-31')\n",
    "        \n",
    "        rates_data = pd.DataFrame({\n",
    "            'ShortRate': short_rate['TB3MS'],\n",
    "            'LongRate': long_rate['GS10']\n",
    "        }).dropna()\n",
    "        \n",
    "        print(f\"✓ Real Interest Rate Data: {len(rates_data)} monthly observations\")\n",
    "        DATA_SOURCE = \"FRED\"\n",
    "    except Exception as e:\n",
    "        print(f\"Could not fetch data: {e}\")\n",
    "        HAS_PDR = False\n",
    "\n",
    "if not HAS_PDR:\n",
    "    # Simulated cointegrated interest rates\n",
    "    np.random.seed(456)\n",
    "    n = 400\n",
    "    \n",
    "    # Common trend\n",
    "    trend = np.cumsum(np.random.randn(n) * 0.1) + 5\n",
    "    \n",
    "    # Short and long rates\n",
    "    short_rate = trend + np.random.randn(n) * 0.3\n",
    "    long_rate = trend + 1.5 + np.random.randn(n) * 0.2  # Higher with term premium\n",
    "    \n",
    "    rates_data = pd.DataFrame({\n",
    "        'ShortRate': short_rate,\n",
    "        'LongRate': long_rate\n",
    "    }, index=pd.date_range('1990-01', periods=n, freq='ME'))\n",
    "    \n",
    "    DATA_SOURCE = \"Simulated\"\n",
    "    print(f\"Using simulated data: {len(rates_data)} observations\")\n",
    "\n",
    "print(f\"\\nData Source: {DATA_SOURCE}\")\n",
    "print(rates_data.describe().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot interest rates\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Both rates\n",
    "axes[0].plot(rates_data.index, rates_data['ShortRate'], color=COLORS['blue'], \n",
    "             label='3-Month T-Bill', linewidth=1)\n",
    "axes[0].plot(rates_data.index, rates_data['LongRate'], color=COLORS['orange'], \n",
    "             label='10-Year Treasury', linewidth=1)\n",
    "axes[0].set_title(f'US Interest Rates ({DATA_SOURCE})', fontweight='bold')\n",
    "axes[0].set_ylabel('Interest Rate (%)')\n",
    "axes[0].legend(loc='upper center', bbox_to_anchor=(0.5, -0.12), ncol=2)\n",
    "\n",
    "# Term spread\n",
    "spread = rates_data['LongRate'] - rates_data['ShortRate']\n",
    "axes[1].plot(spread.index, spread, color=COLORS['green'], linewidth=1)\n",
    "axes[1].axhline(y=spread.mean(), color='red', linestyle='--', alpha=0.7, label=f'Mean: {spread.mean():.2f}%')\n",
    "axes[1].axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "axes[1].fill_between(spread.index, 0, spread, where=spread < 0, alpha=0.3, color='red', label='Inverted')\n",
    "axes[1].set_title('Term Spread (Long - Short)', fontweight='bold')\n",
    "axes[1].set_ylabel('Spread (%)')\n",
    "axes[1].legend(loc='upper center', bbox_to_anchor=(0.5, -0.12), ncol=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(bottom=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cointegration analysis of interest rates\n",
    "print(\"Cointegration Analysis: Interest Rates\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Unit root tests\n",
    "print(\"\\n1. Unit Root Tests (ADF):\")\n",
    "for col in ['ShortRate', 'LongRate']:\n",
    "    adf = adfuller(rates_data[col].dropna())\n",
    "    status = \"Stationary\" if adf[1] < 0.05 else \"Non-stationary I(1)\"\n",
    "    print(f\"   {col:>12}: ADF = {adf[0]:>7.3f}, p-value = {adf[1]:.4f} → {status}\")\n",
    "\n",
    "# Test spread\n",
    "adf_spread = adfuller(spread.dropna())\n",
    "print(f\"   {'Spread':>12}: ADF = {adf_spread[0]:>7.3f}, p-value = {adf_spread[1]:.4f}\")\n",
    "\n",
    "# Engle-Granger test\n",
    "print(\"\\n2. Engle-Granger Cointegration Test:\")\n",
    "eg_stat, eg_pval, eg_crit = coint(rates_data['ShortRate'], rates_data['LongRate'])\n",
    "print(f\"   Test statistic: {eg_stat:.4f}\")\n",
    "print(f\"   P-value: {eg_pval:.4f}\")\n",
    "print(f\"   Conclusion: {'Cointegrated' if eg_pval < 0.05 else 'Not cointegrated'} at 5% level\")\n",
    "\n",
    "# Johansen test\n",
    "print(\"\\n3. Johansen Cointegration Test:\")\n",
    "johansen = coint_johansen(rates_data.values, det_order=0, k_ar_diff=1)\n",
    "print(f\"   Trace stat (r=0): {johansen.lr1[0]:.2f} vs 95% CV: {johansen.cvt[0, 1]:.2f}\")\n",
    "print(f\"   Trace stat (r≤1): {johansen.lr1[1]:.2f} vs 95% CV: {johansen.cvt[1, 1]:.2f}\")\n",
    "print(f\"   Conclusion: {'1 cointegrating relationship' if johansen.lr1[0] > johansen.cvt[0, 1] else 'No cointegration'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate VECM for interest rates\n",
    "print(\"VECM Estimation: Interest Rates\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "vecm_rates = VECM(rates_data, k_ar_diff=1, coint_rank=1, deterministic='ci')\n",
    "vecm_rates_results = vecm_rates.fit()\n",
    "\n",
    "print(vecm_rates_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Economic interpretation\n",
    "print(\"\\nEconomic Interpretation\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "alpha_rates = vecm_rates_results.alpha\n",
    "beta_rates = vecm_rates_results.beta\n",
    "\n",
    "print(f\"\\nCointegrating vector (β): [{beta_rates[0, 0]:.4f}, {beta_rates[1, 0]:.4f}]\")\n",
    "print(f\"  → Long-run: ShortRate = {-beta_rates[1, 0]/beta_rates[0, 0]:.4f} × LongRate + const\")\n",
    "\n",
    "print(f\"\\nAdjustment coefficients (α):\")\n",
    "print(f\"  ShortRate α: {alpha_rates[0, 0]:.4f}\")\n",
    "print(f\"  LongRate α:  {alpha_rates[1, 0]:.4f}\")\n",
    "\n",
    "print(f\"\\nInterpretation:\")\n",
    "if abs(alpha_rates[0, 0]) > abs(alpha_rates[1, 0]):\n",
    "    print(f\"  → Short rate adjusts MORE to disequilibrium\")\n",
    "    print(f\"  → Long rate is more 'weakly exogenous' (driven by expectations)\")\n",
    "    print(f\"  → Consistent with central bank adjusting short rate to maintain spread\")\n",
    "else:\n",
    "    print(f\"  → Long rate adjusts MORE to disequilibrium\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "## 8. VECM Forecasting\n",
    "\n",
    "VECM provides better long-run forecasts than VAR in differences because it preserves the equilibrium relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VECM forecasting\n",
    "forecast_steps = 24\n",
    "\n",
    "# Generate forecasts\n",
    "forecast = vecm_rates_results.predict(steps=forecast_steps)\n",
    "\n",
    "# Create forecast dates\n",
    "if hasattr(rates_data.index[-1], 'to_timestamp'):\n",
    "    last_date = rates_data.index[-1].to_timestamp()\n",
    "else:\n",
    "    last_date = rates_data.index[-1]\n",
    "forecast_dates = pd.date_range(start=last_date + pd.DateOffset(months=1), \n",
    "                               periods=forecast_steps, freq='ME')\n",
    "\n",
    "# Plot forecasts\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "for i, (col, color) in enumerate(zip(['ShortRate', 'LongRate'], [COLORS['blue'], COLORS['orange']])):\n",
    "    # Historical\n",
    "    axes[i].plot(rates_data.index[-60:], rates_data[col].values[-60:], \n",
    "                 color=color, linewidth=1.5, label='Historical')\n",
    "    # Forecast\n",
    "    axes[i].plot(forecast_dates, forecast[:, i], \n",
    "                 color=COLORS['red'], linewidth=2, linestyle='--', label='VECM Forecast')\n",
    "    axes[i].axvline(x=rates_data.index[-1], color='black', linestyle='-', alpha=0.3)\n",
    "    axes[i].set_title(f'{col} Forecast', fontweight='bold')\n",
    "    axes[i].set_ylabel('Rate (%)')\n",
    "    axes[i].legend(loc='upper center', bbox_to_anchor=(0.5, -0.12), ncol=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(bottom=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-27",
   "metadata": {},
   "source": [
    "## 9. Impulse Response Functions in VECM\n",
    "\n",
    "In a cointegrated system, shocks have **permanent effects** on levels but the system returns to equilibrium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IRF from VECM\n",
    "irf = vecm_rates_results.irf(periods=40)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "titles = [['Short → Short', 'Long → Short'], ['Short → Long', 'Long → Long']]\n",
    "colors_irf = [[COLORS['blue'], COLORS['orange']], [COLORS['blue'], COLORS['orange']]]\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        axes[i, j].plot(irf.irfs[:, i, j], color=colors_irf[i][j], linewidth=2)\n",
    "        axes[i, j].axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "        axes[i, j].set_title(titles[i][j], fontweight='bold')\n",
    "        if i == 1:\n",
    "            axes[i, j].set_xlabel('Horizon')\n",
    "        if j == 0:\n",
    "            axes[i, j].set_ylabel('Response')\n",
    "\n",
    "plt.suptitle('VECM Impulse Response Functions', fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nNote: Unlike stationary VAR, VECM IRFs don't decay to zero.\")\n",
    "print(\"      Shocks have permanent effects but equilibrium is restored.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-29",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Spurious regression** occurs when regressing I(1) series that are not cointegrated\n",
    "   - High R², significant coefficients, but meaningless!\n",
    "   - Rule: If R² > DW, suspect spurious regression\n",
    "\n",
    "2. **Cointegration** means I(1) variables share a common trend\n",
    "   - Linear combination is stationary (I(0))\n",
    "   - Represents long-run equilibrium relationship\n",
    "\n",
    "3. **Testing for cointegration:**\n",
    "   - Engle-Granger: Simple, but only one vector\n",
    "   - Johansen: Multiple vectors, more powerful\n",
    "\n",
    "4. **VECM** is the appropriate model for cointegrated variables\n",
    "   - $\\beta$ = cointegrating vectors (equilibrium)\n",
    "   - $\\alpha$ = adjustment speeds\n",
    "   - Preserves long-run information lost by differencing\n",
    "\n",
    "5. **Weak exogeneity** ($\\alpha = 0$): Variable doesn't respond to disequilibrium\n",
    "\n",
    "### Practical Workflow\n",
    "1. Test for unit roots (ADF/KPSS)\n",
    "2. If I(1), test for cointegration (Johansen)\n",
    "3. If cointegrated, estimate VECM\n",
    "4. Interpret adjustment coefficients\n",
    "5. Check diagnostics\n",
    "6. IRF, FEVD, forecasting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}