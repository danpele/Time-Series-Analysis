{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/danpele/Time-Series-Analysis/blob/main/EN/Seminar_Notebooks/chapter0_seminar_notebook.ipynb)\n\n---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "# Chapter 0: Seminar - Exercises and Practice\n",
    "\n",
    "**Course:** Time Series Analysis and Forecasting  \n",
    "**Program:** Bachelor program, Faculty of Cybernetics, Statistics and Economic Informatics, Bucharest University of Economic Studies, Romania  \n",
    "**Academic Year:** 2025-2026\n",
    "\n",
    "---\n",
    "\n",
    "## Seminar Objectives\n",
    "\n",
    "In this seminar, you will:\n",
    "1. Practice calculating exponential smoothing forecasts by hand\n",
    "2. Apply decomposition methods to real data\n",
    "3. Evaluate forecast accuracy with different metrics\n",
    "4. Compare exponential smoothing methods\n",
    "5. Understand trend and seasonality handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import yfinance as yf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose, STL\n",
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing, ExponentialSmoothing\n",
    "from statsmodels.tsa.filters.hp_filter import hpfilter\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Plotting style - clean, professional\n",
    "plt.rcParams['figure.figsize'] = (12, 5)\n",
    "plt.rcParams['axes.facecolor'] = 'none'\n",
    "plt.rcParams['figure.facecolor'] = 'none'\n",
    "plt.rcParams['savefig.facecolor'] = 'none'\n",
    "plt.rcParams['savefig.transparent'] = True\n",
    "plt.rcParams['legend.frameon'] = False\n",
    "plt.rcParams['axes.grid'] = False\n",
    "plt.rcParams['axes.spines.top'] = False\n",
    "plt.rcParams['axes.spines.right'] = False\n",
    "\n",
    "# Colors\n",
    "BLUE = '#1A3A6E'\n",
    "RED = '#DC3545'\n",
    "GREEN = '#2E7D32'\n",
    "ORANGE = '#E67E22'\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 1: Multiple Choice Quiz\n",
    "\n",
    "Answer the following questions. Run the cell after each answer to check if you're correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "### Quiz 1: Time Series Basics\n",
    "\n",
    "**Question:** Which of the following is NOT a characteristic of time series data?\n",
    "\n",
    "- A) Observations are ordered in time\n",
    "- B) Consecutive observations are typically correlated\n",
    "- C) Observations are independent and identically distributed\n",
    "- D) The data has a natural temporal ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your answer: 'A', 'B', 'C', or 'D'\n",
    "quiz1_answer = ''  # <-- Enter your answer here\n",
    "\n",
    "# Check answer\n",
    "if quiz1_answer.upper() == 'C':\n",
    "    print(\"CORRECT! Time series observations are typically DEPENDENT (autocorrelated), not i.i.d.\")\n",
    "    print(\"This temporal dependence is what makes time series analysis unique.\")\n",
    "elif quiz1_answer:\n",
    "    print(\"Incorrect. Try again!\")\n",
    "    print(\"Hint: What assumption is violated in time series that holds in cross-sectional data?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "### Quiz 2: Decomposition\n",
    "\n",
    "**Question:** When should you use multiplicative decomposition instead of additive?\n",
    "\n",
    "- A) When the seasonal pattern has constant amplitude\n",
    "- B) When the variance of the series is stable over time\n",
    "- C) When the seasonal fluctuations grow proportionally with the level\n",
    "- D) When the time series has no trend component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your answer: 'A', 'B', 'C', or 'D'\n",
    "quiz2_answer = ''  # <-- Enter your answer here\n",
    "\n",
    "# Check answer\n",
    "if quiz2_answer.upper() == 'C':\n",
    "    print(\"CORRECT! In multiplicative decomposition X = T * S * e,\")\n",
    "    print(\"the seasonal component S is a ratio, so the absolute effect scales with the level.\")\n",
    "    print(\"Use when you see 'fan-shaped' patterns where variance increases with mean.\")\n",
    "elif quiz2_answer:\n",
    "    print(\"Incorrect. Try again!\")\n",
    "    print(\"Hint: Think about what happens to seasonal peaks as the series level increases.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "### Quiz 3: Exponential Smoothing\n",
    "\n",
    "**Question:** In Simple Exponential Smoothing with $\\alpha = 0.9$, what happens?\n",
    "\n",
    "- A) Forecasts are very smooth and stable\n",
    "- B) Recent observations have very little weight\n",
    "- C) Forecasts react quickly to recent changes\n",
    "- D) The forecast is essentially a long-term average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your answer: 'A', 'B', 'C', or 'D'\n",
    "quiz3_answer = ''  # <-- Enter your answer here\n",
    "\n",
    "# Check answer\n",
    "if quiz3_answer.upper() == 'C':\n",
    "    print(\"CORRECT! With alpha = 0.9: forecast = 0.9 * X_t + 0.1 * previous_forecast\")\n",
    "    print(\"This means 90% weight on the most recent observation!\")\n",
    "    print(\"High alpha = reactive. Low alpha = smooth.\")\n",
    "elif quiz3_answer:\n",
    "    print(\"Incorrect. Try again!\")\n",
    "    print(\"Hint: What does a high alpha mean for the weight on the most recent observation?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "### Quiz 4: Holt-Winters Parameters\n",
    "\n",
    "**Question:** In Holt-Winters exponential smoothing, what does the gamma ($\\gamma$) parameter control?\n",
    "\n",
    "- A) The level smoothing\n",
    "- B) The trend smoothing\n",
    "- C) The seasonal smoothing\n",
    "- D) The error variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your answer: 'A', 'B', 'C', or 'D'\n",
    "quiz4_answer = ''  # <-- Enter your answer here\n",
    "\n",
    "# Check answer\n",
    "if quiz4_answer.upper() == 'C':\n",
    "    print(\"CORRECT! In Holt-Winters: alpha controls level, beta controls trend, gamma controls seasonality.\")\n",
    "    print(\"A high gamma means the seasonal pattern adapts quickly to recent seasonal changes.\")\n",
    "    print(\"A low gamma means the seasonal pattern is more stable over time.\")\n",
    "elif quiz4_answer:\n",
    "    print(\"Incorrect. Try again!\")\n",
    "    print(\"Hint: Holt-Winters has three parameters: alpha (level), beta (trend), and gamma (?)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "### Quiz 5: Forecast Accuracy Metrics (RMSE vs MAE)\n",
    "\n",
    "**Question:** When comparing RMSE and MAE for forecast evaluation, which statement is correct?\n",
    "\n",
    "- A) RMSE is always smaller than MAE\n",
    "- B) RMSE penalizes large errors more heavily than MAE\n",
    "- C) MAE is more sensitive to outliers than RMSE\n",
    "- D) RMSE and MAE always give the same ranking of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your answer: 'A', 'B', 'C', or 'D'\n",
    "quiz5_answer = ''  # <-- Enter your answer here\n",
    "\n",
    "# Check answer\n",
    "if quiz5_answer.upper() == 'B':\n",
    "    print(\"CORRECT! RMSE squares the errors before averaging, so large errors are penalized more.\")\n",
    "    print(\"RMSE >= MAE always (equality only when all errors are equal).\")\n",
    "    print(\"Use RMSE when large errors are particularly undesirable.\")\n",
    "elif quiz5_answer:\n",
    "    print(\"Incorrect. Try again!\")\n",
    "    print(\"Hint: What happens when you square a large error vs a small error?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "### Quiz 6: Cross-validation for Time Series\n",
    "\n",
    "**Question:** Why can't we use standard k-fold cross-validation for time series data?\n",
    "\n",
    "- A) Time series data is too large\n",
    "- B) It violates the temporal ordering and causes data leakage\n",
    "- C) Cross-validation only works for classification\n",
    "- D) Time series data has no variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your answer: 'A', 'B', 'C', or 'D'\n",
    "quiz6_answer = ''  # <-- Enter your answer here\n",
    "\n",
    "# Check answer\n",
    "if quiz6_answer.upper() == 'B':\n",
    "    print(\"CORRECT! Standard k-fold CV randomly shuffles data, which destroys temporal ordering.\")\n",
    "    print(\"Using future data to predict the past causes data leakage and overly optimistic results.\")\n",
    "    print(\"Use time series CV: expanding window or rolling window validation instead.\")\n",
    "elif quiz6_answer:\n",
    "    print(\"Incorrect. Try again!\")\n",
    "    print(\"Hint: What happens when you shuffle time series data and use future values to predict past?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "### Quiz 7: Variance Stabilization\n",
    "\n",
    "**Question:** A time series shows increasing variance as the level increases (heteroscedasticity). Which transformation is most appropriate?\n",
    "\n",
    "- A) First differencing\n",
    "- B) Log transformation\n",
    "- C) Adding a constant\n",
    "- D) Seasonal differencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your answer: 'A', 'B', 'C', or 'D'\n",
    "quiz7_answer = ''  # <-- Enter your answer here\n",
    "\n",
    "# Check answer\n",
    "if quiz7_answer.upper() == 'B':\n",
    "    print(\"CORRECT! Log transformation stabilizes variance when it increases with the level.\")\n",
    "    print(\"If Var(X) is proportional to E[X]^2, then Var(log X) becomes approximately constant.\")\n",
    "    print(\"This is common in financial and economic data.\")\n",
    "elif quiz7_answer:\n",
    "    print(\"Incorrect. Try again!\")\n",
    "    print(\"Hint: Which transformation converts multiplicative relationships to additive?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "### Quiz 8: Trend Estimation\n",
    "\n",
    "**Question:** Which method is most appropriate for estimating a non-linear trend in a time series?\n",
    "\n",
    "- A) Simple moving average with window size 3\n",
    "- B) Linear regression on time\n",
    "- C) LOESS (locally weighted regression)\n",
    "- D) First differencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your answer: 'A', 'B', 'C', or 'D'\n",
    "quiz8_answer = ''  # <-- Enter your answer here\n",
    "\n",
    "# Check answer\n",
    "if quiz8_answer.upper() == 'C':\n",
    "    print(\"CORRECT! LOESS (Locally Estimated Scatterplot Smoothing) is ideal for non-linear trends.\")\n",
    "    print(\"It fits local polynomials to subsets of data, adapting to changing curvature.\")\n",
    "    print(\"Linear regression assumes a straight line; differencing removes trends but doesn't estimate them.\")\n",
    "elif quiz8_answer:\n",
    "    print(\"Incorrect. Try again!\")\n",
    "    print(\"Hint: Which method can adapt to curves and changes in trend direction?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "### Quiz 9: Seasonal Adjustment\n",
    "\n",
    "**Question:** What is the purpose of seasonal adjustment in time series analysis?\n",
    "\n",
    "- A) To remove the trend component\n",
    "- B) To make the series non-stationary\n",
    "- C) To remove recurring seasonal patterns for better trend analysis\n",
    "- D) To increase the variance of the series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your answer: 'A', 'B', 'C', or 'D'\n",
    "quiz9_answer = ''  # <-- Enter your answer here\n",
    "\n",
    "# Check answer\n",
    "if quiz9_answer.upper() == 'C':\n",
    "    print(\"CORRECT! Seasonal adjustment removes predictable seasonal patterns from data.\")\n",
    "    print(\"This makes it easier to see the underlying trend and irregular movements.\")\n",
    "    print(\"Seasonally adjusted data is often published for economic indicators like GDP and unemployment.\")\n",
    "elif quiz9_answer:\n",
    "    print(\"Incorrect. Try again!\")\n",
    "    print(\"Hint: Why would economists want to 'remove' the Christmas shopping spike from retail sales?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "### Quiz 10: Forecast Horizon\n",
    "\n",
    "**Question:** As the forecast horizon increases, what typically happens to forecast accuracy?\n",
    "\n",
    "- A) Accuracy improves because more data is used\n",
    "- B) Accuracy decreases because uncertainty accumulates\n",
    "- C) Accuracy stays constant for stationary series\n",
    "- D) Accuracy improves due to mean reversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your answer: 'A', 'B', 'C', or 'D'\n",
    "quiz10_answer = ''  # <-- Enter your answer here\n",
    "\n",
    "# Check answer\n",
    "if quiz10_answer.upper() == 'B':\n",
    "    print(\"CORRECT! Forecast uncertainty grows with the horizon.\")\n",
    "    print(\"Each step ahead compounds the error from previous forecasts.\")\n",
    "    print(\"This is why confidence intervals 'fan out' as h increases.\")\n",
    "elif quiz10_answer:\n",
    "    print(\"Incorrect. Try again!\")\n",
    "    print(\"Hint: What happens to prediction intervals as you forecast further ahead?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 2: True/False Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer each statement with True or False\n",
    "tf_answers = {\n",
    "    1: None,  # \"Multiplicative decomposition is always better than additive.\"\n",
    "    2: None,  # \"Holt-Winters is appropriate for data with no seasonality.\"\n",
    "    3: None,  # \"You should always use the test set for hyperparameter tuning.\"\n",
    "    4: None,  # \"Log transformation can stabilize variance in a time series.\"\n",
    "    5: None,  # \"Moving average with a larger window produces smoother trends.\"\n",
    "    6: None,  # \"MAPE is undefined when actual values are zero.\"\n",
    "}\n",
    "\n",
    "# Enter your answers below (True or False)\n",
    "tf_answers[1] = None  # Multiplicative always better\n",
    "tf_answers[2] = None  # Holt-Winters for non-seasonal\n",
    "tf_answers[3] = None  # Use test set for tuning\n",
    "tf_answers[4] = None  # Log stabilizes variance\n",
    "tf_answers[5] = None  # Larger window = smoother\n",
    "tf_answers[6] = None  # MAPE undefined at zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check your answers\n",
    "correct_answers = {1: False, 2: False, 3: False, 4: True, 5: True, 6: True}\n",
    "explanations = {\n",
    "    1: \"FALSE: Use multiplicative when seasonal amplitude grows with level, additive when constant.\",\n",
    "    2: \"FALSE: Use Holt's method (no seasonal) or SES for non-seasonal data.\",\n",
    "    3: \"FALSE: Use VALIDATION set for tuning. Test set is for FINAL evaluation only!\",\n",
    "    4: \"TRUE: Log transformation converts multiplicative to additive, stabilizing variance.\",\n",
    "    5: \"TRUE: Larger windows average over more observations, producing smoother trends.\",\n",
    "    6: \"TRUE: MAPE = |error/actual|, so division by zero when actual = 0.\"\n",
    "}\n",
    "\n",
    "score = 0\n",
    "for q, correct in correct_answers.items():\n",
    "    user_ans = tf_answers[q]\n",
    "    if user_ans is None:\n",
    "        status = \"NOT ANSWERED\"\n",
    "    elif user_ans == correct:\n",
    "        status = \"CORRECT\"\n",
    "        score += 1\n",
    "    else:\n",
    "        status = \"INCORRECT\"\n",
    "    print(f\"Q{q}: {status}\")\n",
    "    if user_ans is not None:\n",
    "        print(f\"   {explanations[q]}\")\n",
    "    print()\n",
    "\n",
    "print(f\"\\nScore: {score}/6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-28",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 3: Calculation Exercises\n",
    "\n",
    "## Exercise 1: Simple Exponential Smoothing by Hand\n",
    "\n",
    "Given the following data and $\\alpha = 0.3$:\n",
    "\n",
    "| t | 1 | 2 | 3 | 4 | 5 |\n",
    "|---|---|---|---|---|---|\n",
    "| $X_t$ | 10 | 12 | 11 | 14 | 13 |\n",
    "\n",
    "Starting with $\\hat{X}_1 = X_1 = 10$, calculate the forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "X = [10, 12, 11, 14, 13]\n",
    "alpha = 0.3\n",
    "\n",
    "# YOUR TASK: Fill in the forecasts\n",
    "# Formula: X_hat[t+1] = alpha * X[t] + (1-alpha) * X_hat[t]\n",
    "\n",
    "X_hat = [10]  # Start with X_hat[1] = 10\n",
    "\n",
    "# Calculate X_hat[2]\n",
    "X_hat_2 = None  # <-- Calculate this\n",
    "\n",
    "# Calculate X_hat[3]\n",
    "X_hat_3 = None  # <-- Calculate this\n",
    "\n",
    "# Calculate X_hat[4]\n",
    "X_hat_4 = None  # <-- Calculate this\n",
    "\n",
    "# Calculate X_hat[5]\n",
    "X_hat_5 = None  # <-- Calculate this\n",
    "\n",
    "# Calculate X_hat[6] (forecast for next period)\n",
    "X_hat_6 = None  # <-- Calculate this\n",
    "\n",
    "print(\"Your answers:\")\n",
    "print(f\"X_hat[2] = {X_hat_2}\")\n",
    "print(f\"X_hat[3] = {X_hat_3}\")\n",
    "print(f\"X_hat[4] = {X_hat_4}\")\n",
    "print(f\"X_hat[5] = {X_hat_5}\")\n",
    "print(f\"X_hat[6] = {X_hat_6}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION - Run this to check your answers\n",
    "print(\"SOLUTION:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "X = [10, 12, 11, 14, 13]\n",
    "alpha = 0.3\n",
    "X_hat_sol = [10]  # X_hat[1] = X[1] = 10\n",
    "\n",
    "for t in range(len(X)):\n",
    "    next_forecast = alpha * X[t] + (1 - alpha) * X_hat_sol[-1]\n",
    "    X_hat_sol.append(round(next_forecast, 2))\n",
    "    if t < len(X) - 1:\n",
    "        print(f\"X_hat[{t+2}] = {alpha} * {X[t]} + {1-alpha} * {X_hat_sol[t]:.2f} = {next_forecast:.2f}\")\n",
    "    else:\n",
    "        print(f\"X_hat[{t+2}] = {alpha} * {X[t]} + {1-alpha} * {X_hat_sol[t]:.2f} = {next_forecast:.2f} (Forecast)\")\n",
    "\n",
    "# Calculate errors\n",
    "errors = [X[i] - X_hat_sol[i] for i in range(1, len(X))]\n",
    "mae = np.mean(np.abs(errors))\n",
    "rmse = np.sqrt(np.mean(np.array(errors)**2))\n",
    "\n",
    "print(f\"\\nErrors: {[round(e, 2) for e in errors]}\")\n",
    "print(f\"MAE: {mae:.3f}\")\n",
    "print(f\"RMSE: {rmse:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-31",
   "metadata": {},
   "source": [
    "## Exercise 2: Seasonal Index Calculation\n",
    "\n",
    "Given quarterly sales data for 2 years:\n",
    "\n",
    "| Year | Q1 | Q2 | Q3 | Q4 |\n",
    "|------|-----|-----|-----|-----|\n",
    "| 2023 | 80 | 120 | 140 | 160 |\n",
    "| 2024 | 100 | 140 | 160 | 200 |\n",
    "\n",
    "Calculate the seasonal indices using the ratio-to-moving-average method (multiplicative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "sales = [80, 120, 140, 160, 100, 140, 160, 200]\n",
    "quarters = ['Q1', 'Q2', 'Q3', 'Q4'] * 2\n",
    "\n",
    "# YOUR TASK:\n",
    "# Step 1: Calculate centered moving average (window=4)\n",
    "# Step 2: Calculate ratio: actual / CMA\n",
    "# Step 3: Average the ratios for each quarter\n",
    "# Step 4: Normalize so they sum to 4 (or average to 1)\n",
    "\n",
    "# Calculate the seasonal indices for each quarter\n",
    "Q1_index = None  # <-- Calculate\n",
    "Q2_index = None  # <-- Calculate\n",
    "Q3_index = None  # <-- Calculate\n",
    "Q4_index = None  # <-- Calculate\n",
    "\n",
    "print(\"Your seasonal indices:\")\n",
    "print(f\"Q1: {Q1_index}\")\n",
    "print(f\"Q2: {Q2_index}\")\n",
    "print(f\"Q3: {Q3_index}\")\n",
    "print(f\"Q4: {Q4_index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "print(\"SOLUTION:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "import pandas as pd\n",
    "sales_series = pd.Series(sales)\n",
    "\n",
    "# Calculate 4-period moving average (for quarterly data)\n",
    "# Use a 2x4-MA (centered moving average)\n",
    "ma4 = sales_series.rolling(window=4, center=False).mean()\n",
    "cma = ma4.rolling(window=2, center=False).mean().shift(-1)\n",
    "\n",
    "# Calculate seasonal ratios\n",
    "ratios = sales_series / cma\n",
    "\n",
    "print(\"Centered Moving Averages and Ratios:\")\n",
    "for i in range(len(sales)):\n",
    "    cma_val = cma.iloc[i] if pd.notna(cma.iloc[i]) else 'N/A'\n",
    "    ratio_val = ratios.iloc[i] if pd.notna(ratios.iloc[i]) else 'N/A'\n",
    "    print(f\"  {quarters[i]}: Sales={sales[i]}, CMA={cma_val}, Ratio={ratio_val}\")\n",
    "\n",
    "# Average ratios by quarter\n",
    "q_ratios = {}\n",
    "for q in ['Q1', 'Q2', 'Q3', 'Q4']:\n",
    "    q_vals = [ratios.iloc[i] for i in range(len(quarters)) if quarters[i] == q and pd.notna(ratios.iloc[i])]\n",
    "    q_ratios[q] = np.mean(q_vals) if q_vals else np.nan\n",
    "\n",
    "# Normalize\n",
    "total = sum([v for v in q_ratios.values() if pd.notna(v)])\n",
    "n_valid = sum([1 for v in q_ratios.values() if pd.notna(v)])\n",
    "adjustment = n_valid / total if total > 0 else 1\n",
    "\n",
    "print(\"\\nSeasonal Indices (simplified calculation):\")\n",
    "# For a cleaner solution, use statsmodels\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "idx = pd.date_range('2023-01-01', periods=8, freq='Q')\n",
    "sales_ts = pd.Series(sales, index=idx)\n",
    "decomp = seasonal_decompose(sales_ts, model='multiplicative', period=4)\n",
    "\n",
    "indices = decomp.seasonal[:4]\n",
    "print(f\"Q1: {indices.iloc[0]:.3f}\")\n",
    "print(f\"Q2: {indices.iloc[1]:.3f}\")\n",
    "print(f\"Q3: {indices.iloc[2]:.3f}\")\n",
    "print(f\"Q4: {indices.iloc[3]:.3f}\")\n",
    "print(f\"\\nInterpretation: Q1 is {(1-indices.iloc[0])*100:.1f}% below average, Q4 is {(indices.iloc[3]-1)*100:.1f}% above average\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-34",
   "metadata": {},
   "source": [
    "## Exercise 3: Error Metrics Calculation\n",
    "\n",
    "Given actual and forecast values:\n",
    "\n",
    "| t | Actual | Forecast |\n",
    "|---|--------|----------|\n",
    "| 1 | 100 | 95 |\n",
    "| 2 | 110 | 105 |\n",
    "| 3 | 90 | 100 |\n",
    "| 4 | 120 | 115 |\n",
    "\n",
    "Calculate MAE, MSE, RMSE, and MAPE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "actual = np.array([100, 110, 90, 120])\n",
    "forecast = np.array([95, 105, 100, 115])\n",
    "\n",
    "# YOUR TASK: Calculate error metrics\n",
    "# Formulas:\n",
    "# MAE = mean(|actual - forecast|)\n",
    "# MSE = mean((actual - forecast)^2)\n",
    "# RMSE = sqrt(MSE)\n",
    "# MAPE = 100 * mean(|actual - forecast| / |actual|)\n",
    "\n",
    "errors = actual - forecast\n",
    "print(f\"Errors: {errors}\")\n",
    "\n",
    "MAE = None  # <-- Calculate\n",
    "MSE = None  # <-- Calculate\n",
    "RMSE = None  # <-- Calculate\n",
    "MAPE = None  # <-- Calculate\n",
    "\n",
    "print(f\"\\nYour answers:\")\n",
    "print(f\"MAE = {MAE}\")\n",
    "print(f\"MSE = {MSE}\")\n",
    "print(f\"RMSE = {RMSE}\")\n",
    "print(f\"MAPE = {MAPE}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "print(\"SOLUTION:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "errors = actual - forecast\n",
    "print(f\"Errors: {errors}\")\n",
    "print(f\"Absolute Errors: {np.abs(errors)}\")\n",
    "print(f\"Squared Errors: {errors**2}\")\n",
    "\n",
    "MAE_sol = np.mean(np.abs(errors))\n",
    "MSE_sol = np.mean(errors**2)\n",
    "RMSE_sol = np.sqrt(MSE_sol)\n",
    "MAPE_sol = 100 * np.mean(np.abs(errors) / actual)\n",
    "\n",
    "print(f\"\\nMAE = mean(|5, 5, 10, 5|) = {MAE_sol}\")\n",
    "print(f\"MSE = mean(25, 25, 100, 25) = {MSE_sol}\")\n",
    "print(f\"RMSE = sqrt({MSE_sol}) = {RMSE_sol:.2f}\")\n",
    "print(f\"MAPE = 100 * mean(5/100, 5/110, 10/90, 5/120) = {MAPE_sol:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-37",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 4: Python Coding Exercises\n",
    "\n",
    "## Exercise 4: Load and Decompose Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Perform STL decomposition on airline passengers data\n",
    "\n",
    "# Load data\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv'\n",
    "airline = pd.read_csv(url, parse_dates=['Month'], index_col='Month')\n",
    "airline.columns = ['Passengers']\n",
    "\n",
    "# Step 1: Apply STL decomposition with period=12\n",
    "# YOUR CODE HERE\n",
    "# stl = STL(...)  # <-- Complete this\n",
    "# result = stl.fit()\n",
    "\n",
    "\n",
    "# Step 2: Plot all four components (original, trend, seasonal, residual)\n",
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "# Step 3: Calculate what percentage of variance is explained by trend\n",
    "# Hint: Compare Var(trend) to Var(original)\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "print(\"SOLUTION:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# STL decomposition\n",
    "stl = STL(airline['Passengers'], period=12, robust=True)\n",
    "result = stl.fit()\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(4, 1, figsize=(12, 10))\n",
    "\n",
    "axes[0].plot(airline.index, airline['Passengers'], color=BLUE, label='Original')\n",
    "axes[0].set_title('Original', fontweight='bold')\n",
    "axes[0].legend(loc='upper left')\n",
    "\n",
    "axes[1].plot(airline.index, result.trend, color=GREEN, label='Trend')\n",
    "axes[1].set_title('Trend', fontweight='bold')\n",
    "axes[1].legend(loc='upper left')\n",
    "\n",
    "axes[2].plot(airline.index, result.seasonal, color=ORANGE, label='Seasonal')\n",
    "axes[2].set_title('Seasonal', fontweight='bold')\n",
    "axes[2].legend(loc='upper left')\n",
    "\n",
    "axes[3].plot(airline.index, result.resid, color=RED, label='Residual')\n",
    "axes[3].set_title('Residual', fontweight='bold')\n",
    "axes[3].legend(loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Variance explained\n",
    "var_original = airline['Passengers'].var()\n",
    "var_trend = result.trend.var()\n",
    "pct_explained = (var_trend / var_original) * 100\n",
    "\n",
    "print(f\"\\nVariance of original: {var_original:.2f}\")\n",
    "print(f\"Variance of trend: {var_trend:.2f}\")\n",
    "print(f\"Percentage explained by trend: {pct_explained:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-40",
   "metadata": {},
   "source": [
    "## Exercise 5: Forecast Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Compare SES, Holt, and Holt-Winters on airline data\n",
    "\n",
    "# Split data\n",
    "train = airline[:'1958']\n",
    "test = airline['1959':]\n",
    "\n",
    "# Step 1: Fit Simple Exponential Smoothing\n",
    "# ses = SimpleExpSmoothing(train['Passengers']).fit()\n",
    "# ses_forecast = ses.forecast(len(test))\n",
    "\n",
    "\n",
    "# Step 2: Fit Holt's method (trend='add')\n",
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "# Step 3: Fit Holt-Winters with multiplicative seasonality\n",
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "# Step 4: Calculate RMSE for each method\n",
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "# Step 5: Plot all forecasts vs actual\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "\n",
    "# Fit models\n",
    "ses = SimpleExpSmoothing(train['Passengers']).fit()\n",
    "holt = ExponentialSmoothing(train['Passengers'], trend='add', seasonal=None).fit()\n",
    "hw = ExponentialSmoothing(train['Passengers'], trend='add', \n",
    "                          seasonal='mul', seasonal_periods=12).fit()\n",
    "\n",
    "# Forecasts\n",
    "h = len(test)\n",
    "ses_fc = ses.forecast(h)\n",
    "holt_fc = holt.forecast(h)\n",
    "hw_fc = hw.forecast(h)\n",
    "\n",
    "# Calculate RMSE\n",
    "actual = test['Passengers'].values\n",
    "rmse_ses = np.sqrt(mean_squared_error(actual, ses_fc))\n",
    "rmse_holt = np.sqrt(mean_squared_error(actual, holt_fc))\n",
    "rmse_hw = np.sqrt(mean_squared_error(actual, hw_fc))\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "ax.plot(train.index, train['Passengers'], color=BLUE, label='Training')\n",
    "ax.plot(test.index, test['Passengers'], color='gray', linewidth=2, label='Actual')\n",
    "ax.plot(test.index, ses_fc, color=RED, linestyle='--', label=f'SES (RMSE={rmse_ses:.1f})')\n",
    "ax.plot(test.index, holt_fc, color=ORANGE, linestyle='--', label=f'Holt (RMSE={rmse_holt:.1f})')\n",
    "ax.plot(test.index, hw_fc, color=GREEN, linestyle='--', label=f'HW (RMSE={rmse_hw:.1f})')\n",
    "ax.axvline(x=train.index[-1], color='black', linestyle='-', alpha=0.3)\n",
    "ax.set_title('Forecast Comparison', fontweight='bold')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Passengers')\n",
    "ax.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"SOLUTION:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nRMSE Comparison:\")\n",
    "print(f\"  SES:          {rmse_ses:.2f}\")\n",
    "print(f\"  Holt:         {rmse_holt:.2f}\")\n",
    "print(f\"  Holt-Winters: {rmse_hw:.2f}\")\n",
    "print(f\"\\nBest Model: Holt-Winters (captures both trend and seasonality!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-43",
   "metadata": {},
   "source": [
    "## Exercise 6: Effect of Smoothing Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Explore how alpha affects SES forecasts\n",
    "\n",
    "# Create simple synthetic data\n",
    "np.random.seed(42)\n",
    "n = 50\n",
    "synthetic = pd.Series(50 + np.cumsum(np.random.randn(n) * 2),\n",
    "                      index=pd.date_range('2020-01-01', periods=n, freq='D'))\n",
    "\n",
    "# Test different alpha values\n",
    "alphas = [0.1, 0.3, 0.5, 0.9]\n",
    "\n",
    "# YOUR TASK:\n",
    "# 1. Fit SES with each alpha value\n",
    "# 2. Plot the fitted values for each\n",
    "# 3. Observe the differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, alpha in enumerate(alphas):\n",
    "    model = SimpleExpSmoothing(synthetic).fit(smoothing_level=alpha, optimized=False)\n",
    "    fitted = model.fittedvalues\n",
    "    \n",
    "    axes[i].plot(synthetic.index, synthetic, color='gray', linewidth=1, alpha=0.7, label='Actual')\n",
    "    axes[i].plot(fitted.index, fitted, color=BLUE, linewidth=2, label=f'SES (alpha={alpha})')\n",
    "    axes[i].set_title(f'alpha = {alpha}', fontweight='bold')\n",
    "    axes[i].legend(loc='upper left')\n",
    "\n",
    "plt.suptitle('Effect of Smoothing Parameter on SES', fontweight='bold', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Observation:\")\n",
    "print(\"- Low alpha (0.1): Very smooth, slow to react to changes\")\n",
    "print(\"- High alpha (0.9): Very reactive, follows data closely\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-46",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 5: Discussion Questions\n",
    "\n",
    "Write your answers in the markdown cells below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-47",
   "metadata": {},
   "source": [
    "### Discussion 1\n",
    "\n",
    "**Scenario:** You are analyzing monthly sales data for a retail company. The data shows clear seasonality (high sales in December) and an upward trend. The seasonal peaks have been getting larger over time.\n",
    "\n",
    "**Questions:**\n",
    "1. Should you use additive or multiplicative decomposition? Why?\n",
    "2. Which exponential smoothing method would you recommend?\n",
    "3. How would you evaluate your forecast model?\n",
    "\n",
    "**Your Answer:**\n",
    "\n",
    "*Write your answer here...*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-48",
   "metadata": {},
   "source": [
    "### Discussion 2\n",
    "\n",
    "**Scenario:** Your colleague suggests using RMSE to compare two forecast models. Model A has RMSE = 5 on one dataset, and Model B has RMSE = 50 on a different dataset. Your colleague concludes Model A is better.\n",
    "\n",
    "**Questions:**\n",
    "1. What is wrong with this comparison?\n",
    "2. How should you properly compare models?\n",
    "3. Which metric would be more appropriate for comparing across different scales?\n",
    "\n",
    "**Your Answer:**\n",
    "\n",
    "*Write your answer here...*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-49",
   "metadata": {},
   "source": [
    "---\n",
    "# Summary\n",
    "\n",
    "## Key Takeaways from Today's Seminar\n",
    "\n",
    "1. **Choose decomposition wisely** - multiplicative when seasonal amplitude grows with level\n",
    "2. **Understand smoothing parameters** - high $\\alpha$ = reactive, low $\\alpha$ = smooth\n",
    "3. **Match method to data** - SES (no trend/seasonality), Holt (trend), Holt-Winters (both)\n",
    "4. **Proper evaluation** - never tune on test set, use validation set\n",
    "5. **Error metrics matter** - RMSE penalizes large errors, MAPE is scale-independent\n",
    "\n",
    "## Next Seminar\n",
    "Stochastic processes, stationarity, and unit root testing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}