{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/danpele/Time-Series-Analysis/blob/main/chapter1_seminar_notebook.ipynb)\n\n---",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1: Seminar - Exercises and Practice\n",
    "\n",
    "**Course:** Time Series Analysis and Forecasting  \n",
    "**Program:** Master in Statistics and Data Science  \n",
    "**Academic Year:** 2025-2026\n",
    "\n",
    "---\n",
    "\n",
    "## Seminar Objectives\n",
    "\n",
    "In this seminar, you will:\n",
    "1. Practice calculating exponential smoothing forecasts by hand\n",
    "2. Apply decomposition methods to real data\n",
    "3. Test for stationarity using ADF and KPSS tests\n",
    "4. Evaluate forecast accuracy with different metrics\n",
    "5. Interpret ACF and PACF plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport yfinance as yf\nfrom statsmodels.tsa.seasonal import seasonal_decompose, STL\nfrom statsmodels.tsa.holtwinters import SimpleExpSmoothing, ExponentialSmoothing\nfrom statsmodels.tsa.stattools import adfuller, kpss, acf, pacf\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\n\n# Plotting style - clean, professional\nplt.rcParams['figure.figsize'] = (12, 5)\nplt.rcParams['axes.facecolor'] = 'none'  # Transparent background\nplt.rcParams['figure.facecolor'] = 'none'  # Transparent figure\nplt.rcParams['savefig.facecolor'] = 'none'\nplt.rcParams['axes.grid'] = False  # No grid\nplt.rcParams['axes.spines.top'] = False\nplt.rcParams['axes.spines.right'] = False\n\n# Colors\nBLUE = '#1A3A6E'\nRED = '#DC3545'\nGREEN = '#2E7D32'\n\nprint(\"Setup complete!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 1: Multiple Choice Quiz\n",
    "\n",
    "Answer the following questions. Run the cell after each answer to check if you're correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz 1: Time Series Basics\n",
    "\n",
    "**Question:** Which of the following is NOT a characteristic of time series data?\n",
    "\n",
    "- A) Observations are ordered in time\n",
    "- B) Consecutive observations are typically correlated\n",
    "- C) Observations are independent and identically distributed\n",
    "- D) The data has a natural temporal ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your answer: 'A', 'B', 'C', or 'D'\n",
    "quiz1_answer = ''  # <-- Enter your answer here\n",
    "\n",
    "# Check answer\n",
    "if quiz1_answer.upper() == 'C':\n",
    "    print(\"CORRECT! Time series observations are typically DEPENDENT (autocorrelated), not i.i.d.\")\n",
    "    print(\"This temporal dependence is what makes time series analysis unique.\")\n",
    "elif quiz1_answer:\n",
    "    print(\"Incorrect. Try again!\")\n",
    "    print(\"Hint: What assumption is violated in time series that holds in cross-sectional data?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz 2: Decomposition\n",
    "\n",
    "**Question:** When should you use multiplicative decomposition instead of additive?\n",
    "\n",
    "- A) When the seasonal pattern has constant amplitude\n",
    "- B) When the variance of the series is stable over time\n",
    "- C) When the seasonal fluctuations grow proportionally with the level\n",
    "- D) When the time series has no trend component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your answer: 'A', 'B', 'C', or 'D'\n",
    "quiz2_answer = ''  # <-- Enter your answer here\n",
    "\n",
    "# Check answer\n",
    "if quiz2_answer.upper() == 'C':\n",
    "    print(\"CORRECT! In multiplicative decomposition X = T * S * e,\")\n",
    "    print(\"the seasonal component S is a ratio, so the absolute effect scales with the level.\")\n",
    "    print(\"Use when you see 'fan-shaped' patterns where variance increases with mean.\")\n",
    "elif quiz2_answer:\n",
    "    print(\"Incorrect. Try again!\")\n",
    "    print(\"Hint: Think about what happens to seasonal peaks as the series level increases.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz 3: Exponential Smoothing\n",
    "\n",
    "**Question:** In Simple Exponential Smoothing with α = 0.9, what happens?\n",
    "\n",
    "- A) Forecasts are very smooth and stable\n",
    "- B) Recent observations have very little weight\n",
    "- C) Forecasts react quickly to recent changes\n",
    "- D) The forecast is essentially a long-term average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your answer: 'A', 'B', 'C', or 'D'\n",
    "quiz3_answer = ''  # <-- Enter your answer here\n",
    "\n",
    "# Check answer\n",
    "if quiz3_answer.upper() == 'C':\n",
    "    print(\"CORRECT! With α = 0.9: forecast = 0.9 * X_t + 0.1 * previous_forecast\")\n",
    "    print(\"This means 90% weight on the most recent observation!\")\n",
    "    print(\"High α = reactive. Low α = smooth.\")\n",
    "elif quiz3_answer:\n",
    "    print(\"Incorrect. Try again!\")\n",
    "    print(\"Hint: What does a high α mean for the weight on the most recent observation?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz 4: Stationarity\n",
    "\n",
    "**Question:** A random walk process $X_t = X_{t-1} + \\varepsilon_t$ is:\n",
    "\n",
    "- A) Strictly stationary\n",
    "- B) Weakly stationary\n",
    "- C) Non-stationary because variance grows with time\n",
    "- D) Stationary after adding a constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your answer: 'A', 'B', 'C', or 'D'\n",
    "quiz4_answer = ''  # <-- Enter your answer here\n",
    "\n",
    "# Check answer\n",
    "if quiz4_answer.upper() == 'C':\n",
    "    print(\"CORRECT! For random walk: Var(X_t) = t * σ²\")\n",
    "    print(\"The variance grows with time, violating stationarity.\")\n",
    "    print(\"Solution: DIFFERENCING gives ΔX_t = ε_t which IS stationary.\")\n",
    "elif quiz4_answer:\n",
    "    print(\"Incorrect. Try again!\")\n",
    "    print(\"Hint: What is Var(X_t) for a random walk? Does it depend on t?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz 5: Unit Root Tests\n",
    "\n",
    "**Question:** You run ADF and KPSS tests. ADF fails to reject H₀, and KPSS rejects H₀. What do you conclude?\n",
    "\n",
    "- A) The series is stationary\n",
    "- B) The series has a unit root (non-stationary)\n",
    "- C) The results are inconclusive\n",
    "- D) You need to run more tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your answer: 'A', 'B', 'C', or 'D'\n",
    "quiz5_answer = ''  # <-- Enter your answer here\n",
    "\n",
    "# Check answer\n",
    "if quiz5_answer.upper() == 'B':\n",
    "    print(\"CORRECT!\")\n",
    "    print(\"ADF: H₀ = unit root. Fail to reject → evidence FOR unit root\")\n",
    "    print(\"KPSS: H₀ = stationary. Reject → evidence AGAINST stationarity\")\n",
    "    print(\"Both agree: the series is NON-STATIONARY. You should difference it.\")\n",
    "elif quiz5_answer:\n",
    "    print(\"Incorrect. Try again!\")\n",
    "    print(\"Hint: Remember the null hypotheses are OPPOSITE for ADF and KPSS.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 2: True/False Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer each statement with True or False\n",
    "tf_answers = {\n",
    "    1: None,  # \"The ACF of a stationary AR(1) process decays exponentially.\"\n",
    "    2: None,  # \"White noise is always normally distributed.\"\n",
    "    3: None,  # \"Differencing can make a non-stationary series stationary.\"\n",
    "    4: None,  # \"The PACF of a MA(1) process cuts off after lag 1.\"\n",
    "    5: None,  # \"You should always use the test set for hyperparameter tuning.\"\n",
    "    6: None,  # \"Holt-Winters is appropriate for data with no seasonality.\"\n",
    "}\n",
    "\n",
    "# Enter your answers below (True or False)\n",
    "tf_answers[1] = None  # ACF of AR(1) decays exponentially\n",
    "tf_answers[2] = None  # White noise is always normal\n",
    "tf_answers[3] = None  # Differencing makes series stationary\n",
    "tf_answers[4] = None  # PACF of MA(1) cuts off at lag 1\n",
    "tf_answers[5] = None  # Use test set for tuning\n",
    "tf_answers[6] = None  # Holt-Winters for non-seasonal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check your answers\n",
    "correct_answers = {1: True, 2: False, 3: True, 4: False, 5: False, 6: False}\n",
    "explanations = {\n",
    "    1: \"TRUE: For AR(1), ρ(h) = φ^h, which decays exponentially.\",\n",
    "    2: \"FALSE: White noise only requires zero mean, constant variance, no autocorrelation. Gaussian WN is a special case.\",\n",
    "    3: \"TRUE: Differencing removes stochastic trends (unit roots).\",\n",
    "    4: \"FALSE: It's the ACF that cuts off for MA. PACF DECAYS for MA processes.\",\n",
    "    5: \"FALSE: Use VALIDATION set for tuning. Test set is for FINAL evaluation only!\",\n",
    "    6: \"FALSE: Use Holt's method (no seasonal) or SES for non-seasonal data.\"\n",
    "}\n",
    "\n",
    "score = 0\n",
    "for q, correct in correct_answers.items():\n",
    "    user_ans = tf_answers[q]\n",
    "    if user_ans is None:\n",
    "        status = \"NOT ANSWERED\"\n",
    "    elif user_ans == correct:\n",
    "        status = \"CORRECT\"\n",
    "        score += 1\n",
    "    else:\n",
    "        status = \"INCORRECT\"\n",
    "    print(f\"Q{q}: {status}\")\n",
    "    if user_ans is not None:\n",
    "        print(f\"   {explanations[q]}\")\n",
    "    print()\n",
    "\n",
    "print(f\"\\nScore: {score}/6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 3: Calculation Exercises\n",
    "\n",
    "## Exercise 1: Simple Exponential Smoothing by Hand\n",
    "\n",
    "Given the following data and α = 0.3:\n",
    "\n",
    "| t | 1 | 2 | 3 | 4 | 5 |\n",
    "|---|---|---|---|---|---|\n",
    "| X_t | 10 | 12 | 11 | 14 | 13 |\n",
    "\n",
    "Starting with $\\hat{X}_1 = X_1 = 10$, calculate the forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "X = [10, 12, 11, 14, 13]\n",
    "alpha = 0.3\n",
    "\n",
    "# YOUR TASK: Fill in the forecasts\n",
    "# Formula: X_hat[t+1] = alpha * X[t] + (1-alpha) * X_hat[t]\n",
    "\n",
    "X_hat = [10]  # Start with X_hat[1] = 10\n",
    "\n",
    "# Calculate X_hat[2]\n",
    "X_hat_2 = None  # <-- Calculate this\n",
    "\n",
    "# Calculate X_hat[3]\n",
    "X_hat_3 = None  # <-- Calculate this\n",
    "\n",
    "# Calculate X_hat[4]\n",
    "X_hat_4 = None  # <-- Calculate this\n",
    "\n",
    "# Calculate X_hat[5]\n",
    "X_hat_5 = None  # <-- Calculate this\n",
    "\n",
    "# Calculate X_hat[6] (forecast for next period)\n",
    "X_hat_6 = None  # <-- Calculate this\n",
    "\n",
    "print(\"Your answers:\")\n",
    "print(f\"X_hat[2] = {X_hat_2}\")\n",
    "print(f\"X_hat[3] = {X_hat_3}\")\n",
    "print(f\"X_hat[4] = {X_hat_4}\")\n",
    "print(f\"X_hat[5] = {X_hat_5}\")\n",
    "print(f\"X_hat[6] = {X_hat_6}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION - Run this to check your answers\n",
    "print(\"SOLUTION:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "X = [10, 12, 11, 14, 13]\n",
    "alpha = 0.3\n",
    "X_hat_sol = [10]  # X_hat[1] = X[1] = 10\n",
    "\n",
    "for t in range(len(X)):\n",
    "    next_forecast = alpha * X[t] + (1 - alpha) * X_hat_sol[-1]\n",
    "    X_hat_sol.append(round(next_forecast, 2))\n",
    "    if t < len(X) - 1:\n",
    "        print(f\"X_hat[{t+2}] = {alpha} × {X[t]} + {1-alpha} × {X_hat_sol[t]:.2f} = {next_forecast:.2f}\")\n",
    "    else:\n",
    "        print(f\"X_hat[{t+2}] = {alpha} × {X[t]} + {1-alpha} × {X_hat_sol[t]:.2f} = {next_forecast:.2f} (Forecast)\")\n",
    "\n",
    "# Calculate errors\n",
    "errors = [X[i] - X_hat_sol[i] for i in range(1, len(X))]\n",
    "mae = np.mean(np.abs(errors))\n",
    "rmse = np.sqrt(np.mean(np.array(errors)**2))\n",
    "\n",
    "print(f\"\\nErrors: {[round(e, 2) for e in errors]}\")\n",
    "print(f\"MAE: {mae:.3f}\")\n",
    "print(f\"RMSE: {rmse:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Autocovariance Calculations\n",
    "\n",
    "For a stationary process with:\n",
    "- E[X_t] = 5\n",
    "- γ(0) = 4 (variance)\n",
    "- γ(1) = 2\n",
    "- γ(2) = 1\n",
    "\n",
    "Calculate:\n",
    "1. The autocorrelation function ρ(0), ρ(1), ρ(2)\n",
    "2. Cov(X_t, X_{t-1})\n",
    "3. Corr(X_5, X_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given values\n",
    "mu = 5\n",
    "gamma_0 = 4  # Var(X_t)\n",
    "gamma_1 = 2\n",
    "gamma_2 = 1\n",
    "\n",
    "# YOUR TASK: Calculate the following\n",
    "# Formula: ρ(h) = γ(h) / γ(0)\n",
    "\n",
    "rho_0 = None  # <-- Calculate ρ(0)\n",
    "rho_1 = None  # <-- Calculate ρ(1)\n",
    "rho_2 = None  # <-- Calculate ρ(2)\n",
    "\n",
    "cov_Xt_Xt_minus_1 = None  # <-- Cov(X_t, X_{t-1})\n",
    "corr_X5_X7 = None  # <-- Corr(X_5, X_7)\n",
    "\n",
    "print(\"Your answers:\")\n",
    "print(f\"ρ(0) = {rho_0}\")\n",
    "print(f\"ρ(1) = {rho_1}\")\n",
    "print(f\"ρ(2) = {rho_2}\")\n",
    "print(f\"Cov(X_t, X_{{t-1}}) = {cov_Xt_Xt_minus_1}\")\n",
    "print(f\"Corr(X_5, X_7) = {corr_X5_X7}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "print(\"SOLUTION:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "rho_0_sol = gamma_0 / gamma_0\n",
    "rho_1_sol = gamma_1 / gamma_0\n",
    "rho_2_sol = gamma_2 / gamma_0\n",
    "\n",
    "print(f\"ρ(0) = γ(0)/γ(0) = {gamma_0}/{gamma_0} = {rho_0_sol}\")\n",
    "print(f\"ρ(1) = γ(1)/γ(0) = {gamma_1}/{gamma_0} = {rho_1_sol}\")\n",
    "print(f\"ρ(2) = γ(2)/γ(0) = {gamma_2}/{gamma_0} = {rho_2_sol}\")\n",
    "\n",
    "print(f\"\\nCov(X_t, X_{{t-1}}) = γ(1) = {gamma_1}\")\n",
    "print(f\"   (By stationarity, lag 1 covariance is always γ(1))\")\n",
    "\n",
    "print(f\"\\nCorr(X_5, X_7) = ρ(|7-5|) = ρ(2) = {rho_2_sol}\")\n",
    "print(f\"   (Correlation depends only on the LAG, not the specific times)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Random Walk Properties\n",
    "\n",
    "Consider a random walk $X_t = X_{t-1} + \\varepsilon_t$ where $\\varepsilon_t \\sim WN(0, 4)$ and $X_0 = 100$.\n",
    "\n",
    "Calculate:\n",
    "1. E[X_10]\n",
    "2. Var(X_10)\n",
    "3. Cov(X_5, X_10)\n",
    "4. 95% confidence interval for X_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given\n",
    "X_0 = 100\n",
    "sigma_sq = 4  # Var(epsilon_t)\n",
    "\n",
    "# YOUR TASK: Calculate the following\n",
    "# Formulas for random walk:\n",
    "# E[X_t] = X_0\n",
    "# Var(X_t) = t * sigma^2\n",
    "# Cov(X_s, X_t) = min(s, t) * sigma^2\n",
    "\n",
    "E_X10 = None  # <-- Calculate E[X_10]\n",
    "Var_X10 = None  # <-- Calculate Var(X_10)\n",
    "Cov_X5_X10 = None  # <-- Calculate Cov(X_5, X_10)\n",
    "\n",
    "# For 95% CI of X_100:\n",
    "E_X100 = None  # <-- E[X_100]\n",
    "SD_X100 = None  # <-- Standard deviation of X_100\n",
    "CI_lower = None  # <-- Lower bound (use 1.96)\n",
    "CI_upper = None  # <-- Upper bound\n",
    "\n",
    "print(\"Your answers:\")\n",
    "print(f\"E[X_10] = {E_X10}\")\n",
    "print(f\"Var(X_10) = {Var_X10}\")\n",
    "print(f\"Cov(X_5, X_10) = {Cov_X5_X10}\")\n",
    "print(f\"95% CI for X_100: [{CI_lower}, {CI_upper}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "print(\"SOLUTION:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "E_X10_sol = X_0\n",
    "Var_X10_sol = 10 * sigma_sq\n",
    "Cov_X5_X10_sol = min(5, 10) * sigma_sq\n",
    "\n",
    "print(f\"E[X_10] = X_0 = {E_X10_sol}\")\n",
    "print(f\"   (Mean stays at starting value for random walk)\")\n",
    "\n",
    "print(f\"\\nVar(X_10) = 10 × σ² = 10 × {sigma_sq} = {Var_X10_sol}\")\n",
    "\n",
    "print(f\"\\nCov(X_5, X_10) = min(5, 10) × σ² = 5 × {sigma_sq} = {Cov_X5_X10_sol}\")\n",
    "\n",
    "E_X100_sol = X_0\n",
    "Var_X100_sol = 100 * sigma_sq\n",
    "SD_X100_sol = np.sqrt(Var_X100_sol)\n",
    "CI_lower_sol = E_X100_sol - 1.96 * SD_X100_sol\n",
    "CI_upper_sol = E_X100_sol + 1.96 * SD_X100_sol\n",
    "\n",
    "print(f\"\\n95% CI for X_100:\")\n",
    "print(f\"   E[X_100] = {E_X100_sol}\")\n",
    "print(f\"   Var(X_100) = 100 × {sigma_sq} = {Var_X100_sol}\")\n",
    "print(f\"   SD(X_100) = √{Var_X100_sol} = {SD_X100_sol}\")\n",
    "print(f\"   CI = {E_X100_sol} ± 1.96 × {SD_X100_sol}\")\n",
    "print(f\"   CI = [{CI_lower_sol:.1f}, {CI_upper_sol:.1f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 4: Python Coding Exercises\n",
    "\n",
    "## Exercise 4: Load and Analyze Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Download Apple stock data and perform basic analysis\n",
    "\n",
    "# Step 1: Download data using yfinance\n",
    "# YOUR CODE HERE\n",
    "ticker = 'AAPL'\n",
    "start_date = '2020-01-01'\n",
    "end_date = '2025-01-01'\n",
    "\n",
    "# Download the data\n",
    "# data = yf.download(...)  # <-- Complete this line\n",
    "\n",
    "\n",
    "# Step 2: Plot the closing prices\n",
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "# Step 3: Calculate and print basic statistics (mean, std, min, max)\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# SOLUTION\nprint(\"SOLUTION:\")\nprint(\"=\"*50)\n\n# Download data\ndata = yf.download('AAPL', start='2020-01-01', end='2025-01-01', progress=False)\n# Flatten multi-level columns (newer yfinance returns MultiIndex)\nif isinstance(data.columns, pd.MultiIndex):\n    data.columns = data.columns.droplevel(1)\nprint(f\"Downloaded {len(data)} observations\")\n\n# Plot\nfig, ax = plt.subplots(figsize=(12, 5))\nax.plot(data.index, data['Close'], color=BLUE, linewidth=1, label='AAPL Close')\nax.set_title('Apple Stock Price (2020-2025)', fontweight='bold')\nax.set_xlabel('Date')\nax.set_ylabel('Price ($)')\nax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.12), ncol=1, frameon=False)\nplt.tight_layout()\nplt.show()\n\n# Statistics\nprint(f\"\\nBasic Statistics:\")\nprint(f\"Mean: ${data['Close'].mean():.2f}\")\nprint(f\"Std Dev: ${data['Close'].std():.2f}\")\nprint(f\"Min: ${data['Close'].min():.2f}\")\nprint(f\"Max: ${data['Close'].max():.2f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Perform STL decomposition on airline passengers data\n",
    "\n",
    "# Load data\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv'\n",
    "airline = pd.read_csv(url, parse_dates=['Month'], index_col='Month')\n",
    "airline.columns = ['Passengers']\n",
    "\n",
    "# Step 1: Apply STL decomposition with period=12\n",
    "# YOUR CODE HERE\n",
    "# stl = STL(...)  # <-- Complete this\n",
    "# result = stl.fit()\n",
    "\n",
    "\n",
    "# Step 2: Plot all four components (original, trend, seasonal, residual)\n",
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "# Step 3: Calculate what percentage of variance is explained by trend\n",
    "# Hint: Compare Var(trend) to Var(original)\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# SOLUTION\nprint(\"SOLUTION:\")\nprint(\"=\"*50)\n\n# STL decomposition\nstl = STL(airline['Passengers'], period=12, robust=True)\nresult = stl.fit()\n\n# Plot\nfig, axes = plt.subplots(4, 1, figsize=(12, 10))\n\naxes[0].plot(airline.index, airline['Passengers'], color=BLUE, label='Original')\naxes[0].set_title('Original', fontweight='bold')\naxes[0].legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=1, frameon=False)\n\naxes[1].plot(airline.index, result.trend, color=GREEN, label='Trend')\naxes[1].set_title('Trend', fontweight='bold')\naxes[1].legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=1, frameon=False)\n\naxes[2].plot(airline.index, result.seasonal, color='orange', label='Seasonal')\naxes[2].set_title('Seasonal', fontweight='bold')\naxes[2].legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=1, frameon=False)\n\naxes[3].plot(airline.index, result.resid, color=RED, label='Residual')\naxes[3].set_title('Residual', fontweight='bold')\naxes[3].legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=1, frameon=False)\n\nplt.tight_layout()\nplt.show()\n\n# Variance explained\nvar_original = airline['Passengers'].var()\nvar_trend = result.trend.var()\npct_explained = (var_trend / var_original) * 100\n\nprint(f\"\\nVariance of original: {var_original:.2f}\")\nprint(f\"Variance of trend: {var_trend:.2f}\")\nprint(f\"Percentage explained by trend: {pct_explained:.1f}%\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6: Stationarity Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Test for stationarity using ADF and KPSS tests\n",
    "\n",
    "# Use the Apple stock data from Exercise 4\n",
    "prices = data['Close'].dropna()\n",
    "returns = prices.pct_change().dropna() * 100\n",
    "\n",
    "# Step 1: Run ADF test on prices\n",
    "# adf_prices = adfuller(...)  # <-- Complete this\n",
    "# Print the test statistic and p-value\n",
    "\n",
    "\n",
    "# Step 2: Run ADF test on returns\n",
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "# Step 3: Run KPSS test on both\n",
    "# kpss_prices = kpss(...)  # <-- Complete this\n",
    "\n",
    "\n",
    "# Step 4: Interpret the results\n",
    "# Are prices stationary? Are returns stationary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "print(\"SOLUTION:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Test prices\n",
    "print(\"\\n--- PRICES ---\")\n",
    "adf_prices = adfuller(prices, autolag='AIC')\n",
    "print(f\"ADF Test:\")\n",
    "print(f\"  Statistic: {adf_prices[0]:.4f}\")\n",
    "print(f\"  p-value: {adf_prices[1]:.4f}\")\n",
    "print(f\"  Conclusion: {'STATIONARY' if adf_prices[1] < 0.05 else 'NON-STATIONARY'}\")\n",
    "\n",
    "kpss_prices = kpss(prices, regression='c', nlags='auto')\n",
    "print(f\"\\nKPSS Test:\")\n",
    "print(f\"  Statistic: {kpss_prices[0]:.4f}\")\n",
    "print(f\"  p-value: {kpss_prices[1]:.4f}\")\n",
    "print(f\"  Conclusion: {'NON-STATIONARY' if kpss_prices[1] < 0.05 else 'STATIONARY'}\")\n",
    "\n",
    "# Test returns\n",
    "print(\"\\n--- RETURNS ---\")\n",
    "adf_returns = adfuller(returns, autolag='AIC')\n",
    "print(f\"ADF Test:\")\n",
    "print(f\"  Statistic: {adf_returns[0]:.4f}\")\n",
    "print(f\"  p-value: {adf_returns[1]:.4f}\")\n",
    "print(f\"  Conclusion: {'STATIONARY' if adf_returns[1] < 0.05 else 'NON-STATIONARY'}\")\n",
    "\n",
    "kpss_returns = kpss(returns, regression='c', nlags='auto')\n",
    "print(f\"\\nKPSS Test:\")\n",
    "print(f\"  Statistic: {kpss_returns[0]:.4f}\")\n",
    "print(f\"  p-value: {kpss_returns[1]:.4f}\")\n",
    "print(f\"  Conclusion: {'NON-STATIONARY' if kpss_returns[1] < 0.05 else 'STATIONARY'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"INTERPRETATION:\")\n",
    "print(\"- Prices are NON-STATIONARY (both tests agree)\")\n",
    "print(\"- Returns are STATIONARY (both tests agree)\")\n",
    "print(\"- This is why we model RETURNS, not prices!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 7: Forecast Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Compare SES, Holt, and Holt-Winters on airline data\n",
    "\n",
    "# Split data\n",
    "train = airline[:'1958']\n",
    "test = airline['1959':]\n",
    "\n",
    "# Step 1: Fit Simple Exponential Smoothing\n",
    "# ses = SimpleExpSmoothing(train['Passengers']).fit()\n",
    "# ses_forecast = ses.forecast(len(test))\n",
    "\n",
    "\n",
    "# Step 2: Fit Holt's method (trend='add')\n",
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "# Step 3: Fit Holt-Winters with multiplicative seasonality\n",
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "# Step 4: Calculate RMSE for each method\n",
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "# Step 5: Plot all forecasts vs actual\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# SOLUTION\nprint(\"SOLUTION:\")\nprint(\"=\"*50)\n\n# Fit models\nses = SimpleExpSmoothing(train['Passengers']).fit()\nholt = ExponentialSmoothing(train['Passengers'], trend='add', seasonal=None).fit()\nhw = ExponentialSmoothing(train['Passengers'], trend='add', \n                          seasonal='mul', seasonal_periods=12).fit()\n\n# Forecasts\nh = len(test)\nses_fc = ses.forecast(h)\nholt_fc = holt.forecast(h)\nhw_fc = hw.forecast(h)\n\n# Calculate RMSE\nactual = test['Passengers'].values\nrmse_ses = np.sqrt(mean_squared_error(actual, ses_fc))\nrmse_holt = np.sqrt(mean_squared_error(actual, holt_fc))\nrmse_hw = np.sqrt(mean_squared_error(actual, hw_fc))\n\nprint(f\"\\nRMSE Comparison:\")\nprint(f\"  SES:          {rmse_ses:.2f}\")\nprint(f\"  Holt:         {rmse_holt:.2f}\")\nprint(f\"  Holt-Winters: {rmse_hw:.2f}\")\nprint(f\"\\nBest Model: Holt-Winters (captures seasonality!)\")\n\n# Plot\nfig, ax = plt.subplots(figsize=(14, 6))\nax.plot(train.index, train['Passengers'], color=BLUE, label='Training')\nax.plot(test.index, test['Passengers'], color='gray', linewidth=2, label='Actual')\nax.plot(test.index, ses_fc, color=RED, linestyle='--', label=f'SES (RMSE={rmse_ses:.1f})')\nax.plot(test.index, holt_fc, color='orange', linestyle='--', label=f'Holt (RMSE={rmse_holt:.1f})')\nax.plot(test.index, hw_fc, color=GREEN, linestyle='--', label=f'HW (RMSE={rmse_hw:.1f})')\nax.axvline(x=train.index[-1], color='black', linestyle='-', alpha=0.3)\nax.set_title('Forecast Comparison', fontweight='bold')\nax.set_xlabel('Date')\nax.set_ylabel('Passengers')\nax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.12), ncol=5, frameon=False)\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 5: Discussion Questions\n",
    "\n",
    "Write your answers in the markdown cells below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion 1\n",
    "\n",
    "**Scenario:** You are analyzing monthly sales data for a retail company. The data shows clear seasonality (high sales in December) and an upward trend. The seasonal peaks have been getting larger over time.\n",
    "\n",
    "**Questions:**\n",
    "1. Should you use additive or multiplicative decomposition? Why?\n",
    "2. Which exponential smoothing method would you recommend?\n",
    "3. How would you evaluate your forecast model?\n",
    "\n",
    "**Your Answer:**\n",
    "\n",
    "*Write your answer here...*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion 2\n",
    "\n",
    "**Scenario:** A colleague claims: \"I ran the ADF test on my stock price data and got a p-value of 0.65, so my data is stationary and I can fit an ARMA model directly.\"\n",
    "\n",
    "**Questions:**\n",
    "1. What is wrong with this interpretation?\n",
    "2. What do the ADF hypotheses actually test?\n",
    "3. What should the colleague do before fitting an ARMA model?\n",
    "\n",
    "**Your Answer:**\n",
    "\n",
    "*Write your answer here...*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Summary\n",
    "\n",
    "## Key Takeaways from Today's Seminar\n",
    "\n",
    "1. **Time series are dependent** - not i.i.d. like cross-sectional data\n",
    "2. **Choose decomposition wisely** - multiplicative when seasonal amplitude grows\n",
    "3. **Understand smoothing parameters** - high α = reactive, low α = smooth\n",
    "4. **Test for stationarity** - use both ADF and KPSS together\n",
    "5. **Proper evaluation** - never tune on test set!\n",
    "6. **Random walk is non-stationary** - variance grows with time\n",
    "\n",
    "## Next Seminar\n",
    "ARMA/ARIMA model identification, estimation, and forecasting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}