{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/danpele/Time-Series-Analysis/blob/main/chapter1_lecture_notebook.ipynb)\n\n---",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1: Introduction to Time Series Analysis\n",
    "\n",
    "**Course:** Time Series Analysis and Forecasting  \n",
    "**Program:** Master in Statistics and Data Science  \n",
    "**Academic Year:** 2025-2026\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "1. Define time series and distinguish from other data types\n",
    "2. Decompose time series into trend, seasonal, and residual components\n",
    "3. Apply exponential smoothing methods (SES, Holt, Holt-Winters)\n",
    "4. Evaluate forecasts using MAE, RMSE, MAPE\n",
    "5. Understand stationarity and test for it (ADF, KPSS)\n",
    "6. Compute and interpret ACF and PACF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Core libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Time series specific\nimport yfinance as yf\nfrom statsmodels.tsa.seasonal import seasonal_decompose, STL\nfrom statsmodels.tsa.holtwinters import SimpleExpSmoothing, ExponentialSmoothing\nfrom statsmodels.tsa.stattools import adfuller, kpss, acf, pacf\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfrom statsmodels.stats.diagnostic import acorr_ljungbox\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\n\n# Plotting style - clean, professional\nplt.rcParams['figure.figsize'] = (12, 5)\nplt.rcParams['font.size'] = 11\nplt.rcParams['axes.facecolor'] = 'none'  # Transparent background\nplt.rcParams['figure.facecolor'] = 'none'  # Transparent figure\nplt.rcParams['savefig.facecolor'] = 'none'\nplt.rcParams['axes.grid'] = False  # No grid\nplt.rcParams['axes.spines.top'] = False\nplt.rcParams['axes.spines.right'] = False\n\n# Colors (IDA color scheme)\nCOLORS = {\n    'blue': '#1A3A6E',\n    'red': '#DC3545',\n    'green': '#2E7D32',\n    'orange': '#E67E22',\n    'gray': '#666666'\n}\n\nprint(\"All libraries loaded successfully!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is a Time Series?\n",
    "\n",
    "A **time series** is a sequence of observations indexed by time:\n",
    "\n",
    "$$\\{X_t : t \\in \\mathcal{T}\\}$$\n",
    "\n",
    "### Key Characteristics:\n",
    "- **Ordered**: Observations have a natural temporal ordering\n",
    "- **Dependent**: Consecutive observations are typically correlated\n",
    "- **Discrete or Continuous**: Time index can be discrete or continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Download real financial data\nprint(\"Downloading S&P 500 data...\")\nsp500 = yf.download('^GSPC', start='2020-01-01', end='2025-01-01', progress=False)\n# Flatten multi-level columns (newer yfinance returns MultiIndex)\nif isinstance(sp500.columns, pd.MultiIndex):\n    sp500.columns = sp500.columns.droplevel(1)\nprint(f\"Downloaded {len(sp500)} observations\")\n\n# Display first few rows\nsp500.head()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Plot the time series\nfig, ax = plt.subplots(figsize=(12, 5))\nax.plot(sp500.index, sp500['Close'], color=COLORS['blue'], linewidth=1, label='S&P 500 Close')\nax.set_xlabel('Date')\nax.set_ylabel('Price ($)')\nax.set_title('S&P 500 Index (2020-2025)', fontweight='bold', fontsize=14)\nax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.12), ncol=1, frameon=False)\nplt.tight_layout()\nplt.show()\n\nprint(f\"\\nBasic Statistics:\")\nprint(f\"Mean: ${sp500['Close'].mean():.2f}\")\nprint(f\"Std Dev: ${sp500['Close'].std():.2f}\")\nprint(f\"Min: ${sp500['Close'].min():.2f}\")\nprint(f\"Max: ${sp500['Close'].max():.2f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Data: Comparison\n",
    "\n",
    "| Data Type | Units (N) | Time (T) | Example |\n",
    "|-----------|-----------|----------|----------|\n",
    "| Cross-sectional | Many | 1 | Survey of 1000 households |\n",
    "| Time series | 1 | Many | Daily S&P 500 prices |\n",
    "| Panel | Many | Many | GDP of 50 countries, 20 years |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Time Series Decomposition\n",
    "\n",
    "### Decomposition Models\n",
    "\n",
    "**Additive Model:** $X_t = T_t + S_t + \\varepsilon_t$\n",
    "- Use when seasonal fluctuations are **constant** over time\n",
    "\n",
    "**Multiplicative Model:** $X_t = T_t \\times S_t \\times \\varepsilon_t$\n",
    "- Use when seasonal fluctuations **grow** with the level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load airline passengers data (classic example with trend and seasonality)\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv'\n",
    "airline = pd.read_csv(url, parse_dates=['Month'], index_col='Month')\n",
    "airline.columns = ['Passengers']\n",
    "\n",
    "print(f\"Airline Passengers Data: {len(airline)} observations\")\n",
    "print(f\"Period: {airline.index[0].strftime('%Y-%m')} to {airline.index[-1].strftime('%Y-%m')}\")\n",
    "airline.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Plot airline data\nfig, ax = plt.subplots(figsize=(12, 5))\nax.plot(airline.index, airline['Passengers'], color=COLORS['blue'], linewidth=1.5, label='Passengers')\nax.set_xlabel('Date')\nax.set_ylabel('Passengers (thousands)')\nax.set_title('International Airline Passengers (1949-1960)', fontweight='bold', fontsize=14)\nax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.12), ncol=1, frameon=False)\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nObservations:\")\nprint(\"- Clear upward TREND\")\nprint(\"- Regular SEASONAL pattern (peaks in summer)\")\nprint(\"- Seasonal amplitude INCREASES with level -> Multiplicative!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Classical Decomposition - Multiplicative\ndecomposition = seasonal_decompose(airline['Passengers'], model='multiplicative', period=12)\n\nfig, axes = plt.subplots(4, 1, figsize=(12, 10))\n\naxes[0].plot(airline.index, airline['Passengers'], color=COLORS['blue'], label='Original')\naxes[0].set_title('Original Series', fontweight='bold')\naxes[0].set_ylabel('Passengers')\naxes[0].legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=1, frameon=False)\n\naxes[1].plot(airline.index, decomposition.trend, color=COLORS['green'], label='Trend')\naxes[1].set_title('Trend Component', fontweight='bold')\naxes[1].set_ylabel('Trend')\naxes[1].legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=1, frameon=False)\n\naxes[2].plot(airline.index, decomposition.seasonal, color=COLORS['orange'], label='Seasonal')\naxes[2].set_title('Seasonal Component', fontweight='bold')\naxes[2].set_ylabel('Seasonal')\naxes[2].axhline(y=1, color='gray', linestyle='--', linewidth=0.8)\naxes[2].legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=1, frameon=False)\n\naxes[3].plot(airline.index, decomposition.resid, color=COLORS['red'], label='Residual')\naxes[3].set_title('Residual Component', fontweight='bold')\naxes[3].set_ylabel('Residual')\naxes[3].axhline(y=1, color='gray', linestyle='--', linewidth=0.8)\naxes[3].legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=1, frameon=False)\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# STL Decomposition (more robust)\nstl = STL(airline['Passengers'], period=12, robust=True)\nstl_result = stl.fit()\n\nfig, axes = plt.subplots(4, 1, figsize=(12, 10))\n\naxes[0].plot(airline.index, airline['Passengers'], color=COLORS['blue'], label='Original')\naxes[0].set_title('Original Series', fontweight='bold')\naxes[0].legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=1, frameon=False)\n\naxes[1].plot(airline.index, stl_result.trend, color=COLORS['green'], label='Trend')\naxes[1].set_title('STL Trend', fontweight='bold')\naxes[1].legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=1, frameon=False)\n\naxes[2].plot(airline.index, stl_result.seasonal, color=COLORS['orange'], label='Seasonal')\naxes[2].set_title('STL Seasonal', fontweight='bold')\naxes[2].legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=1, frameon=False)\n\naxes[3].plot(airline.index, stl_result.resid, color=COLORS['red'], label='Residual')\naxes[3].set_title('STL Residual', fontweight='bold')\naxes[3].legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=1, frameon=False)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"STL Decomposition is ADDITIVE: X = Trend + Seasonal + Residual\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seasonal Indices Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Extract monthly seasonal factors\nseasonal_factors = decomposition.seasonal[:12]\n\nmonths = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n          'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n\nfig, ax = plt.subplots(figsize=(10, 5))\ncolors = [COLORS['red'] if s < 1 else COLORS['green'] for s in seasonal_factors]\nbars = ax.bar(months, seasonal_factors, color=colors, edgecolor='black', linewidth=0.5)\nax.axhline(y=1, color='black', linestyle='-', linewidth=1)\nax.set_xlabel('Month')\nax.set_ylabel('Seasonal Factor')\nax.set_title('Monthly Seasonal Indices (Multiplicative)', fontweight='bold', fontsize=14)\nax.set_ylim(0.7, 1.3)\n\n# Add value labels\nfor bar, val in zip(bars, seasonal_factors):\n    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, \n            f'{val:.2f}', ha='center', va='bottom', fontsize=9)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nInterpretation:\")\nprint(f\"- July factor = {seasonal_factors.iloc[6]:.2f} -> {(seasonal_factors.iloc[6]-1)*100:.0f}% above average\")\nprint(f\"- November factor = {seasonal_factors.iloc[10]:.2f} -> {(1-seasonal_factors.iloc[10])*100:.0f}% below average\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exponential Smoothing Methods\n",
    "\n",
    "### Simple Exponential Smoothing (SES)\n",
    "\n",
    "$$\\hat{X}_{t+1|t} = \\alpha X_t + (1-\\alpha)\\hat{X}_{t|t-1}$$\n",
    "\n",
    "where $\\alpha \\in (0,1)$ is the smoothing parameter.\n",
    "\n",
    "- **Large α**: Responsive to recent changes\n",
    "- **Small α**: Smoother, more stable forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create synthetic data without trend/seasonality for SES demo\nnp.random.seed(42)\nn = 100\nsynthetic = pd.Series(50 + np.cumsum(np.random.randn(n) * 0.5), \n                      index=pd.date_range('2020-01-01', periods=n, freq='D'))\n\n# Fit SES with different alpha values\nalphas = [0.1, 0.3, 0.7, 0.9]\n\nfig, axes = plt.subplots(2, 2, figsize=(14, 8))\naxes = axes.flatten()\n\nfor i, alpha in enumerate(alphas):\n    model = SimpleExpSmoothing(synthetic).fit(smoothing_level=alpha, optimized=False)\n    fitted = model.fittedvalues\n    \n    axes[i].plot(synthetic.index, synthetic, color=COLORS['gray'], \n                 linewidth=1, alpha=0.7, label='Actual')\n    axes[i].plot(fitted.index, fitted, color=COLORS['blue'], \n                 linewidth=2, label=f'SES (α={alpha})')\n    axes[i].set_title(f'α = {alpha}', fontweight='bold', fontsize=12)\n    axes[i].legend(loc='upper center', bbox_to_anchor=(0.5, -0.12), ncol=2, frameon=False)\n\nplt.suptitle('Effect of Smoothing Parameter α on SES', fontweight='bold', fontsize=14)\nplt.tight_layout()\nplt.show()\n\nprint(\"Observation: Higher α -> more reactive to changes, Lower α -> smoother\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holt's Linear Trend Method\n",
    "\n",
    "**Level:** $\\ell_t = \\alpha X_t + (1-\\alpha)(\\ell_{t-1} + b_{t-1})$\n",
    "\n",
    "**Trend:** $b_t = \\beta^*(\\ell_t - \\ell_{t-1}) + (1-\\beta^*)b_{t-1}$\n",
    "\n",
    "**Forecast:** $\\hat{X}_{t+h|t} = \\ell_t + h \\cdot b_t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create data with trend\nnp.random.seed(42)\nn = 100\ntrend_data = pd.Series(30 + 0.5 * np.arange(n) + np.random.randn(n) * 3,\n                       index=pd.date_range('2020-01-01', periods=n, freq='D'))\n\n# Split into train/test\ntrain_size = 80\ntrain = trend_data[:train_size]\ntest = trend_data[train_size:]\n\n# Fit Holt's method\nholt_model = ExponentialSmoothing(train, trend='add', seasonal=None).fit()\nholt_forecast = holt_model.forecast(len(test))\n\n# Also fit SES for comparison\nses_model = SimpleExpSmoothing(train).fit()\nses_forecast = ses_model.forecast(len(test))\n\n# Plot\nfig, ax = plt.subplots(figsize=(12, 5))\nax.plot(train.index, train, color=COLORS['blue'], linewidth=1.5, label='Training Data')\nax.plot(test.index, test, color=COLORS['gray'], linewidth=1.5, label='Test Data')\nax.plot(test.index, holt_forecast, color=COLORS['green'], linewidth=2, \n        linestyle='--', label='Holt Forecast')\nax.plot(test.index, ses_forecast, color=COLORS['red'], linewidth=2, \n        linestyle=':', label='SES Forecast')\nax.axvline(x=train.index[-1], color='black', linestyle='-', linewidth=1, alpha=0.5)\nax.set_xlabel('Date')\nax.set_ylabel('Value')\nax.set_title(\"Holt's Method vs SES on Trending Data\", fontweight='bold', fontsize=14)\nax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.12), ncol=4, frameon=False)\nplt.tight_layout()\nplt.show()\n\n# Calculate errors\nholt_rmse = np.sqrt(mean_squared_error(test, holt_forecast))\nses_rmse = np.sqrt(mean_squared_error(test, ses_forecast))\nprint(f\"\\nHolt RMSE: {holt_rmse:.2f}\")\nprint(f\"SES RMSE: {ses_rmse:.2f}\")\nprint(f\"\\nHolt captures the trend, SES does not!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holt-Winters Seasonal Method\n",
    "\n",
    "Extends Holt's method to include **seasonality** with three equations:\n",
    "\n",
    "- **Level:** $\\ell_t = \\alpha(X_t - S_{t-s}) + (1-\\alpha)(\\ell_{t-1} + b_{t-1})$\n",
    "- **Trend:** $b_t = \\beta^*(\\ell_t - \\ell_{t-1}) + (1-\\beta^*)b_{t-1}$  \n",
    "- **Seasonal:** $S_t = \\gamma(X_t - \\ell_t) + (1-\\gamma)S_{t-s}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use airline data with train/test split\n",
    "train_airline = airline[:'1958']\n",
    "test_airline = airline['1959':]\n",
    "\n",
    "print(f\"Training: {len(train_airline)} observations ({train_airline.index[0].strftime('%Y-%m')} to {train_airline.index[-1].strftime('%Y-%m')})\")\n",
    "print(f\"Testing: {len(test_airline)} observations ({test_airline.index[0].strftime('%Y-%m')} to {test_airline.index[-1].strftime('%Y-%m')})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Fit different methods\nses = SimpleExpSmoothing(train_airline['Passengers']).fit()\nholt = ExponentialSmoothing(train_airline['Passengers'], trend='add', seasonal=None).fit()\nhw_add = ExponentialSmoothing(train_airline['Passengers'], trend='add', \n                               seasonal='add', seasonal_periods=12).fit()\nhw_mul = ExponentialSmoothing(train_airline['Passengers'], trend='add', \n                               seasonal='mul', seasonal_periods=12).fit()\n\n# Generate forecasts\nh = len(test_airline)\nforecasts = {\n    'SES': ses.forecast(h),\n    'Holt': holt.forecast(h),\n    'HW Additive': hw_add.forecast(h),\n    'HW Multiplicative': hw_mul.forecast(h)\n}\n\n# Plot\nfig, ax = plt.subplots(figsize=(14, 6))\nax.plot(train_airline.index, train_airline['Passengers'], color=COLORS['blue'], \n        linewidth=1.5, label='Training')\nax.plot(test_airline.index, test_airline['Passengers'], color=COLORS['gray'], \n        linewidth=2, label='Actual')\n\ncolors_list = [COLORS['red'], COLORS['orange'], COLORS['green'], '#9C27B0']\nfor (name, fc), color in zip(forecasts.items(), colors_list):\n    ax.plot(test_airline.index, fc, linewidth=1.5, linestyle='--', \n            color=color, label=name)\n\nax.axvline(x=train_airline.index[-1], color='black', linestyle='-', alpha=0.3)\nax.set_xlabel('Date')\nax.set_ylabel('Passengers (thousands)')\nax.set_title('Comparing Exponential Smoothing Methods', fontweight='bold', fontsize=14)\nax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.12), ncol=6, frameon=False)\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate error metrics\n",
    "def mape(actual, forecast):\n",
    "    return np.mean(np.abs((actual - forecast) / actual)) * 100\n",
    "\n",
    "print(\"Forecast Accuracy Comparison:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"{'Method':<20} {'RMSE':>10} {'MAE':>10} {'MAPE':>10}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "actual = test_airline['Passengers'].values\n",
    "for name, fc in forecasts.items():\n",
    "    rmse = np.sqrt(mean_squared_error(actual, fc))\n",
    "    mae = mean_absolute_error(actual, fc)\n",
    "    mape_val = mape(actual, fc)\n",
    "    print(f\"{name:<20} {rmse:>10.2f} {mae:>10.2f} {mape_val:>9.2f}%\")\n",
    "\n",
    "print(\"\\nConclusion: Holt-Winters Multiplicative performs best for seasonal data!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Forecast Evaluation\n",
    "\n",
    "### Error Metrics\n",
    "\n",
    "**Scale-Dependent:**\n",
    "- MAE = $\\frac{1}{n}\\sum|e_t|$\n",
    "- RMSE = $\\sqrt{\\frac{1}{n}\\sum e_t^2}$\n",
    "\n",
    "**Scale-Independent:**\n",
    "- MAPE = $\\frac{100}{n}\\sum\\left|\\frac{e_t}{X_t}\\right|$\n",
    "\n",
    "### Train / Validation / Test Split\n",
    "\n",
    "| Set | Purpose | Usage |\n",
    "|-----|---------|-------|\n",
    "| **Train** | Fit model parameters | 60-80% of data |\n",
    "| **Validation** | Tune hyperparameters, compare models | 10-20% |\n",
    "| **Test** | Final evaluation only | 10-20% |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Residual diagnostics for the best model\nresiduals = test_airline['Passengers'].values - forecasts['HW Multiplicative'].values\n\nfig, axes = plt.subplots(2, 2, figsize=(12, 8))\n\n# Residuals over time\naxes[0, 0].plot(test_airline.index, residuals, color=COLORS['blue'], marker='o', markersize=4, label='Residuals')\naxes[0, 0].axhline(y=0, color='red', linestyle='--')\naxes[0, 0].set_title('Residuals Over Time', fontweight='bold')\naxes[0, 0].set_xlabel('Date')\naxes[0, 0].set_ylabel('Residual')\naxes[0, 0].legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=1, frameon=False)\n\n# Histogram\naxes[0, 1].hist(residuals, bins=10, color=COLORS['blue'], edgecolor='black', alpha=0.7, label='Residuals')\naxes[0, 1].axvline(x=0, color='red', linestyle='--')\naxes[0, 1].set_title('Residual Distribution', fontweight='bold')\naxes[0, 1].set_xlabel('Residual')\naxes[0, 1].set_ylabel('Frequency')\naxes[0, 1].legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=1, frameon=False)\n\n# ACF of residuals\nplot_acf(residuals, ax=axes[1, 0], lags=12, color=COLORS['blue'])\naxes[1, 0].set_title('ACF of Residuals', fontweight='bold')\n\n# Q-Q plot with equal axes\nfrom scipy import stats\n(osm, osr), (slope, intercept, r) = stats.probplot(residuals, dist=\"norm\")\naxes[1, 1].scatter(osm, osr, color=COLORS['blue'], s=30, label='Sample Quantiles')\naxes[1, 1].plot(osm, slope*osm + intercept, color=COLORS['red'], linewidth=2, label='Theoretical Line')\naxes[1, 1].set_title('Q-Q Plot', fontweight='bold')\naxes[1, 1].set_xlabel('Theoretical Quantiles')\naxes[1, 1].set_ylabel('Sample Quantiles')\n# Set equal axis limits based on theoretical quantiles range\nq_range = abs(osm).max() * 1.1\naxes[1, 1].set_xlim(-q_range, q_range)\naxes[1, 1].set_ylim(-q_range * slope + intercept - abs(intercept)*0.5, \n                    q_range * slope + intercept + abs(intercept)*0.5)\naxes[1, 1].legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=2, frameon=False)\n\nplt.tight_layout()\nplt.show()\n\n# Ljung-Box test\nlb_result = acorr_ljungbox(residuals, lags=[6, 12], return_df=True)\nprint(\"\\nLjung-Box Test for Residual Autocorrelation:\")\nprint(lb_result)\nprint(\"\\nIf p-values > 0.05, residuals are not significantly autocorrelated (good!)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Stationarity\n",
    "\n",
    "### Definition\n",
    "\n",
    "A process $\\{X_t\\}$ is **weakly stationary** if:\n",
    "1. $E[X_t] = \\mu$ (constant mean)\n",
    "2. $Var(X_t) = \\sigma^2 < \\infty$ (constant, finite variance)\n",
    "3. $Cov(X_t, X_{t+h}) = \\gamma(h)$ (covariance depends only on lag $h$)\n",
    "\n",
    "### Why Does Stationarity Matter?\n",
    "- Most time series models (ARMA, ARIMA) require stationarity\n",
    "- Non-stationary series must be transformed (differencing) before modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# White Noise Example (Stationary)\nnp.random.seed(42)\nn = 200\nwhite_noise = np.random.randn(n)\n\n# Random Walk Example (Non-Stationary)\nrandom_walk = np.cumsum(white_noise)\n\nfig, axes = plt.subplots(2, 2, figsize=(14, 8))\n\n# White noise\naxes[0, 0].plot(white_noise, color=COLORS['blue'], linewidth=0.8, label='White Noise')\naxes[0, 0].axhline(y=0, color='red', linestyle='--')\naxes[0, 0].set_title('White Noise (Stationary)', fontweight='bold')\naxes[0, 0].set_xlabel('Time')\naxes[0, 0].legend(loc='upper center', bbox_to_anchor=(0.5, -0.12), ncol=1, frameon=False)\n\n# White noise ACF\nplot_acf(white_noise, ax=axes[0, 1], lags=30, color=COLORS['blue'])\naxes[0, 1].set_title('ACF of White Noise', fontweight='bold')\n\n# Random walk\naxes[1, 0].plot(random_walk, color=COLORS['red'], linewidth=0.8, label='Random Walk')\naxes[1, 0].set_title('Random Walk (Non-Stationary)', fontweight='bold')\naxes[1, 0].set_xlabel('Time')\naxes[1, 0].legend(loc='upper center', bbox_to_anchor=(0.5, -0.12), ncol=1, frameon=False)\n\n# Random walk ACF\nplot_acf(random_walk, ax=axes[1, 1], lags=30, color=COLORS['red'])\naxes[1, 1].set_title('ACF of Random Walk', fontweight='bold')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"Key Observation:\")\nprint(\"- White noise ACF: cuts off immediately (no autocorrelation)\")\nprint(\"- Random walk ACF: decays very slowly (persistent autocorrelation)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Walk Properties\n",
    "\n",
    "$X_t = X_{t-1} + \\varepsilon_t$ where $\\varepsilon_t \\sim WN(0, \\sigma^2)$\n",
    "\n",
    "- $E[X_t] = X_0$ (constant)\n",
    "- $Var(X_t) = t\\sigma^2$ (**grows with time!**)\n",
    "- This violates stationarity!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Demonstrate variance growth in random walk\nnp.random.seed(123)\nn_simulations = 100\nn_steps = 200\n\n# Simulate many random walks\nrandom_walks = np.zeros((n_simulations, n_steps))\nfor i in range(n_simulations):\n    random_walks[i, :] = np.cumsum(np.random.randn(n_steps))\n\n# Calculate variance at each time point\nvariances = np.var(random_walks, axis=0)\ntheoretical_var = np.arange(1, n_steps + 1)  # Var(X_t) = t * sigma^2 (sigma=1)\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Multiple random walks\nfor i in range(20):\n    axes[0].plot(random_walks[i, :], alpha=0.3, linewidth=0.8)\naxes[0].axhline(y=0, color='black', linestyle='-', linewidth=1)\naxes[0].set_title('Multiple Random Walk Realizations', fontweight='bold')\naxes[0].set_xlabel('Time (t)')\naxes[0].set_ylabel('$X_t$')\n\n# Variance over time\naxes[1].plot(variances, color=COLORS['blue'], linewidth=2, label='Empirical Variance')\naxes[1].plot(theoretical_var, color=COLORS['red'], linestyle='--', \n             linewidth=2, label='Theoretical: $t\\\\sigma^2$')\naxes[1].set_title('Variance Grows with Time', fontweight='bold')\naxes[1].set_xlabel('Time (t)')\naxes[1].set_ylabel('Variance')\naxes[1].legend(loc='upper center', bbox_to_anchor=(0.5, -0.12), ncol=2, frameon=False)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nRandom Walk is NON-STATIONARY because Var(X_t) = t*σ² depends on t\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Testing for Stationarity\n",
    "\n",
    "### ADF Test (Augmented Dickey-Fuller)\n",
    "- $H_0$: Unit root (non-stationary)\n",
    "- $H_1$: Stationary\n",
    "- Reject $H_0$ if p-value < 0.05 → **Stationary**\n",
    "\n",
    "### KPSS Test\n",
    "- $H_0$: Stationary\n",
    "- $H_1$: Unit root (non-stationary)\n",
    "- Reject $H_0$ if p-value < 0.05 → **Non-stationary**\n",
    "\n",
    "**Use both tests together for robust conclusions!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_stationarity(series, name):\n",
    "    \"\"\"Perform ADF and KPSS tests and report results\"\"\"\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Stationarity Tests for: {name}\")\n",
    "    print('='*50)\n",
    "    \n",
    "    # ADF Test\n",
    "    adf_result = adfuller(series, autolag='AIC')\n",
    "    print(f\"\\nADF Test:\")\n",
    "    print(f\"  Test Statistic: {adf_result[0]:.4f}\")\n",
    "    print(f\"  p-value: {adf_result[1]:.4f}\")\n",
    "    print(f\"  Critical Values:\")\n",
    "    for key, value in adf_result[4].items():\n",
    "        print(f\"    {key}: {value:.4f}\")\n",
    "    \n",
    "    adf_conclusion = \"STATIONARY\" if adf_result[1] < 0.05 else \"NON-STATIONARY\"\n",
    "    print(f\"  Conclusion: {adf_conclusion} (reject H0: unit root)\" if adf_result[1] < 0.05 \n",
    "          else f\"  Conclusion: {adf_conclusion} (fail to reject H0: unit root)\")\n",
    "    \n",
    "    # KPSS Test\n",
    "    kpss_result = kpss(series, regression='c', nlags='auto')\n",
    "    print(f\"\\nKPSS Test:\")\n",
    "    print(f\"  Test Statistic: {kpss_result[0]:.4f}\")\n",
    "    print(f\"  p-value: {kpss_result[1]:.4f}\")\n",
    "    print(f\"  Critical Values:\")\n",
    "    for key, value in kpss_result[3].items():\n",
    "        print(f\"    {key}: {value:.4f}\")\n",
    "    \n",
    "    kpss_conclusion = \"NON-STATIONARY\" if kpss_result[1] < 0.05 else \"STATIONARY\"\n",
    "    print(f\"  Conclusion: {kpss_conclusion} (reject H0: stationary)\" if kpss_result[1] < 0.05 \n",
    "          else f\"  Conclusion: {kpss_conclusion} (fail to reject H0: stationary)\")\n",
    "    \n",
    "    return adf_result[1], kpss_result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test S&P 500 prices\n",
    "prices = sp500['Close'].dropna()\n",
    "test_stationarity(prices, 'S&P 500 Prices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test S&P 500 returns\n",
    "returns = prices.pct_change().dropna() * 100  # percentage returns\n",
    "test_stationarity(returns, 'S&P 500 Returns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Visualize the difference\nfig, axes = plt.subplots(2, 2, figsize=(14, 8))\n\n# Prices\naxes[0, 0].plot(prices.index, prices, color=COLORS['blue'], linewidth=0.8, label='Prices')\naxes[0, 0].set_title('S&P 500 Prices (Non-Stationary)', fontweight='bold')\naxes[0, 0].set_xlabel('Date')\naxes[0, 0].legend(loc='upper center', bbox_to_anchor=(0.5, -0.12), ncol=1, frameon=False)\n\n# Prices ACF\nplot_acf(prices, ax=axes[0, 1], lags=50, color=COLORS['blue'])\naxes[0, 1].set_title('ACF of Prices', fontweight='bold')\n\n# Returns\naxes[1, 0].plot(returns.index, returns, color=COLORS['green'], linewidth=0.5, label='Returns')\naxes[1, 0].axhline(y=0, color='red', linestyle='--')\naxes[1, 0].set_title('S&P 500 Returns (Stationary)', fontweight='bold')\naxes[1, 0].set_xlabel('Date')\naxes[1, 0].legend(loc='upper center', bbox_to_anchor=(0.5, -0.12), ncol=1, frameon=False)\n\n# Returns ACF\nplot_acf(returns, ax=axes[1, 1], lags=50, color=COLORS['green'])\naxes[1, 1].set_title('ACF of Returns', fontweight='bold')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nKey Insight:\")\nprint(\"- Prices are non-stationary (random walk behavior)\")\nprint(\"- Returns (differences) are stationary\")\nprint(\"- This is why we model RETURNS, not prices, in finance!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ACF and PACF\n",
    "\n",
    "### Autocorrelation Function (ACF)\n",
    "$$\\rho(h) = \\frac{\\gamma(h)}{\\gamma(0)} = \\frac{Cov(X_t, X_{t+h})}{Var(X_t)}$$\n",
    "\n",
    "### Partial Autocorrelation Function (PACF)\n",
    "- Correlation between $X_t$ and $X_{t+h}$ after removing the linear effect of intermediate lags\n",
    "- **Key for model identification:**\n",
    "  - AR(p): PACF cuts off after lag p\n",
    "  - MA(q): ACF cuts off after lag q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Simulate AR(1) and MA(1) processes\nnp.random.seed(42)\nn = 500\n\n# AR(1): X_t = 0.7 * X_{t-1} + epsilon_t\nphi = 0.7\nar1 = np.zeros(n)\nfor t in range(1, n):\n    ar1[t] = phi * ar1[t-1] + np.random.randn()\n\n# MA(1): X_t = epsilon_t + 0.7 * epsilon_{t-1}\ntheta = 0.7\nepsilon = np.random.randn(n)\nma1 = np.zeros(n)\nfor t in range(1, n):\n    ma1[t] = epsilon[t] + theta * epsilon[t-1]\n\nfig, axes = plt.subplots(2, 3, figsize=(15, 8))\n\n# AR(1)\naxes[0, 0].plot(ar1, color=COLORS['blue'], linewidth=0.8, label='AR(1)')\naxes[0, 0].set_title('AR(1) Process: $X_t = 0.7X_{t-1} + \\\\varepsilon_t$', fontweight='bold')\naxes[0, 0].legend(loc='upper center', bbox_to_anchor=(0.5, -0.12), ncol=1, frameon=False)\n\nplot_acf(ar1, ax=axes[0, 1], lags=20, color=COLORS['blue'])\naxes[0, 1].set_title('ACF of AR(1) - Decays', fontweight='bold')\n\nplot_pacf(ar1, ax=axes[0, 2], lags=20, color=COLORS['blue'], method='ywm')\naxes[0, 2].set_title('PACF of AR(1) - Cuts off at lag 1', fontweight='bold')\n\n# MA(1)\naxes[1, 0].plot(ma1, color=COLORS['green'], linewidth=0.8, label='MA(1)')\naxes[1, 0].set_title('MA(1) Process: $X_t = \\\\varepsilon_t + 0.7\\\\varepsilon_{t-1}$', fontweight='bold')\naxes[1, 0].legend(loc='upper center', bbox_to_anchor=(0.5, -0.12), ncol=1, frameon=False)\n\nplot_acf(ma1, ax=axes[1, 1], lags=20, color=COLORS['green'])\naxes[1, 1].set_title('ACF of MA(1) - Cuts off at lag 1', fontweight='bold')\n\nplot_pacf(ma1, ax=axes[1, 2], lags=20, color=COLORS['green'], method='ywm')\naxes[1, 2].set_title('PACF of MA(1) - Decays', fontweight='bold')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nModel Identification Rules:\")\nprint(\"-\" * 40)\nprint(\"| Process | ACF          | PACF         |\")\nprint(\"-\" * 40)\nprint(\"| AR(p)   | Decays       | Cuts off @ p |\")\nprint(\"| MA(q)   | Cuts off @ q | Decays       |\")\nprint(\"| ARMA    | Decays       | Decays       |\")\nprint(\"-\" * 40)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Financial Data: Stylized Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Analyze return distribution\nfig, axes = plt.subplots(1, 3, figsize=(15, 4))\n\n# Histogram with normal overlay\nfrom scipy.stats import norm\nmu, std = returns.mean(), returns.std()\nx = np.linspace(returns.min(), returns.max(), 100)\n\naxes[0].hist(returns, bins=50, density=True, color=COLORS['blue'], \n             alpha=0.7, edgecolor='black', linewidth=0.5, label='Returns')\naxes[0].plot(x, norm.pdf(x, mu, std), color=COLORS['red'], linewidth=2, \n             label='Normal Distribution')\naxes[0].set_title('Return Distribution vs Normal', fontweight='bold')\naxes[0].set_xlabel('Return (%)')\naxes[0].legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=2, frameon=False)\n\n# Q-Q plot with appropriate axes\n(osm, osr), (slope, intercept, r) = stats.probplot(returns, dist=\"norm\")\naxes[1].scatter(osm, osr, color=COLORS['blue'], s=10, alpha=0.5, label='Sample Quantiles')\naxes[1].plot(osm, slope*osm + intercept, color=COLORS['red'], linewidth=2, label='Theoretical Line')\naxes[1].set_title('Q-Q Plot (Heavy Tails)', fontweight='bold')\naxes[1].set_xlabel('Theoretical Quantiles')\naxes[1].set_ylabel('Sample Quantiles')\n# Set axis limits based on theoretical quantiles\nq_range = abs(osm).max() * 1.1\naxes[1].set_xlim(-q_range, q_range)\naxes[1].set_ylim(-q_range * slope + intercept - abs(intercept)*0.5, \n                 q_range * slope + intercept + abs(intercept)*0.5)\naxes[1].legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=2, frameon=False)\n\n# Volatility clustering (squared returns)\naxes[2].plot(returns.index, returns**2, color=COLORS['blue'], linewidth=0.5, label='Squared Returns')\naxes[2].set_title('Squared Returns (Volatility Clustering)', fontweight='bold')\naxes[2].set_xlabel('Date')\naxes[2].legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=1, frameon=False)\n\nplt.tight_layout()\nplt.show()\n\n# Statistics\nfrom scipy.stats import skew, kurtosis\nprint(\"\\nStylized Facts of Financial Returns:\")\nprint(f\"  Mean: {mu:.4f}%\")\nprint(f\"  Std Dev: {std:.4f}%\")\nprint(f\"  Skewness: {skew(returns):.4f} (negative = left tail)\")\nprint(f\"  Excess Kurtosis: {kurtosis(returns):.4f} (>0 = heavy tails)\")\nprint(\"\\n  -> Returns are NOT normally distributed!\")\nprint(\"  -> Volatility clusters (large moves follow large moves)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Time series** = observations indexed by time with temporal dependence\n",
    "2. **Decomposition**: Additive vs Multiplicative based on seasonal behavior\n",
    "3. **Exponential Smoothing**: SES (level), Holt (trend), Holt-Winters (seasonal)\n",
    "4. **Forecast Evaluation**: MAE, RMSE, MAPE; proper train/validation/test splits\n",
    "5. **Stationarity**: Constant mean, variance, and autocovariance over time\n",
    "6. **Unit Root Tests**: ADF (H0: unit root) and KPSS (H0: stationary)\n",
    "7. **ACF/PACF**: Essential tools for identifying dependence structure\n",
    "\n",
    "### Next Chapter: ARMA Models\n",
    "- Autoregressive (AR) models\n",
    "- Moving Average (MA) models  \n",
    "- Model identification, estimation, and forecasting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}