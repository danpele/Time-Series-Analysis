{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/danpele/Time-Series-Analysis/blob/main/chapter3_lecture_notebook.ipynb)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3: ARIMA Models for Non-Stationary Data\n",
    "\n",
    "**Course:** Time Series Analysis and Forecasting  \n",
    "**Program:** Bachelor program, Faculty of Cybernetics, Statistics and Economic Informatics, Bucharest University of Economic Studies, Romania  \n",
    "**Academic Year:** 2025-2026\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "1. Understand non-stationarity and its implications\n",
    "2. Distinguish between deterministic and stochastic trends\n",
    "3. Apply differencing to achieve stationarity\n",
    "4. Perform unit root tests (ADF, KPSS)\n",
    "5. Fit and interpret ARIMA(p,d,q) models\n",
    "6. Generate forecasts with ARIMA models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Time series specific\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.stattools import adfuller, kpss, acf, pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from scipy import stats\n",
    "\n",
    "# Plotting style - clean, professional\n",
    "plt.rcParams['figure.figsize'] = (12, 5)\n",
    "plt.rcParams['font.size'] = 11\n",
    "plt.rcParams['axes.facecolor'] = 'none'\n",
    "plt.rcParams['figure.facecolor'] = 'none'\n",
    "plt.rcParams['savefig.facecolor'] = 'none'\n",
    "plt.rcParams['axes.grid'] = False\n",
    "plt.rcParams['axes.spines.top'] = False\n",
    "plt.rcParams['axes.spines.right'] = False\n",
    "\n",
    "# Colors (IDA color scheme)\n",
    "COLORS = {\n",
    "    'blue': '#1A3A6E',\n",
    "    'red': '#DC3545',\n",
    "    'green': '#2E7D32',\n",
    "    'orange': '#E67E22',\n",
    "    'gray': '#666666'\n",
    "}\n",
    "\n",
    "print(\"All libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Non-Stationarity in Time Series\n",
    "\n",
    "Many economic and financial time series are **non-stationary**:\n",
    "- GDP, stock prices, exchange rates\n",
    "- They exhibit trends, changing means, or growing variance\n",
    "\n",
    "### Why Does It Matter?\n",
    "- Standard ARMA models assume stationarity\n",
    "- Regression with non-stationary data leads to **spurious results**\n",
    "- Statistical inference becomes invalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Simulating different types of non-stationarity\n",
    "np.random.seed(42)\n",
    "n = 200\n",
    "t = np.arange(n)\n",
    "\n",
    "# 1. Stationary process (AR(1))\n",
    "stationary = np.zeros(n)\n",
    "for i in range(1, n):\n",
    "    stationary[i] = 0.7 * stationary[i-1] + np.random.randn()\n",
    "\n",
    "# 2. Deterministic trend\n",
    "det_trend = 0.5 + 0.1 * t + np.random.randn(n)\n",
    "\n",
    "# 3. Random walk (stochastic trend)\n",
    "random_walk = np.cumsum(np.random.randn(n))\n",
    "\n",
    "# 4. Random walk with drift\n",
    "rw_drift = np.cumsum(0.2 + np.random.randn(n))\n",
    "\n",
    "# Plot all four\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 8))\n",
    "\n",
    "processes = [\n",
    "    (stationary, 'Stationary AR(1)', COLORS['blue']),\n",
    "    (det_trend, 'Deterministic Trend', COLORS['green']),\n",
    "    (random_walk, 'Random Walk (Stochastic Trend)', COLORS['red']),\n",
    "    (rw_drift, 'Random Walk with Drift', COLORS['orange'])\n",
    "]\n",
    "\n",
    "for ax, (data, title, color) in zip(axes.flatten(), processes):\n",
    "    ax.plot(data, color=color, linewidth=1, label=title)\n",
    "    ax.set_title(title, fontweight='bold')\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.12), frameon=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Key observation: Non-stationary series have time-varying properties\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The Random Walk Process\n",
    "\n",
    "A **random walk** is the simplest non-stationary process:\n",
    "\n",
    "$$Y_t = Y_{t-1} + \\varepsilon_t, \\quad \\varepsilon_t \\sim WN(0, \\sigma^2)$$\n",
    "\n",
    "### Properties\n",
    "- $E[Y_t] = Y_0$ (constant mean)\n",
    "- $Var(Y_t) = t\\sigma^2$ (variance grows with time!)\n",
    "- Shocks have **permanent effects**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate growing variance of random walk\n",
    "np.random.seed(123)\n",
    "n_sims = 100\n",
    "n_periods = 200\n",
    "\n",
    "# Simulate many random walks\n",
    "random_walks = np.zeros((n_sims, n_periods))\n",
    "for i in range(n_sims):\n",
    "    random_walks[i] = np.cumsum(np.random.randn(n_periods))\n",
    "\n",
    "# Calculate variance at each time point\n",
    "empirical_var = np.var(random_walks, axis=0)\n",
    "theoretical_var = np.arange(1, n_periods + 1)  # t * sigma^2 with sigma^2 = 1\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot sample paths\n",
    "for i in range(20):\n",
    "    axes[0].plot(random_walks[i], alpha=0.3, linewidth=0.8)\n",
    "axes[0].set_title('Random Walk Sample Paths', fontweight='bold')\n",
    "axes[0].set_xlabel('Time')\n",
    "axes[0].set_ylabel('Value')\n",
    "\n",
    "# Plot variance growth\n",
    "axes[1].plot(empirical_var, color=COLORS['blue'], linewidth=2, label='Empirical Variance')\n",
    "axes[1].plot(theoretical_var, color=COLORS['red'], linestyle='--', linewidth=2, label='Theoretical: t·σ²')\n",
    "axes[1].set_title('Variance Grows Linearly with Time', fontweight='bold')\n",
    "axes[1].set_xlabel('Time')\n",
    "axes[1].set_ylabel('Variance')\n",
    "axes[1].legend(loc='upper center', bbox_to_anchor=(0.5, -0.12), ncol=2, frameon=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Variance at t=50: Empirical={empirical_var[49]:.2f}, Theoretical=50.00\")\n",
    "print(f\"Variance at t=200: Empirical={empirical_var[199]:.2f}, Theoretical=200.00\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Integrated Processes\n",
    "\n",
    "A time series $Y_t$ is **integrated of order d**, written $Y_t \\sim I(d)$, if:\n",
    "- $Y_t$ is non-stationary\n",
    "- $\\Delta^d Y_t = (1-L)^d Y_t$ is stationary\n",
    "\n",
    "### Common Cases\n",
    "- **I(0)**: Stationary (ARMA)\n",
    "- **I(1)**: First difference is stationary (most common for economic data)\n",
    "- **I(2)**: Second difference is stationary (rare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show how differencing makes random walk stationary\n",
    "np.random.seed(42)\n",
    "n = 300\n",
    "\n",
    "# Generate random walk (I(1) process)\n",
    "eps = np.random.randn(n)\n",
    "random_walk = np.cumsum(eps)\n",
    "\n",
    "# First difference\n",
    "diff1 = np.diff(random_walk)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 8))\n",
    "\n",
    "# Original series\n",
    "axes[0, 0].plot(random_walk, color=COLORS['blue'], linewidth=1, label='Random Walk')\n",
    "axes[0, 0].set_title('Original: Random Walk Y_t (Non-stationary)', fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Time')\n",
    "axes[0, 0].legend(loc='upper center', bbox_to_anchor=(0.5, -0.12), frameon=False)\n",
    "\n",
    "# ACF of original\n",
    "plot_acf(random_walk, ax=axes[0, 1], lags=30, color=COLORS['blue'])\n",
    "axes[0, 1].set_title('ACF of Y_t (Slow decay = Non-stationary)', fontweight='bold')\n",
    "\n",
    "# Differenced series\n",
    "axes[1, 0].plot(diff1, color=COLORS['green'], linewidth=1, label='ΔY_t')\n",
    "axes[1, 0].axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "axes[1, 0].set_title('First Difference: ΔY_t = ε_t (Stationary!)', fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Time')\n",
    "axes[1, 0].legend(loc='upper center', bbox_to_anchor=(0.5, -0.12), frameon=False)\n",
    "\n",
    "# ACF of differenced\n",
    "plot_acf(diff1, ax=axes[1, 1], lags=30, color=COLORS['green'])\n",
    "axes[1, 1].set_title('ACF of ΔY_t (White noise = Stationary)', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey insight: One difference transforms I(1) to I(0)\")\n",
    "print(f\"ΔY_t = Y_t - Y_{'{t-1}'} = ε_t (white noise)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. The Difference Operator\n",
    "\n",
    "### First Difference\n",
    "$$\\Delta Y_t = Y_t - Y_{t-1} = (1-L)Y_t$$\n",
    "\n",
    "### Second Difference\n",
    "$$\\Delta^2 Y_t = \\Delta(\\Delta Y_t) = (1-L)^2 Y_t = Y_t - 2Y_{t-1} + Y_{t-2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate difference operators\n",
    "Y = pd.Series([100, 102, 105, 103, 108, 112, 110, 115])\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Y_t': Y,\n",
    "    'ΔY_t = Y_t - Y_{t-1}': Y.diff(1),\n",
    "    'Δ²Y_t': Y.diff(1).diff(1)\n",
    "})\n",
    "\n",
    "print(\"Differencing Examples:\")\n",
    "print(\"=\" * 60)\n",
    "print(df.to_string())\n",
    "print(\"\\nNote: Each difference loses one observation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Unit Root Tests\n",
    "\n",
    "### Augmented Dickey-Fuller (ADF) Test\n",
    "- $H_0$: Unit root exists (non-stationary)\n",
    "- $H_1$: No unit root (stationary)\n",
    "- Reject $H_0$ if test statistic < critical value (more negative)\n",
    "\n",
    "### KPSS Test\n",
    "- $H_0$: Series is stationary\n",
    "- $H_1$: Series has unit root\n",
    "- Opposite null hypothesis to ADF!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_unit_root_tests(series, name):\n",
    "    \"\"\"Run ADF and KPSS tests and print results.\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Unit Root Tests for: {name}\")\n",
    "    print('='*60)\n",
    "    \n",
    "    # ADF Test\n",
    "    adf_result = adfuller(series, autolag='AIC')\n",
    "    print(f\"\\nADF Test (H0: Unit root exists)\")\n",
    "    print(f\"  Test Statistic: {adf_result[0]:.4f}\")\n",
    "    print(f\"  p-value: {adf_result[1]:.6f}\")\n",
    "    print(f\"  Critical Values:\")\n",
    "    for key, value in adf_result[4].items():\n",
    "        print(f\"    {key}: {value:.4f}\")\n",
    "    adf_conclusion = \"STATIONARY\" if adf_result[1] < 0.05 else \"NON-STATIONARY\"\n",
    "    print(f\"  Conclusion: {adf_conclusion}\")\n",
    "    \n",
    "    # KPSS Test\n",
    "    kpss_result = kpss(series, regression='c', nlags='auto')\n",
    "    print(f\"\\nKPSS Test (H0: Series is stationary)\")\n",
    "    print(f\"  Test Statistic: {kpss_result[0]:.4f}\")\n",
    "    print(f\"  p-value: {kpss_result[1]:.4f}\")\n",
    "    print(f\"  Critical Values:\")\n",
    "    for key, value in kpss_result[3].items():\n",
    "        print(f\"    {key}: {value:.4f}\")\n",
    "    kpss_conclusion = \"STATIONARY\" if kpss_result[1] > 0.05 else \"NON-STATIONARY\"\n",
    "    print(f\"  Conclusion: {kpss_conclusion}\")\n",
    "    \n",
    "    return adf_conclusion, kpss_conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test our simulated series\n",
    "np.random.seed(42)\n",
    "n = 300\n",
    "\n",
    "# Stationary AR(1)\n",
    "ar1 = np.zeros(n)\n",
    "for i in range(1, n):\n",
    "    ar1[i] = 0.7 * ar1[i-1] + np.random.randn()\n",
    "\n",
    "# Random walk\n",
    "rw = np.cumsum(np.random.randn(n))\n",
    "\n",
    "# Test stationary series\n",
    "run_unit_root_tests(ar1, \"Stationary AR(1)\")\n",
    "\n",
    "# Test random walk\n",
    "run_unit_root_tests(rw, \"Random Walk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the differenced random walk\n",
    "rw_diff = np.diff(rw)\n",
    "run_unit_root_tests(rw_diff, \"Differenced Random Walk (ΔY_t)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Summary: Random walk is I(1) - one difference makes it stationary\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ARIMA(p,d,q) Models\n",
    "\n",
    "An **ARIMA(p,d,q)** model combines:\n",
    "- **AR(p)**: Autoregressive component\n",
    "- **I(d)**: Integration (differencing)\n",
    "- **MA(q)**: Moving average component\n",
    "\n",
    "$$\\phi(L)(1-L)^d Y_t = c + \\theta(L)\\varepsilon_t$$\n",
    "\n",
    "### Special Cases\n",
    "- ARIMA(p,0,q) = ARMA(p,q)\n",
    "- ARIMA(0,1,0) = Random walk\n",
    "- ARIMA(0,1,1) = Simple exponential smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate ARIMA(1,1,1) process\n",
    "np.random.seed(42)\n",
    "n = 300\n",
    "phi, theta = 0.6, 0.4\n",
    "\n",
    "# Generate ARIMA(1,1,1)\n",
    "# First generate ARMA(1,1) for the differences\n",
    "eps = np.random.randn(n)\n",
    "diff_y = np.zeros(n)\n",
    "for t in range(1, n):\n",
    "    diff_y[t] = phi * diff_y[t-1] + eps[t] + theta * eps[t-1]\n",
    "\n",
    "# Cumulative sum to get I(1) series\n",
    "y_arima = np.cumsum(diff_y)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 8))\n",
    "\n",
    "# Original series\n",
    "axes[0, 0].plot(y_arima, color=COLORS['blue'], linewidth=1, label='ARIMA(1,1,1)')\n",
    "axes[0, 0].set_title('ARIMA(1,1,1) Process (Non-stationary)', fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Time')\n",
    "axes[0, 0].legend(loc='upper center', bbox_to_anchor=(0.5, -0.12), frameon=False)\n",
    "\n",
    "# ACF of original\n",
    "plot_acf(y_arima, ax=axes[0, 1], lags=30, color=COLORS['blue'])\n",
    "axes[0, 1].set_title('ACF of Y_t (Slow decay)', fontweight='bold')\n",
    "\n",
    "# Differenced series\n",
    "axes[1, 0].plot(diff_y, color=COLORS['green'], linewidth=1, label='ΔY_t')\n",
    "axes[1, 0].axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "axes[1, 0].set_title('First Difference ΔY_t ~ ARMA(1,1)', fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Time')\n",
    "axes[1, 0].legend(loc='upper center', bbox_to_anchor=(0.5, -0.12), frameon=False)\n",
    "\n",
    "# ACF of differenced\n",
    "plot_acf(diff_y, ax=axes[1, 1], lags=30, color=COLORS['green'])\n",
    "axes[1, 1].set_title('ACF of ΔY_t (Stationary pattern)', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"True parameters: φ = {phi}, θ = {theta}, d = 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ARIMA Model Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit ARIMA(1,1,1) to our simulated data\n",
    "model = ARIMA(y_arima, order=(1, 1, 1))\n",
    "results = model.fit()\n",
    "\n",
    "print(\"ARIMA(1,1,1) Estimation Results\")\n",
    "print(\"=\" * 60)\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare estimated vs true parameters\n",
    "print(\"\\nParameter Comparison:\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"{'Parameter':<15} {'True':>10} {'Estimated':>12}\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"{'AR(1) φ':<15} {phi:>10.4f} {results.arparams[0]:>12.4f}\")\n",
    "print(f\"{'MA(1) θ':<15} {theta:>10.4f} {results.maparams[0]:>12.4f}\")\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Selection: Determining p, d, q\n",
    "\n",
    "### Step 1: Determine d\n",
    "- Use unit root tests (ADF, KPSS)\n",
    "- Difference until stationary\n",
    "- Typically d = 1 for economic data\n",
    "\n",
    "### Step 2: Determine p and q\n",
    "- Examine ACF/PACF of differenced series\n",
    "- Use information criteria (AIC, BIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model selection using information criteria\n",
    "print(\"Model Comparison (comparing different ARIMA specifications):\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Model':<20} {'AIC':>12} {'BIC':>12}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "orders = [\n",
    "    (0, 1, 0),  # Random walk\n",
    "    (1, 1, 0),  # ARI(1,1)\n",
    "    (0, 1, 1),  # IMA(1,1)\n",
    "    (1, 1, 1),  # ARIMA(1,1,1)\n",
    "    (2, 1, 0),  # ARI(2,1)\n",
    "    (0, 1, 2),  # IMA(2,1)\n",
    "    (2, 1, 1),  # ARIMA(2,1,1)\n",
    "]\n",
    "\n",
    "best_aic = float('inf')\n",
    "best_bic = float('inf')\n",
    "best_model_aic = None\n",
    "best_model_bic = None\n",
    "\n",
    "for order in orders:\n",
    "    try:\n",
    "        model = ARIMA(y_arima, order=order)\n",
    "        res = model.fit()\n",
    "        model_name = f\"ARIMA{order}\"\n",
    "        print(f\"{model_name:<20} {res.aic:>12.2f} {res.bic:>12.2f}\")\n",
    "        \n",
    "        if res.aic < best_aic:\n",
    "            best_aic = res.aic\n",
    "            best_model_aic = model_name\n",
    "        if res.bic < best_bic:\n",
    "            best_bic = res.bic\n",
    "            best_model_bic = model_name\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(f\"Best by AIC: {best_model_aic}\")\n",
    "print(f\"Best by BIC: {best_model_bic}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Auto-ARIMA\n",
    "\n",
    "Modern software can automatically select the best ARIMA model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install pmdarima if not available\n",
    "try:\n",
    "    import pmdarima as pm\n",
    "    print(\"pmdarima is available\")\n",
    "except ImportError:\n",
    "    print(\"Installing pmdarima...\")\n",
    "    !pip install pmdarima -q\n",
    "    import pmdarima as pm\n",
    "    print(\"pmdarima installed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use auto_arima to find best model\n",
    "import pmdarima as pm\n",
    "\n",
    "auto_model = pm.auto_arima(\n",
    "    y_arima,\n",
    "    start_p=0, start_q=0,\n",
    "    max_p=3, max_q=3,\n",
    "    d=None,  # Let auto_arima determine d\n",
    "    seasonal=False,\n",
    "    stepwise=True,\n",
    "    suppress_warnings=True,\n",
    "    trace=True\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Auto-ARIMA Selected Model:\")\n",
    "print(\"=\"*60)\n",
    "print(auto_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Diagnostic Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get residuals from our fitted model\n",
    "residuals = results.resid\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 8))\n",
    "\n",
    "# Residuals over time\n",
    "axes[0, 0].plot(residuals, color=COLORS['blue'], linewidth=0.5, label='Residuals')\n",
    "axes[0, 0].axhline(y=0, color='red', linestyle='--')\n",
    "axes[0, 0].set_title('Residuals Over Time', fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Time')\n",
    "axes[0, 0].legend(loc='upper center', bbox_to_anchor=(0.5, -0.12), frameon=False)\n",
    "\n",
    "# Histogram\n",
    "axes[0, 1].hist(residuals, bins=30, color=COLORS['blue'], edgecolor='black', \n",
    "                alpha=0.7, density=True, label='Residuals')\n",
    "x = np.linspace(residuals.min(), residuals.max(), 100)\n",
    "axes[0, 1].plot(x, stats.norm.pdf(x, residuals.mean(), residuals.std()), \n",
    "                color=COLORS['red'], linewidth=2, label='Normal')\n",
    "axes[0, 1].set_title('Residual Distribution', fontweight='bold')\n",
    "axes[0, 1].legend(loc='upper center', bbox_to_anchor=(0.5, -0.12), ncol=2, frameon=False)\n",
    "\n",
    "# ACF of residuals\n",
    "plot_acf(residuals, ax=axes[1, 0], lags=20, color=COLORS['blue'])\n",
    "axes[1, 0].set_title('ACF of Residuals', fontweight='bold')\n",
    "\n",
    "# Q-Q plot\n",
    "(osm, osr), (slope, intercept, r) = stats.probplot(residuals, dist=\"norm\")\n",
    "axes[1, 1].scatter(osm, osr, color=COLORS['blue'], s=20, alpha=0.5, label='Sample')\n",
    "axes[1, 1].plot(osm, slope*osm + intercept, color=COLORS['red'], linewidth=2, label='Theoretical')\n",
    "axes[1, 1].set_title('Q-Q Plot', fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Theoretical Quantiles')\n",
    "axes[1, 1].set_ylabel('Sample Quantiles')\n",
    "axes[1, 1].legend(loc='upper center', bbox_to_anchor=(0.5, -0.12), ncol=2, frameon=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ljung-Box test\n",
    "lb_test = acorr_ljungbox(residuals, lags=[10, 20, 30], return_df=True)\n",
    "print(\"Ljung-Box Test for Residual Autocorrelation:\")\n",
    "print(\"=\"*50)\n",
    "print(lb_test)\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"If all p-values > 0.05, residuals are white noise (model is adequate)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Forecasting with ARIMA\n",
    "\n",
    "Key property for I(1) series: **Forecast intervals grow with horizon**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate forecasts\n",
    "forecast_steps = 50\n",
    "forecast = results.get_forecast(steps=forecast_steps)\n",
    "forecast_mean = forecast.predicted_mean\n",
    "forecast_ci = forecast.conf_int()\n",
    "\n",
    "# Handle both DataFrame and numpy array formats\n",
    "if hasattr(forecast_ci, 'iloc'):\n",
    "    ci_lower = forecast_ci.iloc[:, 0]\n",
    "    ci_upper = forecast_ci.iloc[:, 1]\n",
    "else:\n",
    "    ci_lower = forecast_ci[:, 0]\n",
    "    ci_upper = forecast_ci[:, 1]\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "# Historical data (last 100 points)\n",
    "ax.plot(range(200, 300), y_arima[200:], color=COLORS['blue'], linewidth=1, label='Historical')\n",
    "\n",
    "# Forecasts\n",
    "forecast_index = range(300, 300 + forecast_steps)\n",
    "ax.plot(forecast_index, forecast_mean, color=COLORS['red'], linewidth=2, label='Forecast')\n",
    "\n",
    "# Confidence interval\n",
    "ax.fill_between(forecast_index, ci_lower, ci_upper,\n",
    "                color=COLORS['red'], alpha=0.2, label='95% CI')\n",
    "\n",
    "ax.axvline(x=300, color='black', linestyle='-', alpha=0.3)\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Value')\n",
    "ax.set_title('ARIMA(1,1,1) Forecasts with 95% Confidence Interval', fontweight='bold')\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.1), ncol=4, frameon=False)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# CI width analysis\n",
    "if hasattr(ci_upper, 'iloc'):\n",
    "    ci_width = ci_upper.iloc[-1] - ci_lower.iloc[-1]\n",
    "    ci_width_1 = ci_upper.iloc[0] - ci_lower.iloc[0]\n",
    "else:\n",
    "    ci_width = ci_upper[-1] - ci_lower[-1]\n",
    "    ci_width_1 = ci_upper[0] - ci_lower[0]\n",
    "\n",
    "print(f\"\\nForecast Properties:\")\n",
    "print(f\"- 95% CI width at h=1: {ci_width_1:.4f}\")\n",
    "print(f\"- 95% CI width at h={forecast_steps}: {ci_width:.4f}\")\n",
    "print(f\"- CI grows because I(1) processes have unbounded forecast variance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Real Data Example: GDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load US GDP data from FRED\n",
    "import pandas_datareader as pdr\n",
    "\n",
    "try:\n",
    "    # Try to load GDP data\n",
    "    gdp = pdr.get_data_fred('GDP', start='1990-01-01', end='2024-12-31')\n",
    "    gdp = gdp.dropna()\n",
    "    print(f\"US GDP Data: {len(gdp)} quarterly observations\")\n",
    "    print(f\"Period: {gdp.index[0].date()} to {gdp.index[-1].date()}\")\n",
    "except:\n",
    "    # If FRED not available, simulate GDP-like data\n",
    "    print(\"Note: Using simulated GDP data (FRED not available)\")\n",
    "    np.random.seed(42)\n",
    "    n = 140  # ~35 years quarterly\n",
    "    gdp_growth = 0.007 + 0.005 * np.random.randn(n)  # ~2.8% annual growth\n",
    "    gdp_values = 8000 * np.exp(np.cumsum(gdp_growth))  # Starting around $8T in 1990\n",
    "    dates = pd.date_range('1990-01-01', periods=n, freq='QE')\n",
    "    gdp = pd.DataFrame({'GDP': gdp_values}, index=dates)\n",
    "    print(f\"Simulated GDP: {len(gdp)} observations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot GDP and log GDP\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# GDP level\n",
    "gdp_values = gdp.values.flatten() if hasattr(gdp, 'values') else gdp\n",
    "axes[0].plot(gdp.index, gdp_values, color=COLORS['blue'], linewidth=1, label='GDP')\n",
    "axes[0].set_title('US GDP (Billions of $)', fontweight='bold')\n",
    "axes[0].set_xlabel('Date')\n",
    "axes[0].legend(loc='upper center', bbox_to_anchor=(0.5, -0.12), frameon=False)\n",
    "\n",
    "# Log GDP\n",
    "log_gdp = np.log(gdp_values)\n",
    "axes[1].plot(gdp.index, log_gdp, color=COLORS['green'], linewidth=1, label='Log GDP')\n",
    "axes[1].set_title('Log GDP (for modeling)', fontweight='bold')\n",
    "axes[1].set_xlabel('Date')\n",
    "axes[1].legend(loc='upper center', bbox_to_anchor=(0.5, -0.12), frameon=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unit root tests on log GDP\n",
    "log_gdp_clean = log_gdp[~np.isnan(log_gdp)]\n",
    "run_unit_root_tests(log_gdp_clean, \"Log GDP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on GDP growth (first difference of log GDP)\n",
    "gdp_growth = np.diff(log_gdp_clean)\n",
    "run_unit_root_tests(gdp_growth, \"GDP Growth (Δ log GDP)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit ARIMA model to log GDP\n",
    "import pmdarima as pm\n",
    "\n",
    "auto_gdp = pm.auto_arima(\n",
    "    log_gdp_clean,\n",
    "    start_p=0, start_q=0,\n",
    "    max_p=3, max_q=3,\n",
    "    d=None,\n",
    "    seasonal=False,\n",
    "    stepwise=True,\n",
    "    suppress_warnings=True,\n",
    "    trace=True\n",
    ")\n",
    "\n",
    "print(\"\\nBest ARIMA model for log GDP:\")\n",
    "print(auto_gdp.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast GDP\n",
    "forecast_periods = 12  # 3 years quarterly\n",
    "fc, conf_int = auto_gdp.predict(n_periods=forecast_periods, return_conf_int=True)\n",
    "\n",
    "# Convert back from log\n",
    "gdp_forecast = np.exp(fc)\n",
    "gdp_ci_lower = np.exp(conf_int[:, 0])\n",
    "gdp_ci_upper = np.exp(conf_int[:, 1])\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "# Historical\n",
    "ax.plot(gdp.index[-40:], gdp_values[-40:], color=COLORS['blue'], linewidth=1.5, label='Historical GDP')\n",
    "\n",
    "# Forecast dates\n",
    "last_date = gdp.index[-1]\n",
    "forecast_dates = pd.date_range(start=last_date, periods=forecast_periods+1, freq='QE')[1:]\n",
    "\n",
    "ax.plot(forecast_dates, gdp_forecast, color=COLORS['red'], linewidth=2, label='Forecast')\n",
    "ax.fill_between(forecast_dates, gdp_ci_lower, gdp_ci_upper,\n",
    "                color=COLORS['red'], alpha=0.2, label='95% CI')\n",
    "\n",
    "ax.axvline(x=last_date, color='black', linestyle='-', alpha=0.3)\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('GDP (Billions $)')\n",
    "ax.set_title('US GDP Forecast with ARIMA', fontweight='bold')\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.1), ncol=3, frameon=False)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Non-stationarity** is common in economic data\n",
    "   - Random walk: $Y_t = Y_{t-1} + \\varepsilon_t$\n",
    "   - Variance grows with time\n",
    "\n",
    "2. **Differencing** transforms I(d) to I(0)\n",
    "   - $\\Delta Y_t = Y_t - Y_{t-1}$\n",
    "   - Usually d=1 for economic data\n",
    "\n",
    "3. **Unit root tests** determine d\n",
    "   - ADF: H₀ = unit root\n",
    "   - KPSS: H₀ = stationary\n",
    "\n",
    "4. **ARIMA(p,d,q)** combines differencing with ARMA\n",
    "   - Use AIC/BIC for model selection\n",
    "   - Auto-ARIMA automates the process\n",
    "\n",
    "5. **Forecasts** for I(1) processes have growing uncertainty\n",
    "\n",
    "### Next Chapter\n",
    "- Seasonal ARIMA (SARIMA) models\n",
    "- Seasonal differencing\n",
    "- Forecasting with seasonality"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
