{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/danpele/Time-Series-Analysis/blob/main/chapter10_lecture_notebook.ipynb)\n\n---",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Chapter 10: Comprehensive Review\n\n**Complete Time Series Analysis with Real Data**\n\n**Course:** Time Series Analysis and Forecasting  \n**Program:** Bachelor program, Faculty of Cybernetics, Statistics and Economic Informatics, Bucharest University of Economic Studies, Romania  \n**Academic Year:** 2025-2026\n\n---\n\n## Learning Objectives\n\nThis comprehensive review demonstrates the complete time series analysis workflow using **real data**:\n\n1. **Case Study 1: Bitcoin** - Cryptocurrency volatility analysis with ARIMA-GARCH\n2. **Case Study 2: Sunspots** - Long-cycle seasonal data (11-year Schwabe cycle)\n3. **Case Study 3: US Unemployment** - Economic data with COVID-19 structural break\n\nWe will apply ALL methods covered in the course:\n- Stationarity testing (ADF, KPSS)\n- ARIMA/SARIMA modeling\n- GARCH for volatility clustering\n- Prophet with changepoint detection\n- Fourier terms for long seasonality\n- Model comparison and evaluation",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Setup and Imports",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Install required packages (for Colab)\nimport sys\nif 'google.colab' in sys.modules:\n    !pip install prophet arch statsmodels yfinance pandas-datareader -q\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Statistical tests and models\nfrom statsmodels.tsa.stattools import adfuller, kpss\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfrom statsmodels.tsa.arima.model import ARIMA\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom statsmodels.tsa.seasonal import seasonal_decompose\n\n# GARCH\ntry:\n    from arch import arch_model\n    HAS_ARCH = True\nexcept ImportError:\n    HAS_ARCH = False\n    print(\"arch not installed. Install with: pip install arch\")\n\n# Prophet\ntry:\n    from prophet import Prophet\n    HAS_PROPHET = True\nexcept ImportError:\n    HAS_PROPHET = False\n    print(\"Prophet not installed. Install with: pip install prophet\")\n\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\n\n# Plotting style - CONSISTENT WITH OTHER CHAPTERS\nplt.rcParams['figure.figsize'] = (12, 5)\nplt.rcParams['font.size'] = 11\nplt.rcParams['axes.facecolor'] = 'none'\nplt.rcParams['figure.facecolor'] = 'none'\nplt.rcParams['axes.grid'] = False\nplt.rcParams['axes.spines.top'] = False\nplt.rcParams['axes.spines.right'] = False\nplt.rcParams['legend.frameon'] = False\n\nCOLORS = {'blue': '#1A3A6E', 'red': '#DC3545', 'green': '#2E7D32', 'orange': '#E67E22', 'gray': '#666666'}\n\nprint(\"Setup complete!\")\nprint(f\"ARCH/GARCH available: {HAS_ARCH}\")\nprint(f\"Prophet available: {HAS_PROPHET}\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Real Data Loading Functions\n\nWe use actual data from reliable sources:\n- **Bitcoin**: Yahoo Finance via `yfinance`\n- **Sunspots**: Classic dataset from `statsmodels`\n- **US Unemployment**: Federal Reserve Economic Data (FRED)",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def get_bitcoin_data():\n    \"\"\"Fetch REAL Bitcoin daily prices from Yahoo Finance (2019-2024)\"\"\"\n    try:\n        import yfinance as yf\n        btc = yf.download('BTC-USD', start='2019-01-01', end='2024-01-01', progress=False)\n        df = pd.DataFrame({\n            'ds': btc.index,\n            'price': btc['Close'].values\n        }).reset_index(drop=True)\n        df['returns'] = df['price'].pct_change() * 100\n        print(f\"Bitcoin: Loaded {len(df)} days of REAL data from Yahoo Finance\")\n        return df\n    except Exception as e:\n        print(f\"Could not load Bitcoin data: {e}\")\n        print(\"Using backup simulated data...\")\n        # Fallback to simulated data\n        np.random.seed(42)\n        dates = pd.date_range('2019-01-01', '2024-01-01', freq='D')\n        price = 3700\n        prices = [price]\n        for i in range(1, len(dates)):\n            date = dates[i]\n            if date < pd.Timestamp('2020-03-01'):\n                drift, vol = 0.001, 0.03\n            elif date < pd.Timestamp('2020-04-01'):\n                drift, vol = -0.02, 0.08\n            elif date < pd.Timestamp('2021-11-01'):\n                drift, vol = 0.003, 0.04\n            elif date < pd.Timestamp('2023-01-01'):\n                drift, vol = -0.002, 0.045\n            else:\n                drift, vol = 0.0015, 0.025\n            ret = drift + vol * np.random.randn()\n            price = max(prices[-1] * (1 + ret), 1000)\n            prices.append(price)\n        df = pd.DataFrame({'ds': dates, 'price': prices})\n        df['returns'] = df['price'].pct_change() * 100\n        return df\n\n\ndef get_sunspot_data():\n    \"\"\"Fetch REAL monthly sunspot numbers from statsmodels (1749-present)\"\"\"\n    try:\n        import statsmodels.api as sm\n        sunspots = sm.datasets.sunspots.load_pandas().data\n        # Use data from 1900 onwards for cleaner analysis\n        sunspots = sunspots[sunspots['YEAR'] >= 1900].copy()\n        # Create proper date index (yearly data)\n        sunspots['ds'] = pd.to_datetime(sunspots['YEAR'].astype(int), format='%Y')\n        sunspots = sunspots.rename(columns={'SUNACTIVITY': 'y'})\n        sunspots = sunspots[['ds', 'y']].reset_index(drop=True)\n        print(f\"Sunspots: Loaded {len(sunspots)} years of REAL data from statsmodels\")\n        return sunspots\n    except Exception as e:\n        print(f\"Could not load sunspot data: {e}\")\n        print(\"Using backup simulated data...\")\n        np.random.seed(123)\n        dates = pd.date_range('1900-01-01', '2023-12-01', freq='YS')\n        cycle_period = 11  # 11-year cycle\n        sunspots = []\n        for i in range(len(dates)):\n            phase = (i % cycle_period) / cycle_period\n            cycle_value = 150 * np.sin(np.pi * phase) ** 1.5\n            cycle_num = i // cycle_period\n            cycle_amplitude = [1.0, 0.8, 1.1, 0.9, 1.2, 0.7, 1.0, 0.85, 1.15, 0.95, 1.1][cycle_num % 11]\n            cycle_value *= cycle_amplitude\n            noise = np.random.normal(0, 15)\n            sunspots.append(max(0, cycle_value + noise))\n        return pd.DataFrame({'ds': dates, 'y': sunspots})\n\n\ndef get_unemployment_data():\n    \"\"\"Fetch REAL US Unemployment Rate from FRED (2015-2023)\"\"\"\n    try:\n        import pandas_datareader as pdr\n        unemp = pdr.get_data_fred('UNRATE', start='2015-01-01', end='2023-12-31')\n        df = pd.DataFrame({\n            'ds': unemp.index,\n            'y': unemp['UNRATE'].values\n        }).reset_index(drop=True)\n        print(f\"US Unemployment: Loaded {len(df)} months of REAL data from FRED\")\n        return df\n    except Exception as e:\n        print(f\"Could not load unemployment data: {e}\")\n        print(\"Using backup simulated data...\")\n        np.random.seed(456)\n        dates = pd.date_range('2015-01-01', '2023-12-01', freq='MS')\n        unemployment = []\n        for i, date in enumerate(dates):\n            if date < pd.Timestamp('2020-03-01'):\n                base = 5.5 - (i / 60) * 2\n                unemployment.append(max(3.5, base + np.random.normal(0, 0.1)))\n            elif date < pd.Timestamp('2020-05-01'):\n                unemployment.append(4.4 if date.month == 3 else 14.7)\n            elif date < pd.Timestamp('2021-01-01'):\n                months_since = (date.year - 2020) * 12 + date.month - 4\n                rate = 14.7 - months_since * 1.2\n                unemployment.append(max(6.7, rate + np.random.normal(0, 0.2)))\n            elif date < pd.Timestamp('2023-01-01'):\n                months_since = (date.year - 2021) * 12 + date.month\n                rate = 6.7 - months_since * 0.15\n                unemployment.append(max(3.5, rate + np.random.normal(0, 0.1)))\n            else:\n                unemployment.append(3.5 + np.random.normal(0, 0.1))\n        return pd.DataFrame({'ds': dates, 'y': unemployment})\n\n\nprint(\"Real data loading functions defined!\")\nprint(\"- Bitcoin: Yahoo Finance API\")\nprint(\"- Sunspots: statsmodels classic dataset\")\nprint(\"- US Unemployment: FRED API\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "---\n# Case Study 1: Bitcoin Volatility Analysis\n\nCryptocurrency data is characterized by:\n- **Extreme volatility** (much higher than traditional assets)\n- **Regime changes** (bull markets, crypto winters)\n- **Fat tails** (more extreme events than normal distribution)\n- **Volatility clustering** (GARCH is essential)",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Load REAL Bitcoin data\nbtc = get_bitcoin_data()\n\nprint(\"\\nBitcoin Data Overview\")\nprint(\"=\"*50)\nprint(f\"Period: {btc['ds'].min().date()} to {btc['ds'].max().date()}\")\nprint(f\"Observations: {len(btc)} days\")\nprint(f\"\\nPrice Statistics:\")\nprint(f\"  Min: ${btc['price'].min():,.2f}\")\nprint(f\"  Max: ${btc['price'].max():,.2f}\")\nprint(f\"\\nReturn Statistics (Daily %):\")\nprint(f\"  Mean: {btc['returns'].mean():.4f}%\")\nprint(f\"  Std: {btc['returns'].std():.4f}%\")\nprint(f\"  Skewness: {btc['returns'].skew():.4f}\")\nprint(f\"  Kurtosis: {btc['returns'].kurtosis():.4f}\")\nprint(f\"\\nNote: High kurtosis indicates fat tails (extreme events)\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Visualize Bitcoin prices and returns\nfig, axes = plt.subplots(2, 1, figsize=(12, 8))\n\n# Prices with regime annotations\naxes[0].plot(btc['ds'], btc['price'], color=COLORS['blue'], linewidth=1)\naxes[0].axvspan(pd.Timestamp('2020-03-01'), pd.Timestamp('2020-04-01'),\n                alpha=0.3, color=COLORS['red'], label='COVID-19 Crash')\naxes[0].axvspan(pd.Timestamp('2021-11-01'), pd.Timestamp('2022-12-31'),\n                alpha=0.2, color=COLORS['orange'], label='Crypto Winter 2022')\naxes[0].set_title('Bitcoin Daily Prices (2019-2024) - Real Data', fontweight='bold')\naxes[0].set_ylabel('Price (USD)')\naxes[0].set_yscale('log')  # Log scale for better visualization\naxes[0].legend(loc='upper center', bbox_to_anchor=(0.5, -0.12), ncol=2, frameon=False)\n\n# Returns\naxes[1].plot(btc['ds'], btc['returns'], color=COLORS['green'], linewidth=0.5)\naxes[1].axhline(y=0, color='black', linewidth=0.5, alpha=0.3)\naxes[1].set_title('Bitcoin Daily Returns (%)', fontweight='bold')\naxes[1].set_xlabel('Date')\naxes[1].set_ylabel('Return (%)')\n\nplt.tight_layout()\nplt.subplots_adjust(hspace=0.35)\nplt.show()\n\nprint(\"Key Observations:\")\nprint(\"- COVID-19 crash (March 2020): ~50% drop in weeks\")\nprint(\"- 2021 bull run to all-time high (~$69K in November 2021)\")\nprint(\"- 2022 crypto winter: Extended decline to ~$16K\")\nprint(\"- Clear volatility clustering: Large moves cluster together\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Step 1: Stationarity Testing",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def test_stationarity(series, name):\n    \"\"\"Run ADF and KPSS tests\"\"\"\n    print(f\"\\nStationarity Tests for {name}\")\n    print(\"-\" * 40)\n    \n    # ADF Test (H0: unit root exists = non-stationary)\n    adf_result = adfuller(series.dropna(), autolag='AIC')\n    print(f\"ADF Test:\")\n    print(f\"  Statistic: {adf_result[0]:.4f}\")\n    print(f\"  p-value: {adf_result[1]:.4f}\")\n    print(f\"  Conclusion: {'Stationary' if adf_result[1] < 0.05 else 'Non-stationary'}\")\n    \n    # KPSS Test (H0: stationary)\n    kpss_result = kpss(series.dropna(), regression='c', nlags='auto')\n    print(f\"\\nKPSS Test:\")\n    print(f\"  Statistic: {kpss_result[0]:.4f}\")\n    print(f\"  p-value: {kpss_result[1]:.4f}\")\n    print(f\"  Conclusion: {'Stationary' if kpss_result[1] > 0.05 else 'Non-stationary'}\")\n    \n    return adf_result[1] < 0.05 and kpss_result[1] > 0.05\n\n# Test prices (expect non-stationary)\nprices_stationary = test_stationarity(btc['price'], 'Bitcoin Prices')\n\n# Test returns (expect stationary)\nreturns_stationary = test_stationarity(btc['returns'].dropna(), 'Bitcoin Returns')\n\nprint(\"\\n\" + \"=\"*50)\nprint(\"CONCLUSION: Use RETURNS for mean modeling (stationary)\")\nprint(\"But volatility of returns is NOT constant -> GARCH needed!\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Step 2: ACF/PACF Analysis",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "returns = btc['returns'].dropna()\n\nfig, axes = plt.subplots(2, 2, figsize=(12, 8))\n\n# ACF/PACF for returns (mean equation)\nplot_acf(returns, ax=axes[0, 0], lags=30, alpha=0.05)\naxes[0, 0].set_title('ACF: Returns (Mean)', fontweight='bold')\n\nplot_pacf(returns, ax=axes[0, 1], lags=30, alpha=0.05, method='ywm')\naxes[0, 1].set_title('PACF: Returns (Mean)', fontweight='bold')\n\n# ACF/PACF for squared returns (volatility)\nplot_acf(returns**2, ax=axes[1, 0], lags=30, alpha=0.05)\naxes[1, 0].set_title('ACF: Squared Returns (Volatility)', fontweight='bold')\n\nplot_pacf(returns**2, ax=axes[1, 1], lags=30, alpha=0.05, method='ywm')\naxes[1, 1].set_title('PACF: Squared Returns (Volatility)', fontweight='bold')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"Key Findings:\")\nprint(\"- Returns: Weak autocorrelation (hard to predict mean)\")\nprint(\"- Squared returns: STRONG persistence -> GARCH essential!\")\nprint(\"- This is typical of financial returns: 'weak mean, strong variance'\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Step 3: ARIMA-GARCH Model\n\n**GARCH(1,1) Model:**\n$$\\sigma_t^2 = \\omega + \\alpha \\epsilon_{t-1}^2 + \\beta \\sigma_{t-1}^2$$\n\nWhere:\n- $\\omega$ = constant (long-run variance component)\n- $\\alpha$ = ARCH effect (reaction to recent shock)\n- $\\beta$ = GARCH effect (persistence of volatility)\n- $\\alpha + \\beta$ = persistence (how long shocks affect volatility)",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "if HAS_ARCH:\n    # Fit GARCH(1,1) model with AR(1) mean\n    print(\"Fitting GARCH(1,1) Model for Bitcoin\")\n    print(\"=\"*50)\n    \n    model = arch_model(returns, vol='Garch', p=1, q=1, mean='AR', lags=1)\n    results = model.fit(disp='off')\n    \n    print(results.summary())\nelse:\n    print(\"ARCH package not available. Install with: pip install arch\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "if HAS_ARCH:\n    # Plot conditional volatility\n    fig, axes = plt.subplots(2, 1, figsize=(12, 8))\n    \n    # Returns with volatility bands\n    cond_vol = results.conditional_volatility\n    dates = btc['ds'][1:]\n    \n    axes[0].plot(dates, returns, color=COLORS['blue'], linewidth=0.5, alpha=0.7, label='Returns')\n    axes[0].plot(dates, 2*cond_vol, color=COLORS['red'], linewidth=1, label='+2\\u03c3')\n    axes[0].plot(dates, -2*cond_vol, color=COLORS['red'], linewidth=1, label='-2\\u03c3')\n    axes[0].axhline(y=0, color='black', linewidth=0.5, alpha=0.3)\n    axes[0].set_title('Bitcoin Returns with GARCH(1,1) Volatility Bands', fontweight='bold')\n    axes[0].set_ylabel('Return (%)')\n    axes[0].legend(loc='upper center', bbox_to_anchor=(0.5, -0.12), ncol=3, frameon=False)\n    \n    # Conditional volatility\n    axes[1].fill_between(dates, 0, cond_vol, color=COLORS['orange'], alpha=0.7, label='Conditional Volatility')\n    axes[1].axvspan(pd.Timestamp('2020-03-01'), pd.Timestamp('2020-04-30'),\n                    alpha=0.3, color=COLORS['red'], label='COVID Crash')\n    axes[1].set_title('GARCH(1,1) Conditional Volatility', fontweight='bold')\n    axes[1].set_xlabel('Date')\n    axes[1].set_ylabel('Volatility (\\u03c3)')\n    axes[1].legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=2, frameon=False)\n    \n    plt.tight_layout()\n    plt.subplots_adjust(hspace=0.35)\n    plt.show()\n    \n    # Interpret parameters\n    alpha = results.params.get('alpha[1]', 0)\n    beta = results.params.get('beta[1]', 0)\n    \n    print(\"\\nGARCH Model Interpretation:\")\n    print(f\"- \\u03b1 (ARCH): {alpha:.4f} - Reaction to recent shocks\")\n    print(f\"- \\u03b2 (GARCH): {beta:.4f} - Persistence of past volatility\")\n    print(f\"- Persistence (\\u03b1+\\u03b2): {alpha + beta:.4f}\")\n    print(\"\\nHigh persistence indicates volatility shocks are long-lasting.\")\n    if alpha + beta > 0.95:\n        print(\"Warning: Very high persistence - consider IGARCH or long-memory models.\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "---\n# Case Study 2: Sunspot Cycle Analysis\n\nSunspots demonstrate:\n- **Very long seasonality** (11-year Schwabe cycle)\n- **Asymmetric pattern** (rapid rise, slow decline)\n- **Variable cycle amplitude**\n- Challenge: Standard SARIMA cannot handle such long seasonality",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Load REAL Sunspot data\nsunspots = get_sunspot_data()\n\nprint(\"\\nSunspot Data Overview\")\nprint(\"=\"*50)\nprint(f\"Period: {sunspots['ds'].min().year} to {sunspots['ds'].max().year}\")\nprint(f\"Observations: {len(sunspots)} years\")\nprint(f\"\\nStatistics:\")\nprint(f\"  Mean: {sunspots['y'].mean():.1f}\")\nprint(f\"  Std: {sunspots['y'].std():.1f}\")\nprint(f\"  Min: {sunspots['y'].min():.0f}\")\nprint(f\"  Max: {sunspots['y'].max():.0f}\")\nprint(f\"\\nKey Feature: ~11-year Schwabe solar cycle\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Visualize sunspot data\nfig, axes = plt.subplots(2, 1, figsize=(12, 8))\n\n# Time series\naxes[0].plot(sunspots['ds'], sunspots['y'], color=COLORS['blue'], linewidth=1, label='Sunspot Activity')\naxes[0].set_title('Yearly Sunspot Numbers (1900-present) - Real Data', fontweight='bold')\naxes[0].set_ylabel('Sunspot Count')\n\n# Rolling statistics\nwindow = 11  # 11-year window\nrolling_mean = sunspots['y'].rolling(window=window, center=True).mean()\nrolling_std = sunspots['y'].rolling(window=window, center=True).std()\n\naxes[1].plot(sunspots['ds'], rolling_mean, color=COLORS['green'], \n             linewidth=2, label=f'{window}-year Rolling Mean')\naxes[1].fill_between(sunspots['ds'], rolling_mean - rolling_std, rolling_mean + rolling_std,\n                     color=COLORS['green'], alpha=0.2, label='\\u00b11 Std Dev')\naxes[1].set_title('Rolling Statistics', fontweight='bold')\naxes[1].set_xlabel('Year')\naxes[1].set_ylabel('Sunspot Count')\naxes[1].legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=2, frameon=False)\n\nplt.tight_layout()\nplt.subplots_adjust(hspace=0.35)\nplt.show()\n\nprint(\"Key Observations:\")\nprint(\"- Clear ~11-year periodicity (solar cycle)\")\nprint(\"- Asymmetric shape: rapid rise, gradual decline\")\nprint(\"- Cycle amplitudes vary significantly\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## ACF Analysis and Spectral Analysis",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n\n# ACF showing long cycle\nplot_acf(sunspots['y'], ax=axes[0], lags=50, alpha=0.05)\naxes[0].axvline(x=11, color=COLORS['red'], linestyle='--', alpha=0.5, label='11-year lag')\naxes[0].axvline(x=22, color=COLORS['red'], linestyle='--', alpha=0.5)\naxes[0].set_title('ACF: Shows ~11-year Periodicity', fontweight='bold')\naxes[0].legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=1, frameon=False)\n\n# FFT to find dominant period\nfrom scipy.fft import fft, fftfreq\n\ny = sunspots['y'].values - sunspots['y'].mean()\nn = len(y)\nyf = np.abs(fft(y))[:n//2]\nxf = fftfreq(n, 1)[:n//2]  # Yearly frequency\n\n# Convert to period in years\nperiod_years = 1 / xf[1:]  # Skip zero frequency\npower = yf[1:]\n\naxes[1].plot(period_years[:50], power[:50], color=COLORS['orange'], linewidth=1, label='Power Spectrum')\naxes[1].axvline(x=11, color=COLORS['red'], linestyle='--', label='11-year cycle')\naxes[1].set_title('Power Spectrum (Periodogram)', fontweight='bold')\naxes[1].set_xlabel('Period (years)')\naxes[1].set_ylabel('Spectral Power')\naxes[1].set_xlim([0, 50])\naxes[1].legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=2, frameon=False)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"Spectral Analysis confirms:\")\nprint(\"- Dominant period around 11 years\")\nprint(\"- ACF shows peak correlation at lag 11\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Modeling with Fourier Terms\n\nFor long seasonal periods, we use **Fourier terms** as regressors:\n\n$$y_t = \\sum_{k=1}^{K} \\left[ a_k \\sin\\left(\\frac{2\\pi k t}{m}\\right) + b_k \\cos\\left(\\frac{2\\pi k t}{m}\\right) \\right] + \\epsilon_t$$",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def add_fourier_terms(df, period, K):\n    \"\"\"Add Fourier terms for seasonality\"\"\"\n    t = np.arange(len(df))\n    for k in range(1, K + 1):\n        df[f'sin_{k}'] = np.sin(2 * np.pi * k * t / period)\n        df[f'cos_{k}'] = np.cos(2 * np.pi * k * t / period)\n    return df\n\n# Prepare data with Fourier terms\nsunspot_model = sunspots.copy()\nsunspot_model = add_fourier_terms(sunspot_model, period=11, K=3)  # 3 harmonics\n\n# Train/test split\ntrain_size = len(sunspots) - 20  # Hold out last 20 years\ntrain = sunspot_model.iloc[:train_size]\ntest = sunspot_model.iloc[train_size:]\n\nprint(f\"Training: {train_size} years\")\nprint(f\"Testing: {len(test)} years\")\nprint(f\"\\nFourier terms added: sin_1, cos_1, sin_2, cos_2, sin_3, cos_3\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Fit ARIMA with Fourier regressors\nexog_cols = ['sin_1', 'cos_1', 'sin_2', 'cos_2', 'sin_3', 'cos_3']\n\nprint(\"Fitting ARIMA(2,0,1) with Fourier Regressors\")\nprint(\"=\"*50)\n\nmodel = SARIMAX(train['y'], \n                exog=train[exog_cols],\n                order=(2, 0, 1),\n                enforce_stationarity=False,\n                enforce_invertibility=False)\nresults = model.fit(disp=False)\n\nprint(results.summary().tables[1])",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Forecast\nforecast = results.get_forecast(steps=len(test), exog=test[exog_cols])\nforecast_mean = forecast.predicted_mean\nforecast_ci = forecast.conf_int()\n\n# Metrics\nrmse = np.sqrt(mean_squared_error(test['y'], forecast_mean))\nmape = np.mean(np.abs((test['y'].values - forecast_mean.values) / (test['y'].values + 1))) * 100\n\nprint(f\"\\nForecast Performance:\")\nprint(f\"  RMSE: {rmse:.2f}\")\nprint(f\"  MAPE: {mape:.2f}%\")\n\n# Plot forecast\nfig, ax = plt.subplots(figsize=(12, 6))\n\nax.plot(train['ds'], train['y'], color=COLORS['blue'], linewidth=1, label='Training')\nax.plot(test['ds'], test['y'], color=COLORS['blue'], linewidth=1.5, label='Actual')\nax.plot(test['ds'], forecast_mean, color=COLORS['red'], linewidth=1.5, \n        linestyle='--', label=f'Forecast (RMSE={rmse:.1f})')\nax.fill_between(test['ds'], forecast_ci.iloc[:, 0], forecast_ci.iloc[:, 1],\n                color=COLORS['red'], alpha=0.2, label='95% CI')\nax.axvline(x=train['ds'].iloc[-1], color='black', linestyle=':', alpha=0.5)\n\nax.set_title('Sunspot Forecast: ARIMA with Fourier Terms', fontweight='bold')\nax.set_xlabel('Year')\nax.set_ylabel('Sunspot Count')\nax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.12), ncol=4, frameon=False)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nNote: Fourier terms capture the 11-year cycle effectively.\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "---\n# Case Study 3: US Unemployment with Structural Break\n\nThe COVID-19 pandemic created an unprecedented structural break:\n- Pre-COVID: 3.5% (50-year low)\n- Peak: 14.7% (April 2020)\n- Recovery: Back to ~3.5% by 2023\n\nThis challenges traditional time series models.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Load REAL unemployment data\nunemp = get_unemployment_data()\n\nprint(\"\\nUS Unemployment Data Overview\")\nprint(\"=\"*50)\nprint(f\"Period: {unemp['ds'].min().strftime('%Y-%m')} to {unemp['ds'].max().strftime('%Y-%m')}\")\nprint(f\"Observations: {len(unemp)} months\")\nprint(f\"\\nKey Statistics:\")\nprint(f\"  Pre-COVID Min: {unemp[unemp['ds'] < '2020-03-01']['y'].min():.1f}%\")\nprint(f\"  COVID Peak: {unemp['y'].max():.1f}% (April 2020)\")\nprint(f\"  Latest: {unemp['y'].iloc[-1]:.1f}%\")\nprint(f\"\\nStructural Break: March-April 2020\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Visualize unemployment with COVID impact\nfig, axes = plt.subplots(2, 1, figsize=(12, 8))\n\n# Main plot\naxes[0].plot(unemp['ds'], unemp['y'], color=COLORS['blue'], linewidth=1.5, label='Unemployment Rate')\naxes[0].axvspan(pd.Timestamp('2020-03-01'), pd.Timestamp('2020-05-01'),\n                alpha=0.3, color=COLORS['red'], label='COVID-19 Shock')\n\n# Pre-COVID trend\npre_covid = unemp[unemp['ds'] < '2020-03-01']\nz1 = np.polyfit(range(len(pre_covid)), pre_covid['y'], 1)\ntrend_pre = np.polyval(z1, range(len(pre_covid)))\naxes[0].plot(pre_covid['ds'], trend_pre, color=COLORS['gray'], linewidth=2, \n             linestyle='--', label='Pre-COVID Trend')\n\naxes[0].set_title('US Unemployment Rate (2015-2023): COVID-19 Structural Break - Real Data', fontweight='bold')\naxes[0].set_ylabel('Unemployment Rate (%)')\naxes[0].set_ylim([0, 16])\naxes[0].legend(loc='upper center', bbox_to_anchor=(0.5, -0.12), ncol=3, frameon=False)\n\n# Month-over-month change\nunemp_change = unemp['y'].diff()\ncolors_bar = [COLORS['green'] if x < 0 else COLORS['red'] for x in unemp_change]\naxes[1].bar(unemp['ds'], unemp_change, color=colors_bar, width=20, alpha=0.7)\naxes[1].axhline(y=0, color='black', linewidth=0.5)\naxes[1].set_title('Month-over-Month Change', fontweight='bold')\naxes[1].set_xlabel('Date')\naxes[1].set_ylabel('Change (pp)')\n\nplt.tight_layout()\nplt.subplots_adjust(hspace=0.35)\nplt.show()\n\nprint(\"Key Observations:\")\nprint(\"- April 2020: Largest single-month increase in history\")\nprint(\"- Recovery was rapid but took ~3 years to return to pre-COVID levels\")\nprint(\"- Traditional ARIMA would struggle with such an extreme outlier\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Prophet Model for Structural Breaks\n\nProphet handles structural breaks through **changepoint detection**:\n- Automatically identifies where the trend changes\n- Adjustable `changepoint_prior_scale` controls flexibility\n- Can add known changepoints (like COVID)",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "if HAS_PROPHET:\n    # Prepare data for Prophet\n    unemp_prophet = unemp.copy()\n    \n    # Train/test split (hold out last 12 months)\n    train_unemp = unemp_prophet.iloc[:-12]\n    test_unemp = unemp_prophet.iloc[-12:]\n    \n    print(\"Fitting Prophet Model with Changepoint Detection\")\n    print(\"=\"*50)\n    \n    # Model with flexible changepoints\n    prophet_model = Prophet(\n        changepoint_prior_scale=0.5,  # More flexible for extreme changes\n        yearly_seasonality=False,\n        weekly_seasonality=False,\n        daily_seasonality=False,\n        changepoints=['2020-03-01', '2020-04-01', '2020-06-01']  # COVID events\n    )\n    prophet_model.fit(train_unemp)\n    \n    # Forecast\n    future = prophet_model.make_future_dataframe(periods=12, freq='MS')\n    forecast = prophet_model.predict(future)\n    \n    # Extract test predictions\n    pred_test = forecast['yhat'].iloc[-12:].values\n    \n    # Metrics\n    rmse = np.sqrt(mean_squared_error(test_unemp['y'], pred_test))\n    mape = np.mean(np.abs((test_unemp['y'].values - pred_test) / test_unemp['y'].values)) * 100\n    \n    print(f\"\\nProphet Forecast Performance:\")\n    print(f\"  RMSE: {rmse:.2f}\")\n    print(f\"  MAPE: {mape:.2f}%\")\nelse:\n    print(\"Prophet not available. Install with: pip install prophet\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "if HAS_PROPHET:\n    # Plot Prophet results\n    fig, axes = plt.subplots(2, 1, figsize=(12, 8))\n    \n    # Forecast plot\n    axes[0].plot(unemp['ds'], unemp['y'], color=COLORS['blue'], linewidth=1.5, label='Actual')\n    axes[0].plot(forecast['ds'], forecast['yhat'], color=COLORS['orange'], \n                 linewidth=1.5, linestyle='--', label='Prophet Forecast')\n    axes[0].fill_between(forecast['ds'], forecast['yhat_lower'], forecast['yhat_upper'],\n                        color=COLORS['orange'], alpha=0.2, label='95% CI')\n    axes[0].axvline(x=train_unemp['ds'].iloc[-1], color='black', linestyle=':', alpha=0.5)\n    \n    # Mark changepoints\n    for i, cp in enumerate(prophet_model.changepoints):\n        if i == 0:\n            axes[0].axvline(x=cp, color=COLORS['red'], linestyle='--', alpha=0.5, linewidth=1, label='Changepoints')\n        else:\n            axes[0].axvline(x=cp, color=COLORS['red'], linestyle='--', alpha=0.5, linewidth=1)\n    \n    axes[0].set_title('Prophet Model with Changepoint Detection', fontweight='bold')\n    axes[0].set_ylabel('Unemployment Rate (%)')\n    axes[0].legend(loc='upper center', bbox_to_anchor=(0.5, -0.12), ncol=4, frameon=False)\n    \n    # Trend component\n    axes[1].plot(forecast['ds'], forecast['trend'], color=COLORS['green'], linewidth=2, label='Trend')\n    for i, cp in enumerate(prophet_model.changepoints):\n        if i == 0:\n            axes[1].axvline(x=cp, color=COLORS['red'], linestyle='--', alpha=0.5, linewidth=1, label='Changepoints')\n        else:\n            axes[1].axvline(x=cp, color=COLORS['red'], linestyle='--', alpha=0.5, linewidth=1)\n    axes[1].set_title('Prophet Trend Component (with Changepoints)', fontweight='bold')\n    axes[1].set_xlabel('Date')\n    axes[1].set_ylabel('Trend')\n    axes[1].legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=2, frameon=False)\n    \n    plt.tight_layout()\n    plt.subplots_adjust(hspace=0.35)\n    plt.show()\n    \n    print(\"\\nProphet Changepoints detected:\")\n    for i, cp in enumerate(prophet_model.changepoints):\n        print(f\"  {i+1}. {cp.strftime('%Y-%m-%d')}\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "---\n# Summary: Model Selection Guide\n\n## Decision Flowchart\n\n```\nTime Series Data\n    |\n    v\n[Is data stationary?] --No--> Apply differencing/transformations\n    |\n    Yes\n    v\n[Financial returns?] --Yes--> ARIMA-GARCH\n    |\n    No\n    v\n[Seasonality present?]\n    |         |\n   Yes        No\n    |         |\n    v         v\n[Long season?]   ARIMA\n(>12 periods)\n    |    |\n   Yes   No\n    |    |\n    v    v\nFourier  SARIMA\nTerms\n    |\n    v\n[Structural breaks?] --Yes--> Prophet/Piecewise models\n```",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "print(\"\"\"\n\\u2554\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2557\n\\u2551                    TIME SERIES MODEL SELECTION GUIDE                  \\u2551\n\\u2560\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2563\n\\u2551                                                                      \\u2551\n\\u2551  DATA TYPE              RECOMMENDED MODEL         SPECIAL CASE       \\u2551\n\\u2551  \\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500  \\u2551\n\\u2551                                                                      \\u2551\n\\u2551  Crypto/Financial       ARIMA-GARCH               Extreme volatility \\u2551\n\\u2551  (Bitcoin, stocks)      Focus on volatility       clustering         \\u2551\n\\u2551                                                                      \\u2551\n\\u2551  Long seasonality       ARIMA + Fourier           Period > 12        \\u2551\n\\u2551  (Sunspots, climate)    terms as regressors       years              \\u2551\n\\u2551                                                                      \\u2551\n\\u2551  Structural breaks      Prophet with              Changepoint        \\u2551\n\\u2551  (COVID, crises)        changepoints              detection          \\u2551\n\\u2551                                                                      \\u2551\n\\u2551  Standard seasonality   SARIMA                    Period \\u2264 12        \\u2551\n\\u2551  (monthly, quarterly)                                                \\u2551\n\\u2551                                                                      \\u2551\n\\u2551  Multiple seasonality   Prophet, TBATS            Daily + weekly +   \\u2551\n\\u2551  (hourly data)                                    annual             \\u2551\n\\u2551                                                                      \\u2551\n\\u2560\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2563\n\\u2551                         WORKFLOW STEPS                               \\u2551\n\\u2551  1. Visualize and explore the data                                   \\u2551\n\\u2551  2. Test for stationarity (ADF, KPSS)                                \\u2551\n\\u2551  3. Apply transformations if needed (log, diff)                      \\u2551\n\\u2551  4. Identify patterns (ACF/PACF, decomposition)                      \\u2551\n\\u2551  5. Fit candidate models                                             \\u2551\n\\u2551  6. Check diagnostics (residuals, Ljung-Box)                         \\u2551\n\\u2551  7. Compare with out-of-sample forecast                              \\u2551\n\\u2551  8. Select best model for the task                                   \\u2551\n\\u255a\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u255d\n\"\"\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Final summary table\nprint(\"\\nChapter 10 Case Studies Summary\")\nprint(\"=\"*75)\nprint(f\"{'Dataset':<20} {'Challenge':<25} {'Best Model':<20} {'Key Insight'}\")\nprint(\"-\"*75)\nprint(f\"{'Bitcoin':<20} {'Extreme volatility':<25} {'ARIMA-GARCH(1,1)':<20} {'Focus on volatility, not mean'}\")\nprint(f\"{'Sunspots':<20} {'11-year cycle':<25} {'ARIMA + Fourier':<20} {'Long seasonality handling'}\")\nprint(f\"{'US Unemployment':<20} {'COVID structural break':<25} {'Prophet':<20} {'Changepoint detection'}\")\nprint(\"-\"*75)\n\nprint(\"\\n\" + \"=\"*75)\nprint(\"KEY TAKEAWAYS\")\nprint(\"=\"*75)\nprint(\"\"\"\n1. VOLATILITY MODELING (Bitcoin)\n   - Financial returns show weak mean predictability but strong volatility patterns\n   - GARCH captures volatility clustering: large moves followed by large moves\n   - Always examine squared returns for ARCH effects\n\n2. LONG SEASONALITY (Sunspots)\n   - When seasonal period > 12, traditional SARIMA is computationally challenging\n   - Fourier terms as regressors provide an elegant solution\n   - Use spectral analysis to identify the true period\n\n3. STRUCTURAL BREAKS (Unemployment)\n   - Extreme events (COVID, financial crises) require flexible models\n   - Prophet's changepoint detection handles regime changes\n   - Consider using post-break data only for ARIMA\n\n4. GENERAL PRINCIPLES\n   - Always start with visualization and stationarity testing\n   - Match the model to the data characteristics\n   - Validate with out-of-sample forecasting\n   - Simple models often work better than complex ones\n\"\"\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "---\n\n## Data Sources\n\n- **Bitcoin**: Yahoo Finance (BTC-USD)\n- **Sunspots**: Classic Wolfer sunspot dataset from statsmodels\n- **US Unemployment**: Bureau of Labor Statistics via FRED (series UNRATE)\n\n---\n\n**End of Chapter 10: Comprehensive Review**\n\n*Course: Time Series Analysis and Forecasting*  \n*Bucharest University of Economic Studies*",
      "metadata": {}
    }
  ]
}
