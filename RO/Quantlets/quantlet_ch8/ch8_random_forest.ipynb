{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSA_ch8_random_forest\n",
    "\n",
    "## Random Forest for Time Series Forecasting\n",
    "\n",
    "**Data**: Germany Daily Electricity Consumption\n",
    "\n",
    "**Source**: ENTSO-E / Open Power System Data\n",
    "\n",
    "**Author**: Daniel Traian PELE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Germany Electricity Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download from Open Power System Data\n",
    "url = \"https://data.open-power-system-data.org/time_series/2020-10-06/time_series_60min_singleindex.csv\"\n",
    "\n",
    "print(\"Downloading Germany electricity data (this may take a moment)...\")\n",
    "df_raw = pd.read_csv(url, parse_dates=['utc_timestamp'], low_memory=False)\n",
    "\n",
    "# Extract Germany total load\n",
    "df = df_raw[['utc_timestamp', 'DE_load_actual_entsoe_transparency']].copy()\n",
    "df.columns = ['datetime', 'load_mw']\n",
    "df = df.dropna()\n",
    "\n",
    "# Aggregate to daily\n",
    "df['date'] = df['datetime'].dt.date\n",
    "daily = df.groupby('date')['load_mw'].sum().reset_index()\n",
    "daily['date'] = pd.to_datetime(daily['date'])\n",
    "daily['consumption_gwh'] = daily['load_mw'] / 1000  # MW*h to GWh\n",
    "\n",
    "# Filter 2015-2019\n",
    "daily = daily[(daily['date'] >= '2015-01-01') & (daily['date'] <= '2019-12-31')]\n",
    "daily = daily.reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nData loaded: {daily['date'].min().date()} to {daily['date'].max().date()}\")\n",
    "print(f\"Observations: {len(daily)} days\")\n",
    "print(f\"Mean consumption: {daily['consumption_gwh'].mean():.1f} GWh/day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "axes[0].plot(daily['date'], daily['consumption_gwh'], linewidth=0.5, color='steelblue')\n",
    "axes[0].set_title('Germany Daily Electricity Consumption (2015-2019)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Consumption (GWh)')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Weekly pattern\n",
    "weekly_avg = daily.groupby(daily['date'].dt.dayofweek)['consumption_gwh'].mean()\n",
    "axes[1].bar(range(7), weekly_avg.values, color='steelblue')\n",
    "axes[1].set_xticks(range(7))\n",
    "axes[1].set_xticklabels(['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'])\n",
    "axes[1].set_title('Average Consumption by Day of Week', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Consumption (GWh)')\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    \"\"\"Create features for time series forecasting.\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Target\n",
    "    df['y'] = df['consumption_gwh']\n",
    "    \n",
    "    # Lag features (use only past data!)\n",
    "    for lag in [1, 2, 3, 7, 14, 21, 28]:\n",
    "        df[f'lag_{lag}'] = df['y'].shift(lag)\n",
    "    \n",
    "    # Rolling statistics (shifted by 1 to avoid data leakage)\n",
    "    for window in [7, 14, 30]:\n",
    "        df[f'roll_mean_{window}'] = df['y'].shift(1).rolling(window).mean()\n",
    "        df[f'roll_std_{window}'] = df['y'].shift(1).rolling(window).std()\n",
    "    \n",
    "    # Calendar features\n",
    "    df['day_of_week'] = df['date'].dt.dayofweek\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['day_of_year'] = df['date'].dt.dayofyear\n",
    "    df['week_of_year'] = df['date'].dt.isocalendar().week.astype(int)\n",
    "    df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n",
    "    \n",
    "    # Cyclical encoding\n",
    "    df['dow_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)\n",
    "    df['dow_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)\n",
    "    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "    \n",
    "    return df.dropna()\n",
    "\n",
    "df_features = create_features(daily)\n",
    "print(f\"Features created: {len(df_features)} samples\")\n",
    "print(f\"\\nFeature columns:\")\n",
    "feature_cols = [c for c in df_features.columns if c not in ['date', 'load_mw', 'consumption_gwh', 'y']]\n",
    "print(feature_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train/Test Split (Temporal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 70% train, 15% validation, 15% test\n",
    "n = len(df_features)\n",
    "train_end = int(n * 0.70)\n",
    "val_end = int(n * 0.85)\n",
    "\n",
    "train = df_features.iloc[:train_end]\n",
    "val = df_features.iloc[train_end:val_end]\n",
    "test = df_features.iloc[val_end:]\n",
    "\n",
    "X_train, y_train = train[feature_cols], train['y']\n",
    "X_val, y_val = val[feature_cols], val['y']\n",
    "X_test, y_test = test[feature_cols], test['y']\n",
    "\n",
    "print(f\"Training:   {len(train)} days ({train['date'].min().date()} to {train['date'].max().date()})\")\n",
    "print(f\"Validation: {len(val)} days ({val['date'].min().date()} to {val['date'].max().date()})\")\n",
    "print(f\"Test:       {len(test)} days ({test['date'].min().date()} to {test['date'].max().date()})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=15,\n",
    "    min_samples_leaf=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_train = rf.predict(X_train)\n",
    "y_pred_val = rf.predict(X_val)\n",
    "y_pred_test = rf.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "def mape(y_true, y_pred):\n",
    "    return 100 * np.mean(np.abs((y_true - y_pred) / y_true))\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"RANDOM FOREST PERFORMANCE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTraining Set:\")\n",
    "print(f\"  RMSE: {np.sqrt(mean_squared_error(y_train, y_pred_train)):.2f} GWh\")\n",
    "print(f\"  MAE:  {mean_absolute_error(y_train, y_pred_train):.2f} GWh\")\n",
    "print(f\"  MAPE: {mape(y_train, y_pred_train):.2f}%\")\n",
    "\n",
    "print(f\"\\nValidation Set:\")\n",
    "print(f\"  RMSE: {np.sqrt(mean_squared_error(y_val, y_pred_val)):.2f} GWh\")\n",
    "print(f\"  MAE:  {mean_absolute_error(y_val, y_pred_val):.2f} GWh\")\n",
    "print(f\"  MAPE: {mape(y_val, y_pred_val):.2f}%\")\n",
    "\n",
    "print(f\"\\nTest Set:\")\n",
    "print(f\"  RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_test)):.2f} GWh\")\n",
    "print(f\"  MAE:  {mean_absolute_error(y_test, y_pred_test):.2f} GWh\")\n",
    "print(f\"  MAPE: {mape(y_test, y_pred_test):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': rf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "print(importance.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. Predictions vs Actual\n",
    "ax = axes[0, 0]\n",
    "ax.plot(test['date'], y_test, 'b-', linewidth=1, label='Actual')\n",
    "ax.plot(test['date'], y_pred_test, 'r-', linewidth=1, alpha=0.7, label='Predicted')\n",
    "ax.set_title('Random Forest: Predictions vs Actual (Test Set)', fontweight='bold')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Consumption (GWh)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Feature Importance\n",
    "ax = axes[0, 1]\n",
    "top15 = importance.head(15)\n",
    "colors = plt.cm.Blues(np.linspace(0.4, 0.9, len(top15)))\n",
    "ax.barh(range(len(top15)), top15['importance'].values, color=colors[::-1])\n",
    "ax.set_yticks(range(len(top15)))\n",
    "ax.set_yticklabels(top15['feature'].values)\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel('Importance')\n",
    "ax.set_title('Feature Importance (Top 15)', fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# 3. Residuals\n",
    "ax = axes[1, 0]\n",
    "residuals = y_test.values - y_pred_test\n",
    "ax.plot(test['date'], residuals, 'g-', linewidth=0.8)\n",
    "ax.axhline(y=0, color='red', linestyle='--', linewidth=1)\n",
    "ax.set_title('Prediction Residuals (Test Set)', fontweight='bold')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Residual (GWh)')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Actual vs Predicted scatter\n",
    "ax = axes[1, 1]\n",
    "ax.scatter(y_test, y_pred_test, alpha=0.5, s=20)\n",
    "ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', linewidth=2)\n",
    "ax.set_xlabel('Actual (GWh)')\n",
    "ax.set_ylabel('Predicted (GWh)')\n",
    "ax.set_title('Actual vs Predicted', fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('ch8_random_forest_results.pdf', bbox_inches='tight', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Time Series Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_features[feature_cols]\n",
    "y = df_features['y']\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "cv_scores = []\n",
    "\n",
    "print(\"Time Series Cross-Validation (5 folds):\")\n",
    "for fold, (train_idx, val_idx) in enumerate(tscv.split(X)):\n",
    "    X_cv_train, X_cv_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_cv_train, y_cv_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    \n",
    "    rf_cv = RandomForestRegressor(n_estimators=100, max_depth=15, random_state=42, n_jobs=-1)\n",
    "    rf_cv.fit(X_cv_train, y_cv_train)\n",
    "    y_cv_pred = rf_cv.predict(X_cv_val)\n",
    "    \n",
    "    mape_score = mape(y_cv_val, y_cv_pred)\n",
    "    cv_scores.append(mape_score)\n",
    "    print(f\"  Fold {fold + 1}: MAPE = {mape_score:.2f}%\")\n",
    "\n",
    "print(f\"\\nMean CV MAPE: {np.mean(cv_scores):.2f}% (+/- {np.std(cv_scores):.2f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
