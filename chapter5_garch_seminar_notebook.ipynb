{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/danpele/Time-Series-Analysis/blob/main/chapter5_garch_seminar_notebook.ipynb)\n\n---"
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "# Seminar: GARCH Models - Practice Exercises\n",
    "\n",
    "**Course:** Time Series Analysis and Forecasting  \n",
    "**Program:** Bachelor program, Faculty of Cybernetics, Statistics and Economic Informatics, Bucharest University of Economic Studies, Romania  \n",
    "**Academic Year:** 2025-2026\n",
    "\n",
    "---\n",
    "\n",
    "## Exercises Overview\n",
    "\n",
    "1. **Exercise 1:** ARCH-LM Testing and GARCH Estimation\n",
    "2. **Exercise 2:** Model Comparison (GARCH vs GJR-GARCH vs EGARCH)\n",
    "3. **Exercise 3:** Real Data Analysis - S&P 500\n",
    "4. **Exercise 4:** Volatility Forecasting and VaR\n",
    "5. **Exercise 5:** Bitcoin Volatility Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": "# Install packages if needed (for Colab)\ntry:\n    from arch import arch_model\n    import yfinance as yf\nexcept ImportError:\n    !pip install arch yfinance --quiet\n    from arch import arch_model\n    import yfinance as yf\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom arch import arch_model\nfrom statsmodels.stats.diagnostic import het_arch, acorr_ljungbox\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.graphics.tsaplots import plot_acf\n\n# Plotting style\nplt.rcParams['figure.figsize'] = (12, 5)\nplt.rcParams['font.size'] = 11\nplt.rcParams['axes.facecolor'] = 'none'\nplt.rcParams['figure.facecolor'] = 'none'\nplt.rcParams['savefig.transparent'] = True\nplt.rcParams['axes.grid'] = False\nplt.rcParams['axes.spines.top'] = False\nplt.rcParams['axes.spines.right'] = False\nplt.rcParams['legend.frameon'] = False\n\nCOLORS = {'blue': '#1A3A6E', 'red': '#DC3545', 'green': '#2E7D32', 'orange': '#E67E22'}\n\nprint(\"Setup complete! Ready to analyze real financial data.\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": "---\n\n## Exercise 1: ARCH-LM Testing and GARCH Estimation with Real Data\n\n**Objective:** Learn to detect ARCH effects and estimate GARCH models using real market data.\n\n**Tasks:**\n1. Download EUR/USD exchange rate data\n2. Apply the ARCH-LM test to detect heteroskedasticity\n3. Estimate GARCH(1,1) model and interpret parameters"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": "# Task 1: Download real EUR/USD exchange rate data\nprint(\"Downloading EUR/USD exchange rate data from Yahoo Finance...\")\n\neurusd = yf.download('EURUSD=X', start='2010-01-01', end='2024-12-31', progress=False)\neurusd_close = eurusd['Close'].squeeze() if isinstance(eurusd['Close'], pd.DataFrame) else eurusd['Close']\n\n# Calculate returns (percentage)\nreturns = (eurusd_close.pct_change() * 100).dropna()\nreturns = pd.Series(returns.values, index=returns.index, name='returns')\n\nprint(f\"\\nEUR/USD Data Summary:\")\nprint(f\"Period: {returns.index[0].date()} to {returns.index[-1].date()}\")\nprint(f\"Observations: {len(returns)}\")\nprint(f\"\\nBasic Statistics:\")\nprint(f\"  Mean return: {float(returns.mean()):.4f}%\")\nprint(f\"  Std deviation: {float(returns.std()):.4f}%\")\nprint(f\"  Skewness: {float(stats.skew(returns.values)):.4f}\")\nprint(f\"  Kurtosis: {float(stats.kurtosis(returns.values)+3):.4f} (Normal = 3)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": "# Task 2: Apply ARCH-LM test\nprint(\"ARCH-LM Test Results - EUR/USD\")\nprint(\"=\"*50)\n\nreturns_demeaned = returns.values - returns.values.mean()\nfor lags in [5, 10, 20]:\n    lm_stat, lm_pval, _, _ = het_arch(returns_demeaned, nlags=lags)\n    result = \"ARCH present\" if lm_pval < 0.05 else \"No ARCH\"\n    print(f\"  Lags={lags:2d}: LM={lm_stat:8.2f}, p-value={lm_pval:.6f} → {result}\")\n\n# Visual check\nfig, axes = plt.subplots(1, 2, figsize=(14, 4))\n\naxes[0].plot(returns.index, returns.values, color=COLORS['blue'], linewidth=0.5)\naxes[0].set_title('EUR/USD Daily Returns (Volatility Clustering Visible)', fontweight='bold')\naxes[0].set_ylabel('Return (%)')\n\nplot_acf(returns.values**2, lags=30, ax=axes[1], color=COLORS['red'],\n         vlines_kwargs={'color': COLORS['red']})\naxes[1].set_title('ACF of Squared Returns (significant → ARCH effects)', fontweight='bold')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n→ ARCH effects confirmed in EUR/USD returns!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": "# Task 3: Estimate GARCH(1,1) on EUR/USD\nmodel = arch_model(returns.values, vol='Garch', p=1, q=1, dist='t')\nresults = model.fit(disp='off')\n\nprint(\"GARCH(1,1) Estimation - EUR/USD\")\nprint(\"=\"*50)\nprint(results.summary())\n\n# Parameter interpretation\nprint(\"\\nParameter Interpretation:\")\nomega = results.params['omega']\nalpha = results.params['alpha[1]']\nbeta = results.params['beta[1]']\nnu = results.params['nu']\npersistence = alpha + beta\n\nprint(f\"  ω = {omega:.6f}\")\nprint(f\"  α = {alpha:.4f} (news reaction)\")\nprint(f\"  β = {beta:.4f} (persistence)\")\nprint(f\"  α + β = {persistence:.4f} (total persistence)\")\nprint(f\"  ν = {nu:.2f} (Student-t degrees of freedom)\")\n\nif persistence < 1:\n    uncond_vol = np.sqrt(omega / (1 - persistence))\n    half_life = np.log(0.5) / np.log(persistence)\n    print(f\"\\n  Unconditional volatility: {uncond_vol:.3f}% daily\")\n    print(f\"  Half-life: {half_life:.1f} trading days\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": "---\n\n## Exercise 2: Model Comparison with Real S&P 500 Data\n\n**Objective:** Compare symmetric and asymmetric GARCH models on real equity data.\n\n**Tasks:**\n1. Download S&P 500 data (equity markets have strong leverage effect)\n2. Estimate GARCH, GJR-GARCH, and EGARCH\n3. Compare using AIC/BIC and test for leverage effect"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": "# Task 1: Download S&P 500 data\nprint(\"Downloading S&P 500 data from Yahoo Finance...\")\n\nsp500 = yf.download('^GSPC', start='2010-01-01', end='2024-12-31', progress=False)\nsp500_close = sp500['Close'].squeeze() if isinstance(sp500['Close'], pd.DataFrame) else sp500['Close']\n\n# Calculate returns\nreturns_sp = (sp500_close.pct_change() * 100).dropna()\nreturns_sp = pd.Series(returns_sp.values, index=returns_sp.index, name='returns')\n\nprint(f\"\\nS&P 500 Data Summary:\")\nprint(f\"Period: {returns_sp.index[0].date()} to {returns_sp.index[-1].date()}\")\nprint(f\"Observations: {len(returns_sp)}\")\nprint(f\"\\nBasic Statistics:\")\nprint(f\"  Mean return: {float(returns_sp.mean()):.4f}%\")\nprint(f\"  Std deviation: {float(returns_sp.std()):.4f}%\")\nprint(f\"  Skewness: {float(stats.skew(returns_sp.values)):.4f} (negative → crashes)\")\nprint(f\"  Kurtosis: {float(stats.kurtosis(returns_sp.values)+3):.4f}\")\n\n# Check for leverage effect empirically\nrolling_vol = returns_sp.rolling(window=5).std()\nneg_returns = returns_sp.shift(1) < 0\nvol_after_neg = rolling_vol[neg_returns].mean()\nvol_after_pos = rolling_vol[~neg_returns].mean()\nprint(f\"\\nEmpirical Leverage Check:\")\nprint(f\"  Vol after negative days: {vol_after_neg:.3f}%\")\nprint(f\"  Vol after positive days: {vol_after_pos:.3f}%\")\nprint(f\"  Ratio: {vol_after_neg/vol_after_pos:.2f}x → Leverage effect present!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": "# Task 2: Estimate all three models on S&P 500\nprint(\"Model Estimation and Comparison - S&P 500\")\nprint(\"=\"*60)\n\n# GARCH(1,1)\nmodel_garch = arch_model(returns_sp.values, vol='Garch', p=1, q=1, dist='t')\nres_garch = model_garch.fit(disp='off')\n\n# GJR-GARCH (o=1 adds asymmetry)\nmodel_gjr = arch_model(returns_sp.values, vol='Garch', p=1, o=1, q=1, dist='t')\nres_gjr = model_gjr.fit(disp='off')\n\n# EGARCH (o=1 is needed for asymmetry term gamma)\nmodel_egarch = arch_model(returns_sp.values, vol='EGARCH', p=1, o=1, q=1, dist='t')\nres_egarch = model_egarch.fit(disp='off')\n\n# Task 3: Compare\nprint(f\"\\n{'Model':<15} {'AIC':>10} {'BIC':>10} {'LogLik':>12}\")\nprint(\"-\"*50)\nprint(f\"{'GARCH(1,1)':<15} {res_garch.aic:>10.2f} {res_garch.bic:>10.2f} {res_garch.loglikelihood:>12.2f}\")\nprint(f\"{'GJR-GARCH':<15} {res_gjr.aic:>10.2f} {res_gjr.bic:>10.2f} {res_gjr.loglikelihood:>12.2f}\")\nprint(f\"{'EGARCH':<15} {res_egarch.aic:>10.2f} {res_egarch.bic:>10.2f} {res_egarch.loglikelihood:>12.2f}\")\n\n# Identify best\nmodels = {'GARCH': res_garch.aic, 'GJR-GARCH': res_gjr.aic, 'EGARCH': res_egarch.aic}\nbest = min(models, key=models.get)\nprint(f\"\\n→ Best model by AIC: {best}\")\nprint(\"→ Asymmetric models outperform GARCH because S&P 500 has strong leverage effect!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": "# Check if leverage is significant in GJR-GARCH\nprint(\"\\nGJR-GARCH: Leverage Effect Test - S&P 500\")\nprint(\"=\"*50)\n\ngamma_est = res_gjr.params['gamma[1]']\ngamma_se = res_gjr.std_err['gamma[1]']\ngamma_tstat = gamma_est / gamma_se\ngamma_pval = 2 * (1 - stats.norm.cdf(abs(gamma_tstat)))\n\nalpha_est = res_gjr.params['alpha[1]']\n\nprint(f\"  α estimate: {alpha_est:.4f} (positive shock impact)\")\nprint(f\"  γ estimate: {gamma_est:.4f} (additional impact of negative shocks)\")\nprint(f\"  Std error:  {gamma_se:.4f}\")\nprint(f\"  t-stat:     {gamma_tstat:.2f}\")\nprint(f\"  p-value:    {gamma_pval:.6f}\")\nprint(f\"\\n  Leverage significant? {'YES ✓' if gamma_pval < 0.05 else 'No'}\")\nprint(f\"\\n  Negative shock impact: α + γ = {alpha_est + gamma_est:.4f}\")\nprint(f\"  Ratio: {(alpha_est + gamma_est)/alpha_est:.2f}x higher for negative shocks!\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": "---\n\n## Exercise 3: Extended Analysis with Longer S&P 500 History\n\n**Objective:** Apply GARCH modeling to long-term equity data covering multiple market regimes.\n\n**Tasks:**\n1. Download extended S&P 500 data (2000-2024) to include 2008 crisis\n2. Calculate returns and test for ARCH effects\n3. Estimate and diagnose GJR-GARCH model"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": "# Task 1: Get extended S&P 500 data (2000-2024)\nprint(\"Downloading extended S&P 500 data (2000-2024)...\")\n\nsp500_long = yf.download('^GSPC', start='2000-01-01', end='2024-12-31', progress=False)\nsp500_long_close = sp500_long['Close'].squeeze() if isinstance(sp500_long['Close'], pd.DataFrame) else sp500_long['Close']\n\n# Calculate returns\nreturns_long = (sp500_long_close.pct_change() * 100).dropna()\nreturns_long = pd.Series(returns_long.values, index=returns_long.index, name='returns')\n\nprint(f\"\\nExtended S&P 500 Data:\")\nprint(f\"Period: {returns_long.index[0].date()} to {returns_long.index[-1].date()}\")\nprint(f\"Observations: {len(returns_long)} (covers 2008 crisis, COVID, etc.)\")\nprint(f\"\\nDescriptive Statistics:\")\nprint(returns_long.describe())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": "# Visualize extended S&P 500 data with crisis periods\nfig, axes = plt.subplots(2, 1, figsize=(14, 8), sharex=True)\n\naxes[0].plot(returns_long.index, returns_long.values, color=COLORS['blue'], linewidth=0.5)\naxes[0].axhline(y=0, color='black', linewidth=0.5)\naxes[0].set_ylabel('Return (%)')\naxes[0].set_title('S&P 500 Daily Returns (2000-2024)', fontweight='bold')\n\n# Mark crisis periods\ncrisis_periods = [\n    ('2008-09-01', '2009-03-31', '2008 Crisis', COLORS['red']),\n    ('2020-02-15', '2020-04-30', 'COVID-19', COLORS['orange']),\n    ('2022-01-01', '2022-10-31', '2022 Bear', COLORS['green'])\n]\nfor start, end, label, color in crisis_periods:\n    axes[0].axvspan(pd.Timestamp(start), pd.Timestamp(end), alpha=0.2, color=color, label=label)\naxes[0].legend(loc='upper center', bbox_to_anchor=(0.5, -0.05), ncol=3)\n\n# Rolling 20-day volatility\nrolling_vol = returns_long.rolling(window=20).std()\naxes[1].plot(rolling_vol.index, rolling_vol.values, color=COLORS['red'], linewidth=0.8)\naxes[1].set_ylabel('Rolling Volatility (%)')\naxes[1].set_xlabel('Date')\naxes[1].set_title('20-Day Rolling Volatility', fontweight='bold')\n\nfor start, end, label, color in crisis_periods:\n    axes[1].axvspan(pd.Timestamp(start), pd.Timestamp(end), alpha=0.2, color=color)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nKey observations:\")\nprint(\"  • 2008 financial crisis: Extreme volatility spike (~10% daily moves)\")\nprint(\"  • COVID-19 crash: Sharp but short volatility spike\")\nprint(\"  • 2022 bear market: Elevated but moderate volatility\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": "# Task 2: Test for ARCH effects\nprint(\"ARCH-LM Test on Extended S&P 500 Data\")\nprint(\"=\"*50)\n\nreturns_demeaned = returns_long.values - returns_long.values.mean()\nfor lags in [5, 10, 20]:\n    lm_stat, lm_pval, _, _ = het_arch(returns_demeaned, nlags=lags)\n    print(f\"  Lags={lags:2d}: LM={lm_stat:8.2f}, p-value={lm_pval:.6f}\")\n\nprint(\"\\n→ Very strong ARCH effects present in long-term S&P 500 data!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": "# Task 3: Estimate GJR-GARCH with Student-t on extended data\nmodel_long = arch_model(returns_long.values, vol='Garch', p=1, o=1, q=1, dist='t')\nres_long = model_long.fit(disp='off')\n\nprint(\"GJR-GARCH(1,1,1) with Student-t - Extended S&P 500 (2000-2024)\")\nprint(\"=\"*60)\nprint(res_long.summary())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": "# Interpretation of extended model\nprint(\"\\nParameter Interpretation - Extended S&P 500\")\nprint(\"=\"*50)\n\nalpha_long = res_long.params['alpha[1]']\ngamma_long = res_long.params['gamma[1]']\nbeta_long = res_long.params['beta[1]']\nnu_long = res_long.params['nu']\n\npersistence = alpha_long + gamma_long/2 + beta_long\nhalf_life = np.log(0.5) / np.log(persistence) if persistence < 1 else float('inf')\n\nprint(f\"  α = {alpha_long:.4f} (news reaction)\")\nprint(f\"  γ = {gamma_long:.4f} (leverage effect)\")\nprint(f\"  β = {beta_long:.4f} (persistence)\")\nprint(f\"  ν = {nu_long:.2f} (Student-t degrees of freedom)\")\nprint(f\"\\n  Persistence (α + γ/2 + β) = {persistence:.4f}\")\nprint(f\"  Half-life = {half_life:.1f} trading days\")\nprint(f\"\\n  Leverage ratio: {(alpha_long + gamma_long)/alpha_long:.2f}x higher impact for negative shocks\")\n\n# Plot conditional volatility\nfig, ax = plt.subplots(figsize=(14, 5))\ncond_vol = res_long.conditional_volatility\nax.plot(returns_long.index, cond_vol, color=COLORS['red'], linewidth=0.8)\nax.fill_between(returns_long.index, 0, cond_vol, color=COLORS['red'], alpha=0.3)\nax.set_ylabel('Conditional Volatility (%)')\nax.set_xlabel('Date')\nax.set_title('GJR-GARCH Conditional Volatility - S&P 500 (2000-2024)', fontweight='bold')\n\nfor start, end, label, color in crisis_periods:\n    ax.axvspan(pd.Timestamp(start), pd.Timestamp(end), alpha=0.15, color='gray')\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": "# Diagnostics on extended model\nstd_resid_long = res_long.std_resid\n\nprint(\"Diagnostic Tests - Extended S&P 500\")\nprint(\"=\"*50)\n\n# Ljung-Box on squared residuals\nlb_test = acorr_ljungbox(std_resid_long**2, lags=10, return_df=True)\nprint(f\"Ljung-Box (z²): Q(10) = {lb_test['lb_stat'].iloc[-1]:.2f}, p-value = {lb_test['lb_pvalue'].iloc[-1]:.4f}\")\n\n# ARCH-LM on standardized residuals\nlm_stat, lm_pval, _, _ = het_arch(std_resid_long, nlags=5)\nprint(f\"ARCH-LM (5 lags): LM = {lm_stat:.2f}, p-value = {lm_pval:.4f}\")\n\nif lm_pval > 0.05:\n    print(\"\\n✓ No remaining ARCH effects - GJR-GARCH model is adequate!\")\nelse:\n    print(\"\\n⚠️ Some ARCH effects remain - consider alternative specifications\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 4: Volatility Forecasting and VaR\n",
    "\n",
    "**Objective:** Generate volatility forecasts and calculate Value at Risk.\n",
    "\n",
    "**Tasks:**\n",
    "1. Forecast volatility 10 days ahead\n",
    "2. Calculate 1-day and 10-day VaR\n",
    "3. Backtest VaR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": "# Task 1: Volatility forecast using extended S&P 500 model\nhorizon = 10\nforecasts = res_long.forecast(horizon=horizon)\nvol_forecast = np.sqrt(forecasts.variance.values[-1, :])\n\nprint(\"Volatility Forecast (next 10 days) - S&P 500\")\nprint(\"=\"*40)\nfor h in range(horizon):\n    print(f\"  Day {h+1}: {vol_forecast[h]:.3f}%\")\n\n# Plot\nfig, ax = plt.subplots(figsize=(12, 5))\n\n# Last 50 days historical\nhist_vol = res_long.conditional_volatility\nax.plot(range(50), hist_vol[-50:], color=COLORS['blue'], label='Historical')\n# Use [-1] instead of .iloc[-1] since it might be numpy array\nlast_hist_vol = hist_vol[-1] if isinstance(hist_vol, np.ndarray) else hist_vol.iloc[-1]\nax.plot(range(49, 49+horizon+1), np.concatenate([[last_hist_vol], vol_forecast]),\n        color=COLORS['red'], linestyle='--', linewidth=2, label='Forecast')\nax.axvline(x=49, color='black', linestyle='-', alpha=0.3)\nax.set_xlabel('Days')\nax.set_ylabel('Volatility (%)')\nax.set_title('S&P 500 Volatility Forecast', fontweight='bold')\nax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.12), ncol=2)\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": "# Task 2: Calculate VaR\nportfolio_value = 1_000_000  # EUR\nsigma_1day = vol_forecast[0] / 100\n\n# Quantiles\nnu = res_long.params['nu']\nq_95_norm = stats.norm.ppf(0.95)\nq_99_norm = stats.norm.ppf(0.99)\nq_95_t = stats.t.ppf(0.95, df=nu) * np.sqrt((nu-2)/nu)\nq_99_t = stats.t.ppf(0.99, df=nu) * np.sqrt((nu-2)/nu)\n\nprint(\"Value at Risk Calculation - S&P 500 Portfolio\")\nprint(\"=\"*50)\nprint(f\"Portfolio: €{portfolio_value:,.0f}\")\nprint(f\"1-day volatility: {sigma_1day*100:.3f}%\")\n\nprint(\"\\n1-Day VaR:\")\nprint(f\"  Normal 95%: €{q_95_norm * sigma_1day * portfolio_value:,.0f}\")\nprint(f\"  Normal 99%: €{q_99_norm * sigma_1day * portfolio_value:,.0f}\")\nprint(f\"  Student-t 95%: €{q_95_t * sigma_1day * portfolio_value:,.0f}\")\nprint(f\"  Student-t 99%: €{q_99_t * sigma_1day * portfolio_value:,.0f}\")\n\n# 10-day VaR (sqrt(10) scaling)\nprint(\"\\n10-Day VaR (scaled):\")\nprint(f\"  Normal 99%: €{q_99_norm * sigma_1day * portfolio_value * np.sqrt(10):,.0f}\")\nprint(f\"  Student-t 99%: €{q_99_t * sigma_1day * portfolio_value * np.sqrt(10):,.0f}\")\n\nprint(f\"\\n→ Student-t VaR is {(q_99_t/q_99_norm - 1)*100:.1f}% higher than Normal VaR\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": "# Task 3: Simple VaR backtest on S&P 500\nprint(\"\\nVaR Backtest (95% level) - S&P 500\")\nprint(\"=\"*50)\n\n# Calculate 1-day VaR for each day\ncond_vol = res_long.conditional_volatility / 100\nVaR_95 = q_95_t * cond_vol\n\n# Count violations (returns < -VaR)\nreturns_dec = returns_long / 100\nviolations = returns_dec < -VaR_95\nviolation_rate = float(violations.mean())\nexpected_rate = 0.05\n\nprint(f\"Expected violation rate: {expected_rate*100:.1f}%\")\nprint(f\"Actual violation rate: {violation_rate*100:.2f}%\")\nprint(f\"Number of violations: {int(violations.sum())} out of {len(violations)}\")\n\n# Kupiec test (proportion of failures)\nn_total = len(violations)\nn_viol = int(violations.sum())\n\n# Handle edge case\nif violation_rate > 0 and violation_rate < 1:\n    LR = 2 * (n_viol * np.log(violation_rate/expected_rate) + \n              (n_total - n_viol) * np.log((1-violation_rate)/(1-expected_rate)))\n    pval = 1 - stats.chi2.cdf(LR, 1)\n    print(f\"\\nKupiec LR test: LR = {LR:.2f}, p-value = {pval:.4f}\")\n    print(f\"Conclusion: {'VaR model adequate ✓' if pval > 0.05 else 'VaR model needs adjustment'}\")\nelse:\n    print(\"\\nKupiec test not applicable (extreme violation rate)\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 5: Bitcoin Volatility Analysis\n",
    "\n",
    "**Objective:** Analyze cryptocurrency volatility and compare with traditional assets.\n",
    "\n",
    "**Tasks:**\n",
    "1. Download Bitcoin data and calculate returns\n",
    "2. Estimate GARCH models\n",
    "3. Compare volatility characteristics with S&P 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": "# Task 1: Get Bitcoin data from Yahoo Finance\nprint(\"Downloading Bitcoin data from Yahoo Finance...\")\n\nbtc = yf.download('BTC-USD', start='2017-01-01', end='2024-12-31', progress=False)\nbtc_close = btc['Close'].squeeze() if isinstance(btc['Close'], pd.DataFrame) else btc['Close']\n\n# Calculate returns\nreturns_btc = (btc_close.pct_change() * 100).dropna()\nreturns_btc = pd.Series(returns_btc.values, index=returns_btc.index, name='returns')\n\nprint(f\"\\nBitcoin Data Summary:\")\nprint(f\"Period: {returns_btc.index[0].date()} to {returns_btc.index[-1].date()}\")\nprint(f\"Observations: {len(returns_btc)}\")\nprint(f\"\\nBasic Statistics:\")\nprint(f\"  Mean return: {float(returns_btc.mean()):.4f}%\")\nprint(f\"  Std deviation: {float(returns_btc.std()):.4f}%\")\nprint(f\"  Min: {float(returns_btc.min()):.2f}%\")\nprint(f\"  Max: {float(returns_btc.max()):.2f}%\")\nprint(f\"  Skewness: {float(stats.skew(returns_btc.values)):.4f}\")\nprint(f\"  Kurtosis: {float(stats.kurtosis(returns_btc.values)+3):.4f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": "# Visualize Bitcoin returns\nfig, axes = plt.subplots(1, 2, figsize=(14, 4))\n\naxes[0].plot(returns_btc.index, returns_btc.values, color=COLORS['orange'], linewidth=0.5)\naxes[0].axhline(y=0, color='black', linewidth=0.5)\naxes[0].set_ylabel('Return (%)')\naxes[0].set_title('Bitcoin Daily Returns (2017-2024)', fontweight='bold')\n\naxes[1].hist(returns_btc.values, bins=100, density=True, color=COLORS['orange'],\n             alpha=0.7, edgecolor='white')\nx = np.linspace(-30, 30, 100)\naxes[1].plot(x, stats.norm.pdf(x, float(returns_btc.mean()), float(returns_btc.std())),\n             color=COLORS['red'], linewidth=2, label='Normal')\nkurtosis_btc = float(stats.kurtosis(returns_btc.values) + 3)\naxes[1].set_title(f'Distribution (Kurtosis = {kurtosis_btc:.1f})', fontweight='bold')\naxes[1].set_xlim(-30, 30)\naxes[1].legend()\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nKey observation: Bitcoin has much higher volatility and fatter tails than S&P 500!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": "# Task 2: Estimate GJR-GARCH model for Bitcoin\nmodel_btc = arch_model(returns_btc.values, vol='Garch', p=1, o=1, q=1, dist='t')\nres_btc = model_btc.fit(disp='off')\n\nprint(\"GJR-GARCH(1,1,1) Estimation - Bitcoin\")\nprint(\"=\"*50)\nprint(res_btc.summary())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": "# Task 3: Comparison with S&P 500\nprint(\"\\nComparison: Bitcoin vs S&P 500 (Real Data)\")\nprint(\"=\"*60)\n\n# Use comparable period\ncommon_start = max(returns_long.index[0], returns_btc.index[0])\ncommon_end = min(returns_long.index[-1], returns_btc.index[-1])\nsp_comp = returns_long[(returns_long.index >= common_start) & (returns_long.index <= common_end)]\nbtc_comp = returns_btc[(returns_btc.index >= common_start) & (returns_btc.index <= common_end)]\n\nprint(f\"\\nComparable period: {common_start.date()} to {common_end.date()}\")\nprint(f\"\\n{'Metric':<25} {'S&P 500':>12} {'Bitcoin':>12}\")\nprint(\"-\"*50)\nprint(f\"{'Mean return (%)':<25} {float(sp_comp.mean()):>12.3f} {float(btc_comp.mean()):>12.3f}\")\nprint(f\"{'Volatility (%)':<25} {float(sp_comp.std()):>12.3f} {float(btc_comp.std()):>12.3f}\")\nprint(f\"{'Skewness':<25} {float(stats.skew(sp_comp.values)):>12.3f} {float(stats.skew(btc_comp.values)):>12.3f}\")\nprint(f\"{'Kurtosis':<25} {float(stats.kurtosis(sp_comp.values)+3):>12.3f} {float(stats.kurtosis(btc_comp.values)+3):>12.3f}\")\n\n# Model parameters comparison\nprint(f\"\\n{'GJR-GARCH Parameters:':<25}\")\nprint(f\"{'α (news reaction)':<25} {res_long.params['alpha[1]']:>12.4f} {res_btc.params['alpha[1]']:>12.4f}\")\nprint(f\"{'γ (leverage)':<25} {res_long.params['gamma[1]']:>12.4f} {res_btc.params['gamma[1]']:>12.4f}\")\nprint(f\"{'β (persistence)':<25} {res_long.params['beta[1]']:>12.4f} {res_btc.params['beta[1]']:>12.4f}\")\nprint(f\"{'ν (Student-t df)':<25} {res_long.params['nu']:>12.2f} {res_btc.params['nu']:>12.2f}\")\n\n# Calculate persistence\npers_sp = res_long.params['alpha[1]'] + res_long.params['gamma[1]']/2 + res_long.params['beta[1]']\npers_btc = res_btc.params['alpha[1]'] + res_btc.params['gamma[1]']/2 + res_btc.params['beta[1]']\nprint(f\"{'Persistence (α+γ/2+β)':<25} {pers_sp:>12.4f} {pers_btc:>12.4f}\")\n\nvol_ratio = float(btc_comp.std()) / float(sp_comp.std())\nprint(f\"\\nKey findings:\")\nprint(f\"  • Bitcoin volatility is ~{vol_ratio:.1f}x higher than S&P 500\")\nprint(f\"  • Bitcoin has {'higher' if res_btc.params['alpha[1]'] > res_long.params['alpha[1]'] else 'lower'} α (faster reaction to news)\")\nprint(f\"  • Bitcoin has {'weaker' if res_btc.params['gamma[1]'] < res_long.params['gamma[1]'] else 'stronger'} leverage effect\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-28",
   "metadata": {},
   "source": "---\n\n## Summary\n\n### What We Learned (Using Real Financial Data)\n\n1. **ARCH-LM test** reliably detects heteroskedasticity in real market data\n   - S&P 500, EUR/USD, and Bitcoin all show strong ARCH effects\n\n2. **GARCH(1,1)** captures volatility dynamics well\n   - α measures news reaction (higher for Bitcoin than S&P 500)\n   - β measures persistence (high for all assets, ~0.85-0.95)\n   - α + β < 1 for stationarity\n\n3. **Asymmetric models** (GJR, EGARCH) capture leverage effect\n   - S&P 500 shows strong leverage effect (γ significant)\n   - Bitcoin shows weaker leverage effect\n   - Negative returns increase volatility more than positive returns\n\n4. **Student-t distribution** essential for real financial data\n   - Degrees of freedom typically 5-10\n   - Produces higher VaR estimates than Normal\n\n5. **VaR calculation** with GARCH is practical\n   - 1-day VaR: ~2-3% of portfolio at 99% confidence\n   - Scale by √T for multi-day horizons\n\n6. **Bitcoin vs S&P 500**\n   - Bitcoin ~3-4x more volatile\n   - Bitcoin reacts faster to news (higher α)\n   - S&P 500 has stronger leverage effect\n\n### Practical Workflow for Real Data\n1. Download data (Yahoo Finance via yfinance)\n2. Calculate returns and basic statistics\n3. Test for ARCH effects (ARCH-LM test)\n4. Estimate GJR-GARCH with Student-t\n5. Check diagnostics (Ljung-Box, ARCH-LM on residuals)\n6. Forecast volatility and calculate VaR"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}