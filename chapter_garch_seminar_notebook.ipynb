{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/danpele/Time-Series-Analysis/blob/main/chapter_garch_seminar_notebook.ipynb)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "# Seminar: GARCH Models - Practice Exercises\n",
    "\n",
    "**Course:** Time Series Analysis and Forecasting  \n",
    "**Program:** Bachelor program, Faculty of Cybernetics, Statistics and Economic Informatics, Bucharest University of Economic Studies, Romania  \n",
    "**Academic Year:** 2025-2026\n",
    "\n",
    "---\n",
    "\n",
    "## Exercises Overview\n",
    "\n",
    "1. **Exercise 1:** ARCH-LM Testing and GARCH Estimation\n",
    "2. **Exercise 2:** Model Comparison (GARCH vs GJR-GARCH vs EGARCH)\n",
    "3. **Exercise 3:** Real Data Analysis - S&P 500\n",
    "4. **Exercise 4:** Volatility Forecasting and VaR\n",
    "5. **Exercise 5:** Bitcoin Volatility Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages if needed\n",
    "try:\n",
    "    from arch import arch_model\n",
    "except ImportError:\n",
    "    !pip install arch yfinance --quiet\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from arch import arch_model\n",
    "from statsmodels.stats.diagnostic import het_arch, acorr_ljungbox\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "try:\n",
    "    import yfinance as yf\n",
    "    HAS_YF = True\n",
    "except:\n",
    "    HAS_YF = False\n",
    "\n",
    "# Plotting style\n",
    "plt.rcParams['figure.figsize'] = (12, 5)\n",
    "plt.rcParams['font.size'] = 11\n",
    "plt.rcParams['axes.facecolor'] = 'none'\n",
    "plt.rcParams['figure.facecolor'] = 'none'\n",
    "plt.rcParams['savefig.transparent'] = True\n",
    "plt.rcParams['axes.grid'] = False\n",
    "plt.rcParams['axes.spines.top'] = False\n",
    "plt.rcParams['axes.spines.right'] = False\n",
    "plt.rcParams['legend.frameon'] = False\n",
    "\n",
    "COLORS = {'blue': '#1A3A6E', 'red': '#DC3545', 'green': '#2E7D32', 'orange': '#E67E22'}\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 1: ARCH-LM Testing and GARCH Estimation\n",
    "\n",
    "**Objective:** Learn to detect ARCH effects and estimate basic GARCH models.\n",
    "\n",
    "**Tasks:**\n",
    "1. Simulate a GARCH(1,1) process\n",
    "2. Apply the ARCH-LM test\n",
    "3. Estimate the model and compare with true parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: Simulate GARCH(1,1)\n",
    "np.random.seed(123)\n",
    "n = 2000\n",
    "\n",
    "# True parameters\n",
    "omega_true = 0.00005\n",
    "alpha_true = 0.12\n",
    "beta_true = 0.83\n",
    "\n",
    "# Initialize\n",
    "sigma2 = np.zeros(n)\n",
    "epsilon = np.zeros(n)\n",
    "sigma2[0] = omega_true / (1 - alpha_true - beta_true)\n",
    "\n",
    "# Generate process\n",
    "for t in range(1, n):\n",
    "    sigma2[t] = omega_true + alpha_true * epsilon[t-1]**2 + beta_true * sigma2[t-1]\n",
    "    epsilon[t] = np.sqrt(sigma2[t]) * np.random.randn()\n",
    "\n",
    "returns = epsilon * 100\n",
    "\n",
    "print(\"True GARCH(1,1) Parameters:\")\n",
    "print(f\"  ω = {omega_true}\")\n",
    "print(f\"  α = {alpha_true}\")\n",
    "print(f\"  β = {beta_true}\")\n",
    "print(f\"  α + β = {alpha_true + beta_true}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: Apply ARCH-LM test\n",
    "print(\"ARCH-LM Test Results:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for lags in [5, 10, 20]:\n",
    "    lm_stat, lm_pval, _, _ = het_arch(returns - returns.mean(), nlags=lags)\n",
    "    result = \"ARCH present\" if lm_pval < 0.05 else \"No ARCH\"\n",
    "    print(f\"  Lags={lags:2d}: LM={lm_stat:8.2f}, p-value={lm_pval:.6f} → {result}\")\n",
    "\n",
    "# Visual check\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "axes[0].plot(returns, color=COLORS['blue'], linewidth=0.5)\n",
    "axes[0].set_title('Returns (Volatility Clustering Visible)', fontweight='bold')\n",
    "\n",
    "plot_acf(returns**2, lags=30, ax=axes[1], color=COLORS['red'],\n",
    "         vlines_kwargs={'color': COLORS['red']})\n",
    "axes[1].set_title('ACF of Squared Returns', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3: Estimate GARCH(1,1) and compare\n",
    "model = arch_model(returns, vol='Garch', p=1, q=1, dist='normal')\n",
    "results = model.fit(disp='off')\n",
    "\n",
    "print(\"\\nParameter Comparison:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"{'Parameter':<12} {'True':>10} {'Estimated':>12} {'Std.Err':>10}\")\n",
    "print(\"-\"*50)\n",
    "print(f\"{'omega':<12} {omega_true:>10.6f} {results.params['omega']:>12.6f} {results.std_err['omega']:>10.6f}\")\n",
    "print(f\"{'alpha':<12} {alpha_true:>10.4f} {results.params['alpha[1]']:>12.4f} {results.std_err['alpha[1]']:>10.4f}\")\n",
    "print(f\"{'beta':<12} {beta_true:>10.4f} {results.params['beta[1]']:>12.4f} {results.std_err['beta[1]']:>10.4f}\")\n",
    "\n",
    "print(\"\\n✓ Estimates are close to true values!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 2: Model Comparison\n",
    "\n",
    "**Objective:** Compare symmetric and asymmetric GARCH models.\n",
    "\n",
    "**Tasks:**\n",
    "1. Simulate data with leverage effect\n",
    "2. Estimate GARCH, GJR-GARCH, and EGARCH\n",
    "3. Compare using AIC/BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: Simulate GJR-GARCH with leverage\n",
    "np.random.seed(789)\n",
    "n = 2000\n",
    "\n",
    "omega = 0.00005\n",
    "alpha = 0.04\n",
    "gamma = 0.10  # Leverage parameter\n",
    "beta = 0.88\n",
    "\n",
    "sigma2_lev = np.zeros(n)\n",
    "eps_lev = np.zeros(n)\n",
    "sigma2_lev[0] = omega / (1 - alpha - gamma/2 - beta)\n",
    "\n",
    "for t in range(1, n):\n",
    "    I = 1 if eps_lev[t-1] < 0 else 0\n",
    "    sigma2_lev[t] = omega + alpha * eps_lev[t-1]**2 + gamma * eps_lev[t-1]**2 * I + beta * sigma2_lev[t-1]\n",
    "    eps_lev[t] = np.sqrt(sigma2_lev[t]) * np.random.randn()\n",
    "\n",
    "returns_lev = eps_lev * 100\n",
    "\n",
    "print(\"True GJR-GARCH Parameters:\")\n",
    "print(f\"  α = {alpha}, γ = {gamma}, β = {beta}\")\n",
    "print(f\"  Positive shock impact: {alpha}\")\n",
    "print(f\"  Negative shock impact: {alpha + gamma}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: Estimate all three models\n",
    "print(\"Model Estimation and Comparison\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# GARCH(1,1)\n",
    "model_garch = arch_model(returns_lev, vol='Garch', p=1, q=1, dist='t')\n",
    "res_garch = model_garch.fit(disp='off')\n",
    "\n",
    "# GJR-GARCH\n",
    "model_gjr = arch_model(returns_lev, vol='Garch', p=1, o=1, q=1, dist='t')\n",
    "res_gjr = model_gjr.fit(disp='off')\n",
    "\n",
    "# EGARCH\n",
    "model_egarch = arch_model(returns_lev, vol='EGARCH', p=1, q=1, dist='t')\n",
    "res_egarch = model_egarch.fit(disp='off')\n",
    "\n",
    "# Task 3: Compare\n",
    "print(f\"\\n{'Model':<15} {'AIC':>10} {'BIC':>10} {'LogLik':>12}\")\n",
    "print(\"-\"*50)\n",
    "print(f\"{'GARCH(1,1)':<15} {res_garch.aic:>10.2f} {res_garch.bic:>10.2f} {res_garch.loglikelihood:>12.2f}\")\n",
    "print(f\"{'GJR-GARCH':<15} {res_gjr.aic:>10.2f} {res_gjr.bic:>10.2f} {res_gjr.loglikelihood:>12.2f}\")\n",
    "print(f\"{'EGARCH':<15} {res_egarch.aic:>10.2f} {res_egarch.bic:>10.2f} {res_egarch.loglikelihood:>12.2f}\")\n",
    "\n",
    "# Identify best\n",
    "models = {'GARCH': res_garch.aic, 'GJR-GARCH': res_gjr.aic, 'EGARCH': res_egarch.aic}\n",
    "best = min(models, key=models.get)\n",
    "print(f\"\\n→ Best model by AIC: {best}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if leverage is significant in GJR-GARCH\n",
    "print(\"\\nGJR-GARCH: Leverage Effect Test\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "gamma_est = res_gjr.params['gamma[1]']\n",
    "gamma_se = res_gjr.std_err['gamma[1]']\n",
    "gamma_tstat = gamma_est / gamma_se\n",
    "gamma_pval = 2 * (1 - stats.norm.cdf(abs(gamma_tstat)))\n",
    "\n",
    "print(f\"  γ estimate: {gamma_est:.4f}\")\n",
    "print(f\"  Std error:  {gamma_se:.4f}\")\n",
    "print(f\"  t-stat:     {gamma_tstat:.2f}\")\n",
    "print(f\"  p-value:    {gamma_pval:.4f}\")\n",
    "print(f\"\\n  Leverage significant? {'Yes ✓' if gamma_pval < 0.05 else 'No'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 3: Real Data Analysis - S&P 500\n",
    "\n",
    "**Objective:** Apply GARCH modeling to real financial data.\n",
    "\n",
    "**Tasks:**\n",
    "1. Download S&P 500 data\n",
    "2. Calculate returns and test for ARCH effects\n",
    "3. Estimate and diagnose GARCH models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: Get S&P 500 data\n",
    "if HAS_YF:\n",
    "    try:\n",
    "        sp500 = yf.download('^GSPC', start='2015-01-01', end='2024-12-31', progress=False)\n",
    "        returns_sp = 100 * sp500['Adj Close'].pct_change().dropna()\n",
    "        DATA_SOURCE = \"Yahoo Finance\"\n",
    "    except:\n",
    "        HAS_YF = False\n",
    "\n",
    "if not HAS_YF:\n",
    "    # Simulated realistic S&P 500 data\n",
    "    np.random.seed(2020)\n",
    "    n = 2500\n",
    "    omega, alpha, gamma, beta = 0.01, 0.08, 0.10, 0.88\n",
    "    sigma2 = np.zeros(n)\n",
    "    eps = np.zeros(n)\n",
    "    sigma2[0] = omega / (1 - alpha - gamma/2 - beta)\n",
    "    for t in range(1, n):\n",
    "        I = 1 if eps[t-1] < 0 else 0\n",
    "        sigma2[t] = omega + alpha * eps[t-1]**2 + gamma * eps[t-1]**2 * I + beta * sigma2[t-1]\n",
    "        eps[t] = np.sqrt(sigma2[t]) * np.random.standard_t(df=6)\n",
    "    returns_sp = pd.Series(eps, index=pd.date_range('2015-01-01', periods=n, freq='B'))\n",
    "    DATA_SOURCE = \"Simulated\"\n",
    "\n",
    "print(f\"Data source: {DATA_SOURCE}\")\n",
    "print(f\"Sample size: {len(returns_sp)} observations\")\n",
    "print(f\"Period: {returns_sp.index[0].date()} to {returns_sp.index[-1].date()}\")\n",
    "print(returns_sp.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8), sharex=True)\n",
    "\n",
    "axes[0].plot(returns_sp.index, returns_sp, color=COLORS['blue'], linewidth=0.5)\n",
    "axes[0].axhline(y=0, color='black', linewidth=0.5)\n",
    "axes[0].set_ylabel('Return (%)')\n",
    "axes[0].set_title(f'S&P 500 Daily Returns ({DATA_SOURCE})', fontweight='bold')\n",
    "\n",
    "# Rolling 20-day volatility\n",
    "rolling_vol = returns_sp.rolling(window=20).std()\n",
    "axes[1].plot(rolling_vol.index, rolling_vol, color=COLORS['red'], linewidth=0.8)\n",
    "axes[1].set_ylabel('Rolling Volatility (%)')\n",
    "axes[1].set_xlabel('Date')\n",
    "axes[1].set_title('20-Day Rolling Volatility', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: Test for ARCH effects\n",
    "print(\"\\nARCH-LM Test on S&P 500 Returns\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for lags in [5, 10, 20]:\n",
    "    lm_stat, lm_pval, _, _ = het_arch(returns_sp - returns_sp.mean(), nlags=lags)\n",
    "    print(f\"  Lags={lags:2d}: LM={lm_stat:8.2f}, p-value={lm_pval:.6f}\")\n",
    "\n",
    "print(\"\\n→ Strong ARCH effects detected!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3: Estimate GJR-GARCH with Student-t\n",
    "model_sp = arch_model(returns_sp, vol='Garch', p=1, o=1, q=1, dist='t')\n",
    "res_sp = model_sp.fit(disp='off')\n",
    "\n",
    "print(res_sp.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpretation\n",
    "print(\"\\nParameter Interpretation\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "alpha_sp = res_sp.params['alpha[1]']\n",
    "gamma_sp = res_sp.params['gamma[1]']\n",
    "beta_sp = res_sp.params['beta[1]']\n",
    "nu_sp = res_sp.params['nu']\n",
    "\n",
    "persistence = alpha_sp + gamma_sp/2 + beta_sp\n",
    "half_life = np.log(0.5) / np.log(persistence) if persistence < 1 else float('inf')\n",
    "\n",
    "print(f\"  α = {alpha_sp:.4f} (news reaction)\")\n",
    "print(f\"  γ = {gamma_sp:.4f} (leverage effect)\")\n",
    "print(f\"  β = {beta_sp:.4f} (persistence)\")\n",
    "print(f\"  ν = {nu_sp:.2f} (Student-t degrees of freedom)\")\n",
    "print(f\"\\n  Persistence (α + γ/2 + β) = {persistence:.4f}\")\n",
    "print(f\"  Half-life = {half_life:.1f} days\")\n",
    "print(f\"\\n  Leverage ratio: {(alpha_sp + gamma_sp)/alpha_sp:.2f}x higher impact for negative shocks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostics\n",
    "std_resid_sp = res_sp.std_resid\n",
    "\n",
    "print(\"\\nDiagnostic Tests\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Ljung-Box on squared residuals\n",
    "lb_test = acorr_ljungbox(std_resid_sp**2, lags=10, return_df=True)\n",
    "print(f\"Ljung-Box (z²): Q(10) = {lb_test['lb_stat'].iloc[-1]:.2f}, p-value = {lb_test['lb_pvalue'].iloc[-1]:.4f}\")\n",
    "\n",
    "# ARCH-LM on standardized residuals\n",
    "lm_stat, lm_pval, _, _ = het_arch(std_resid_sp, nlags=5)\n",
    "print(f\"ARCH-LM (5 lags): LM = {lm_stat:.2f}, p-value = {lm_pval:.4f}\")\n",
    "\n",
    "if lm_pval > 0.05:\n",
    "    print(\"\\n✓ No remaining ARCH effects - model adequate!\")\n",
    "else:\n",
    "    print(\"\\n⚠️ Some ARCH effects remain - consider alternative specifications\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 4: Volatility Forecasting and VaR\n",
    "\n",
    "**Objective:** Generate volatility forecasts and calculate Value at Risk.\n",
    "\n",
    "**Tasks:**\n",
    "1. Forecast volatility 10 days ahead\n",
    "2. Calculate 1-day and 10-day VaR\n",
    "3. Backtest VaR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: Volatility forecast\n",
    "horizon = 10\n",
    "forecasts = res_sp.forecast(horizon=horizon)\n",
    "vol_forecast = np.sqrt(forecasts.variance.values[-1, :])\n",
    "\n",
    "print(\"Volatility Forecast (next 10 days)\")\n",
    "print(\"=\"*40)\n",
    "for h in range(horizon):\n",
    "    print(f\"  Day {h+1}: {vol_forecast[h]:.3f}%\")\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "# Last 50 days historical\n",
    "hist_vol = res_sp.conditional_volatility\n",
    "ax.plot(range(50), hist_vol[-50:], color=COLORS['blue'], label='Historical')\n",
    "ax.plot(range(49, 49+horizon+1), np.concatenate([[hist_vol.iloc[-1]], vol_forecast]),\n",
    "        color=COLORS['red'], linestyle='--', linewidth=2, label='Forecast')\n",
    "ax.axvline(x=49, color='black', linestyle='-', alpha=0.3)\n",
    "ax.set_xlabel('Days')\n",
    "ax.set_ylabel('Volatility (%)')\n",
    "ax.set_title('Volatility Forecast', fontweight='bold')\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.12), ncol=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: Calculate VaR\n",
    "portfolio_value = 1_000_000  # EUR\n",
    "sigma_1day = vol_forecast[0] / 100\n",
    "\n",
    "# Quantiles\n",
    "nu = res_sp.params['nu']\n",
    "q_95_norm = stats.norm.ppf(0.95)\n",
    "q_99_norm = stats.norm.ppf(0.99)\n",
    "q_95_t = stats.t.ppf(0.95, df=nu) * np.sqrt((nu-2)/nu)\n",
    "q_99_t = stats.t.ppf(0.99, df=nu) * np.sqrt((nu-2)/nu)\n",
    "\n",
    "print(\"Value at Risk Calculation\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Portfolio: €{portfolio_value:,.0f}\")\n",
    "print(f\"1-day volatility: {sigma_1day*100:.2f}%\")\n",
    "\n",
    "print(\"\\n1-Day VaR:\")\n",
    "print(f\"  Normal 95%: €{q_95_norm * sigma_1day * portfolio_value:,.0f}\")\n",
    "print(f\"  Normal 99%: €{q_99_norm * sigma_1day * portfolio_value:,.0f}\")\n",
    "print(f\"  Student-t 95%: €{q_95_t * sigma_1day * portfolio_value:,.0f}\")\n",
    "print(f\"  Student-t 99%: €{q_99_t * sigma_1day * portfolio_value:,.0f}\")\n",
    "\n",
    "# 10-day VaR (sqrt(10) scaling)\n",
    "print(\"\\n10-Day VaR (scaled):\")\n",
    "print(f\"  Normal 99%: €{q_99_norm * sigma_1day * portfolio_value * np.sqrt(10):,.0f}\")\n",
    "print(f\"  Student-t 99%: €{q_99_t * sigma_1day * portfolio_value * np.sqrt(10):,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3: Simple VaR backtest\n",
    "print(\"\\nVaR Backtest (95% level)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Calculate 1-day VaR for each day\n",
    "cond_vol = res_sp.conditional_volatility / 100\n",
    "VaR_95 = q_95_t * cond_vol\n",
    "\n",
    "# Count violations (returns < -VaR)\n",
    "returns_dec = returns_sp / 100\n",
    "violations = returns_dec < -VaR_95\n",
    "violation_rate = violations.mean()\n",
    "expected_rate = 0.05\n",
    "\n",
    "print(f\"Expected violation rate: {expected_rate*100:.1f}%\")\n",
    "print(f\"Actual violation rate: {violation_rate*100:.2f}%\")\n",
    "print(f\"Number of violations: {violations.sum()} out of {len(violations)}\")\n",
    "\n",
    "# Kupiec test (proportion of failures)\n",
    "n_total = len(violations)\n",
    "n_viol = violations.sum()\n",
    "LR = 2 * (n_viol * np.log(violation_rate/expected_rate) + \n",
    "          (n_total - n_viol) * np.log((1-violation_rate)/(1-expected_rate)))\n",
    "pval = 1 - stats.chi2.cdf(LR, 1)\n",
    "\n",
    "print(f\"\\nKupiec LR test: LR = {LR:.2f}, p-value = {pval:.4f}\")\n",
    "print(f\"Conclusion: {'VaR model adequate ✓' if pval > 0.05 else 'VaR model inadequate ✗'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 5: Bitcoin Volatility Analysis\n",
    "\n",
    "**Objective:** Analyze cryptocurrency volatility and compare with traditional assets.\n",
    "\n",
    "**Tasks:**\n",
    "1. Download Bitcoin data and calculate returns\n",
    "2. Estimate GARCH models\n",
    "3. Compare volatility characteristics with S&P 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: Get Bitcoin data\n",
    "if HAS_YF:\n",
    "    try:\n",
    "        btc = yf.download('BTC-USD', start='2018-01-01', end='2024-12-31', progress=False)\n",
    "        returns_btc = 100 * btc['Adj Close'].pct_change().dropna()\n",
    "        BTC_SOURCE = \"Yahoo Finance\"\n",
    "    except:\n",
    "        HAS_YF = False\n",
    "\n",
    "if not HAS_YF:\n",
    "    # Simulate Bitcoin-like volatility (higher than S&P)\n",
    "    np.random.seed(2021)\n",
    "    n = 2000\n",
    "    omega, alpha, gamma, beta = 0.5, 0.15, 0.08, 0.80\n",
    "    sigma2 = np.zeros(n)\n",
    "    eps = np.zeros(n)\n",
    "    sigma2[0] = omega / (1 - alpha - gamma/2 - beta)\n",
    "    for t in range(1, n):\n",
    "        I = 1 if eps[t-1] < 0 else 0\n",
    "        sigma2[t] = omega + alpha * eps[t-1]**2 + gamma * eps[t-1]**2 * I + beta * sigma2[t-1]\n",
    "        eps[t] = np.sqrt(sigma2[t]) * np.random.standard_t(df=5)\n",
    "    returns_btc = pd.Series(eps, index=pd.date_range('2018-01-01', periods=n, freq='B'))\n",
    "    BTC_SOURCE = \"Simulated\"\n",
    "\n",
    "print(f\"Bitcoin data source: {BTC_SOURCE}\")\n",
    "print(f\"Sample: {len(returns_btc)} observations\")\n",
    "print(f\"\\nBasic statistics:\")\n",
    "print(returns_btc.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Bitcoin returns\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "axes[0].plot(returns_btc.index, returns_btc, color=COLORS['orange'], linewidth=0.5)\n",
    "axes[0].axhline(y=0, color='black', linewidth=0.5)\n",
    "axes[0].set_ylabel('Return (%)')\n",
    "axes[0].set_title(f'Bitcoin Daily Returns ({BTC_SOURCE})', fontweight='bold')\n",
    "\n",
    "axes[1].hist(returns_btc, bins=100, density=True, color=COLORS['orange'],\n",
    "             alpha=0.7, edgecolor='white')\n",
    "x = np.linspace(returns_btc.min(), returns_btc.max(), 100)\n",
    "axes[1].plot(x, stats.norm.pdf(x, returns_btc.mean(), returns_btc.std()),\n",
    "             color=COLORS['red'], linewidth=2)\n",
    "axes[1].set_title(f'Distribution (Kurtosis = {stats.kurtosis(returns_btc)+3:.1f})', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: Estimate GARCH model for Bitcoin\n",
    "model_btc = arch_model(returns_btc, vol='Garch', p=1, o=1, q=1, dist='t')\n",
    "res_btc = model_btc.fit(disp='off')\n",
    "\n",
    "print(res_btc.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3: Comparison with S&P 500\n",
    "print(\"\\nComparison: Bitcoin vs S&P 500\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get comparable sample\n",
    "common_start = max(returns_sp.index[0], returns_btc.index[0])\n",
    "common_end = min(returns_sp.index[-1], returns_btc.index[-1])\n",
    "sp_comp = returns_sp[(returns_sp.index >= common_start) & (returns_sp.index <= common_end)]\n",
    "btc_comp = returns_btc[(returns_btc.index >= common_start) & (returns_btc.index <= common_end)]\n",
    "\n",
    "print(f\"\\n{'Metric':<25} {'S&P 500':>12} {'Bitcoin':>12}\")\n",
    "print(\"-\"*50)\n",
    "print(f\"{'Mean return (%)':<25} {sp_comp.mean():>12.3f} {btc_comp.mean():>12.3f}\")\n",
    "print(f\"{'Volatility (%)':<25} {sp_comp.std():>12.3f} {btc_comp.std():>12.3f}\")\n",
    "print(f\"{'Skewness':<25} {stats.skew(sp_comp):>12.3f} {stats.skew(btc_comp):>12.3f}\")\n",
    "print(f\"{'Kurtosis':<25} {stats.kurtosis(sp_comp)+3:>12.3f} {stats.kurtosis(btc_comp)+3:>12.3f}\")\n",
    "\n",
    "# Model parameters\n",
    "print(f\"\\n{'GARCH Parameters:':<25}\")\n",
    "print(f\"{'α (news reaction)':<25} {res_sp.params['alpha[1]']:>12.4f} {res_btc.params['alpha[1]']:>12.4f}\")\n",
    "print(f\"{'γ (leverage)':<25} {res_sp.params['gamma[1]']:>12.4f} {res_btc.params['gamma[1]']:>12.4f}\")\n",
    "print(f\"{'β (persistence)':<25} {res_sp.params['beta[1]']:>12.4f} {res_btc.params['beta[1]']:>12.4f}\")\n",
    "print(f\"{'ν (Student-t df)':<25} {res_sp.params['nu']:>12.2f} {res_btc.params['nu']:>12.2f}\")\n",
    "\n",
    "# Calculate persistence\n",
    "pers_sp = res_sp.params['alpha[1]'] + res_sp.params['gamma[1]']/2 + res_sp.params['beta[1]']\n",
    "pers_btc = res_btc.params['alpha[1]'] + res_btc.params['gamma[1]']/2 + res_btc.params['beta[1]']\n",
    "print(f\"{'Persistence (α+γ/2+β)':<25} {pers_sp:>12.4f} {pers_btc:>12.4f}\")\n",
    "\n",
    "print(\"\\nKey findings:\")\n",
    "print(f\"  - Bitcoin volatility is ~{btc_comp.std()/sp_comp.std():.1f}x higher than S&P 500\")\n",
    "print(f\"  - Bitcoin has {'higher' if res_btc.params['alpha[1]'] > res_sp.params['alpha[1]'] else 'lower'} α (faster reaction to news)\")\n",
    "print(f\"  - Bitcoin has {'weaker' if res_btc.params['gamma[1]'] < res_sp.params['gamma[1]'] else 'stronger'} leverage effect\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-28",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "### What We Learned\n",
    "\n",
    "1. **ARCH-LM test** detects heteroskedasticity in financial returns\n",
    "\n",
    "2. **GARCH(1,1)** is sufficient for most applications\n",
    "   - α measures news reaction\n",
    "   - β measures persistence\n",
    "   - α + β < 1 for stationarity\n",
    "\n",
    "3. **Asymmetric models** (GJR, EGARCH) capture leverage effect\n",
    "   - γ > 0 in GJR-GARCH indicates leverage\n",
    "   - γ < 0 in EGARCH indicates leverage\n",
    "\n",
    "4. **Student-t distribution** better captures fat tails\n",
    "\n",
    "5. **VaR calculation** uses volatility forecasts\n",
    "   - Student-t gives higher VaR than normal\n",
    "\n",
    "6. **Cryptocurrencies** have higher volatility but similar GARCH dynamics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
