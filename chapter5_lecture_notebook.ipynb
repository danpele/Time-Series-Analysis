{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/danpele/Time-Series-Analysis/blob/main/chapter5_lecture_notebook.ipynb)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "# Chapter 5: VAR Models and Granger Causality\n",
    "\n",
    "**Course:** Time Series Analysis and Forecasting  \n",
    "**Program:** Bachelor program, Faculty of Cybernetics, Statistics and Economic Informatics, Bucharest University of Economic Studies, Romania  \n",
    "**Academic Year:** 2025-2026\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "1. Understand the structure of Vector Autoregression (VAR) models\n",
    "2. Estimate VAR models and select optimal lag order\n",
    "3. Conduct and interpret Granger causality tests\n",
    "4. Compute and interpret Impulse Response Functions (IRF)\n",
    "5. Perform Forecast Error Variance Decomposition (FEVD)\n",
    "6. Understand cointegration and Vector Error Correction Models (VECM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": "# Core libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# VAR and multivariate time series\nfrom statsmodels.tsa.api import VAR\nfrom statsmodels.tsa.stattools import adfuller, grangercausalitytests, ccf\nfrom statsmodels.tsa.vector_ar.vecm import coint_johansen, VECM\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfrom scipy import stats\n\n# For fetching real data\ntry:\n    import pandas_datareader.data as web\n    HAS_PDR = True\nexcept ImportError:\n    HAS_PDR = False\n    print(\"Note: pandas_datareader not installed. Install with: pip install pandas-datareader\")\n\n# Plotting style - clean, professional\nplt.rcParams['figure.figsize'] = (12, 5)\nplt.rcParams['font.size'] = 11\nplt.rcParams['axes.facecolor'] = 'none'\nplt.rcParams['figure.facecolor'] = 'none'\nplt.rcParams['savefig.facecolor'] = 'none'\nplt.rcParams['axes.grid'] = False\nplt.rcParams['axes.spines.top'] = False\nplt.rcParams['axes.spines.right'] = False\n\n# Colors (IDA color scheme)\nCOLORS = {\n    'blue': '#1A3A6E',\n    'red': '#DC3545',\n    'green': '#2E7D32',\n    'orange': '#E67E22',\n    'gray': '#666666'\n}\n\nprint(\"All libraries loaded successfully!\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## 1. Introduction to Multivariate Time Series\n",
    "\n",
    "In many applications, we have **multiple time series** that are related:\n",
    "- GDP, consumption, investment, government spending\n",
    "- Stock prices of related companies\n",
    "- Interest rates at different maturities\n",
    "- Inflation and unemployment (Phillips curve)\n",
    "\n",
    "**Why multivariate models?**\n",
    "- Capture interdependencies between variables\n",
    "- Improve forecasts by using information from related series\n",
    "- Analyze dynamic relationships (causality, impulse responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": "# Fetch REAL macroeconomic data from FRED\n# GDP Growth (quarterly, annualized) and CPI Inflation (monthly → quarterly)\n\nstart_date = '1990-01-01'\nend_date = '2024-12-31'\n\nif HAS_PDR:\n    try:\n        # Fetch from FRED (Federal Reserve Economic Data)\n        # A191RL1Q225SBEA = Real GDP Growth Rate (quarterly, annualized)\n        # CPIAUCSL = Consumer Price Index (monthly)\n        \n        gdp_growth = web.DataReader('A191RL1Q225SBEA', 'fred', start_date, end_date)\n        cpi = web.DataReader('CPIAUCSL', 'fred', start_date, end_date)\n        \n        # Convert CPI to quarterly and compute year-over-year inflation\n        cpi_quarterly = cpi.resample('QE').last()\n        inflation = cpi_quarterly.pct_change(4) * 100  # Year-over-year % change\n        \n        # Align and combine\n        data = pd.DataFrame({\n            'GDP_Growth': gdp_growth['A191RL1Q225SBEA'],\n            'Inflation': inflation['CPIAUCSL']\n        }).dropna()\n        \n        print(f\"✓ Real FRED Data Loaded: {len(data)} quarterly observations\")\n        print(f\"  Period: {data.index[0].strftime('%Y-Q%q')} to {data.index[-1].strftime('%Y-Q%q')}\")\n        DATA_SOURCE = \"FRED (Federal Reserve Economic Data)\"\n        \n    except Exception as e:\n        print(f\"Could not fetch FRED data: {e}\")\n        print(\"Using simulated data as fallback...\")\n        HAS_PDR = False\n\nif not HAS_PDR:\n    # Fallback: Simulated data\n    np.random.seed(42)\n    n = 140  # ~35 years quarterly\n    \n    Y1 = np.zeros(n)  # GDP growth\n    Y2 = np.zeros(n)  # Inflation\n    \n    for t in range(1, n):\n        Y1[t] = 0.5 * Y1[t-1] + 0.15 * Y2[t-1] + np.random.randn() * 1.5 + 2.5\n        Y2[t] = 0.1 * Y1[t-1] + 0.7 * Y2[t-1] + np.random.randn() * 0.8 + 1.5\n    \n    data = pd.DataFrame({\n        'GDP_Growth': Y1,\n        'Inflation': Y2\n    }, index=pd.date_range('1990-01', periods=n, freq='QE'))\n    \n    DATA_SOURCE = \"Simulated (fallback)\"\n    print(f\"Using simulated data: {len(data)} observations\")\n\nprint(f\"\\nData Source: {DATA_SOURCE}\")\nprint(data.describe().round(2))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": "# Plot the multivariate time series\nfig, axes = plt.subplots(2, 1, figsize=(14, 8), sharex=True)\n\naxes[0].plot(data.index, data['GDP_Growth'], color=COLORS['blue'], linewidth=1, label='GDP Growth')\naxes[0].axhline(y=data['GDP_Growth'].mean(), color='red', linestyle='--', alpha=0.5, label=f'Mean: {data[\"GDP_Growth\"].mean():.1f}%')\naxes[0].axhline(y=0, color='black', linestyle='-', alpha=0.2)\naxes[0].set_title(f'US Real GDP Growth Rate (Quarterly, Annualized) - {DATA_SOURCE}', fontweight='bold')\naxes[0].set_ylabel('% Change')\naxes[0].legend(loc='upper right', frameon=False)\n\naxes[1].plot(data.index, data['Inflation'], color=COLORS['orange'], linewidth=1, label='Inflation')\naxes[1].axhline(y=data['Inflation'].mean(), color='red', linestyle='--', alpha=0.5, label=f'Mean: {data[\"Inflation\"].mean():.1f}%')\naxes[1].set_title('US CPI Inflation Rate (Year-over-Year)', fontweight='bold')\naxes[1].set_xlabel('Date')\naxes[1].set_ylabel('% Change')\naxes[1].legend(loc='upper right', frameon=False)\n\nplt.tight_layout()\nplt.show()\n\n# Correlation and basic statistics\nprint(f\"\\nCorrelation between GDP Growth and Inflation: {data['GDP_Growth'].corr(data['Inflation']):.4f}\")\nprint(f\"\\nNote: Using REAL macroeconomic data allows us to discover actual\")\nprint(f\"      economic relationships rather than recovering known parameters.\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 2. The VAR(p) Model\n",
    "\n",
    "A **Vector Autoregression of order p**, VAR(p), for $K$ variables is:\n",
    "\n",
    "$$\\mathbf{Y}_t = \\mathbf{c} + \\mathbf{A}_1 \\mathbf{Y}_{t-1} + \\mathbf{A}_2 \\mathbf{Y}_{t-2} + \\cdots + \\mathbf{A}_p \\mathbf{Y}_{t-p} + \\boldsymbol{\\varepsilon}_t$$\n",
    "\n",
    "where:\n",
    "- $\\mathbf{Y}_t$ is a $K \\times 1$ vector of endogenous variables\n",
    "- $\\mathbf{c}$ is a $K \\times 1$ vector of constants\n",
    "- $\\mathbf{A}_i$ are $K \\times K$ coefficient matrices\n",
    "- $\\boldsymbol{\\varepsilon}_t$ is a $K \\times 1$ vector of white noise errors\n",
    "\n",
    "### Number of Parameters\n",
    "- Each equation has: $1 + Kp$ parameters (constant + K coefficients × p lags)\n",
    "- Total system: $K(1 + Kp)$ parameters\n",
    "- Plus $K(K+1)/2$ covariance parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAR(1) in matrix form\n",
    "print(\"VAR(1) for 2 Variables:\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "print(\"[ Y1_t ]   [ c1 ]   [ a11  a12 ] [ Y1_{t-1} ]   [ e1_t ]\")\n",
    "print(\"[      ] = [    ] + [          ] [          ] + [      ]\")\n",
    "print(\"[ Y2_t ]   [ c2 ]   [ a21  a22 ] [ Y2_{t-1} ]   [ e2_t ]\")\n",
    "print()\n",
    "print(\"Written as two equations:\")\n",
    "print(\"  Y1_t = c1 + a11*Y1_{t-1} + a12*Y2_{t-1} + e1_t\")\n",
    "print(\"  Y2_t = c2 + a21*Y1_{t-1} + a22*Y2_{t-1} + e2_t\")\n",
    "print()\n",
    "print(f\"Parameters per equation: 1 + K*p = 1 + 2*1 = 3\")\n",
    "print(f\"Total parameters: K*(1 + K*p) = 2*(1 + 2*1) = 6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## 3. VAR Stability Condition\n",
    "\n",
    "A VAR(p) is **stable** (stationary) if all eigenvalues of the companion matrix lie inside the unit circle:\n",
    "\n",
    "$$|\\lambda_i| < 1 \\quad \\text{for all } i$$\n",
    "\n",
    "### Companion Form\n",
    "Any VAR(p) can be written as a VAR(1) in companion form:\n",
    "\n",
    "$$\\mathbf{Z}_t = \\mathbf{A} \\mathbf{Z}_{t-1} + \\mathbf{u}_t$$\n",
    "\n",
    "where $\\mathbf{Z}_t = [\\mathbf{Y}_t', \\mathbf{Y}_{t-1}', ..., \\mathbf{Y}_{t-p+1}']'$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": "# Demonstrate stability condition with an example\n# We'll check stability after fitting the model to real data\n\n# For illustration, show a stable vs unstable example\nprint(\"Example: Stable vs Unstable VAR(1) Systems\")\nprint(\"=\"*60)\n\n# Stable system\nA_stable = np.array([[0.6, 0.2],\n                     [0.1, 0.5]])\neig_stable = np.linalg.eigvals(A_stable)\n\n# Unstable system (unit root)\nA_unstable = np.array([[0.9, 0.2],\n                       [0.1, 0.95]])\neig_unstable = np.linalg.eigvals(A_unstable)\n\nprint(\"\\nStable System:\")\nprint(f\"  A = [[0.6, 0.2], [0.1, 0.5]]\")\nprint(f\"  Eigenvalues: {eig_stable.round(3)}\")\nprint(f\"  Moduli: {np.abs(eig_stable).round(3)}\")\nprint(f\"  Stable: {all(np.abs(eig_stable) < 1)} ✓\")\n\nprint(\"\\nUnstable System:\")\nprint(f\"  A = [[0.9, 0.2], [0.1, 0.95]]\")\nprint(f\"  Eigenvalues: {eig_unstable.round(3)}\")\nprint(f\"  Moduli: {np.abs(eig_unstable).round(3)}\")\nprint(f\"  Stable: {all(np.abs(eig_unstable) < 1)} ✗\")\n\n# Visualize in complex plane\nfig, ax = plt.subplots(figsize=(7, 7))\n\n# Unit circle\ntheta = np.linspace(0, 2*np.pi, 100)\nax.plot(np.cos(theta), np.sin(theta), 'k--', alpha=0.5, label='Unit Circle')\n\n# Eigenvalues\nax.scatter(eig_stable.real, eig_stable.imag, s=200, c=COLORS['green'], \n           marker='o', linewidths=2, label='Stable (inside)', zorder=5)\nax.scatter(eig_unstable.real, eig_unstable.imag, s=200, c=COLORS['red'], \n           marker='x', linewidths=3, label='Unstable (on/outside)', zorder=5)\n\nax.set_xlim(-1.5, 1.5)\nax.set_ylim(-1.5, 1.5)\nax.set_aspect('equal')\nax.axhline(y=0, color='gray', linewidth=0.5)\nax.axvline(x=0, color='gray', linewidth=0.5)\nax.set_xlabel('Real')\nax.set_ylabel('Imaginary')\nax.set_title('VAR Stability: Eigenvalues and the Unit Circle', fontweight='bold')\nax.legend(loc='upper left', frameon=False)\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## 4. Estimating VAR Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit VAR model\n",
    "model = VAR(data)\n",
    "\n",
    "# Select optimal lag order\n",
    "lag_selection = model.select_order(maxlags=8)\n",
    "print(\"Lag Order Selection Criteria:\")\n",
    "print(lag_selection.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit VAR(1) based on BIC\n",
    "results = model.fit(1)\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": "# Examine estimated coefficients and check stability\nprint(\"Estimated VAR Coefficients:\")\nprint(\"=\"*50)\n\n# Get coefficient matrices\nfor i, coef in enumerate(results.coefs):\n    print(f\"\\nLag {i+1} coefficient matrix A_{i+1}:\")\n    print(pd.DataFrame(coef, \n                       index=data.columns,\n                       columns=data.columns).round(4))\n\n# Check stability of estimated model\nprint(\"\\n\" + \"=\"*50)\nprint(\"Stability Check:\")\nprint(\"=\"*50)\n\n# For VAR(p), stability is checked via companion matrix\n# statsmodels provides this\nroots = results.roots\nprint(f\"\\nCharacteristic roots (inverse eigenvalues):\")\nfor i, root in enumerate(roots):\n    print(f\"  Root {i+1}: {root:.4f} (modulus: {np.abs(root):.4f})\")\n\nprint(f\"\\nVAR is stable: {all(np.abs(roots) < 1)}\")\n\nif all(np.abs(roots) < 1):\n    print(\"✓ All roots inside unit circle - model is stable\")\nelse:\n    print(\"✗ Warning: Some roots on or outside unit circle\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## 5. Granger Causality\n",
    "\n",
    "**Granger causality** tests whether lagged values of one variable help predict another.\n",
    "\n",
    "### Definition\n",
    "$X$ **Granger-causes** $Y$ if:\n",
    "- Past values of $X$ contain information useful for predicting $Y$\n",
    "- Beyond what is already contained in past values of $Y$ itself\n",
    "\n",
    "### The Test\n",
    "In a VAR with $Y$ and $X$:\n",
    "$$Y_t = c + \\sum_{i=1}^p \\alpha_i Y_{t-i} + \\sum_{i=1}^p \\beta_i X_{t-i} + \\varepsilon_t$$\n",
    "\n",
    "Test $H_0: \\beta_1 = \\beta_2 = \\cdots = \\beta_p = 0$ (X does NOT Granger-cause Y)\n",
    "\n",
    "### Important Caveats\n",
    "- Granger causality ≠ true causality\n",
    "- May be spurious due to omitted variables\n",
    "- Sensitive to lag selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Granger causality tests\n",
    "print(\"Granger Causality Tests\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Test: Does Inflation Granger-cause GDP Growth?\n",
    "print(\"\\n1. H₀: Inflation does NOT Granger-cause GDP Growth\")\n",
    "print(\"-\"*50)\n",
    "gc_infl_to_gdp = grangercausalitytests(data[['GDP_Growth', 'Inflation']], maxlag=4, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Does GDP Growth Granger-cause Inflation?\n",
    "print(\"\\n2. H₀: GDP Growth does NOT Granger-cause Inflation\")\n",
    "print(\"-\"*50)\n",
    "gc_gdp_to_infl = grangercausalitytests(data[['Inflation', 'GDP_Growth']], maxlag=4, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of Granger causality\n",
    "print(\"\\nGranger Causality Summary (at lag 1):\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "p_infl_to_gdp = gc_infl_to_gdp[1][0]['ssr_ftest'][1]\n",
    "p_gdp_to_infl = gc_gdp_to_infl[1][0]['ssr_ftest'][1]\n",
    "\n",
    "print(f\"Inflation → GDP: p-value = {p_infl_to_gdp:.4f} {'✓ Significant' if p_infl_to_gdp < 0.05 else '✗ Not significant'}\")\n",
    "print(f\"GDP → Inflation: p-value = {p_gdp_to_infl:.4f} {'✓ Significant' if p_gdp_to_infl < 0.05 else '✗ Not significant'}\")\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "if p_infl_to_gdp < 0.05 and p_gdp_to_infl < 0.05:\n",
    "    print(\"  Bidirectional causality (feedback)\")\n",
    "elif p_infl_to_gdp < 0.05:\n",
    "    print(\"  Inflation Granger-causes GDP (unidirectional)\")\n",
    "elif p_gdp_to_infl < 0.05:\n",
    "    print(\"  GDP Granger-causes Inflation (unidirectional)\")\n",
    "else:\n",
    "    print(\"  No Granger causality detected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## 6. Impulse Response Functions (IRF)\n",
    "\n",
    "**Impulse Response Functions** trace the effect of a one-time shock to one variable on all variables over time.\n",
    "\n",
    "$$\\text{IRF}_{ij}(h) = \\frac{\\partial Y_{i,t+h}}{\\partial \\varepsilon_{j,t}}$$\n",
    "\n",
    "### Key Properties\n",
    "- Shows dynamic multipliers\n",
    "- For stable VAR: IRF → 0 as h → ∞\n",
    "- Requires identification (e.g., Cholesky ordering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute IRFs\n",
    "irf = results.irf(20)\n",
    "\n",
    "# Plot IRFs\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Response to GDP shock\n",
    "axes[0, 0].plot(irf.irfs[:, 0, 0], color=COLORS['blue'], linewidth=2, label='IRF')\n",
    "axes[0, 0].fill_between(range(21), \n",
    "                        irf.irfs[:, 0, 0] - 1.96*irf.stderr()[:, 0, 0],\n",
    "                        irf.irfs[:, 0, 0] + 1.96*irf.stderr()[:, 0, 0], \n",
    "                        alpha=0.2, color=COLORS['blue'], label='95% CI')\n",
    "axes[0, 0].axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "axes[0, 0].set_title('GDP → GDP', fontweight='bold')\n",
    "axes[0, 0].legend(loc='upper right', frameon=False)\n",
    "\n",
    "axes[0, 1].plot(irf.irfs[:, 1, 0], color=COLORS['blue'], linewidth=2, label='IRF')\n",
    "axes[0, 1].fill_between(range(21), \n",
    "                        irf.irfs[:, 1, 0] - 1.96*irf.stderr()[:, 1, 0],\n",
    "                        irf.irfs[:, 1, 0] + 1.96*irf.stderr()[:, 1, 0], \n",
    "                        alpha=0.2, color=COLORS['blue'], label='95% CI')\n",
    "axes[0, 1].axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "axes[0, 1].set_title('GDP → Inflation', fontweight='bold')\n",
    "axes[0, 1].legend(loc='upper right', frameon=False)\n",
    "\n",
    "# Response to Inflation shock\n",
    "axes[1, 0].plot(irf.irfs[:, 0, 1], color=COLORS['orange'], linewidth=2, label='IRF')\n",
    "axes[1, 0].fill_between(range(21), \n",
    "                        irf.irfs[:, 0, 1] - 1.96*irf.stderr()[:, 0, 1],\n",
    "                        irf.irfs[:, 0, 1] + 1.96*irf.stderr()[:, 0, 1], \n",
    "                        alpha=0.2, color=COLORS['orange'], label='95% CI')\n",
    "axes[1, 0].axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "axes[1, 0].set_title('Inflation → GDP', fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Horizon (months)')\n",
    "axes[1, 0].legend(loc='upper right', frameon=False)\n",
    "\n",
    "axes[1, 1].plot(irf.irfs[:, 1, 1], color=COLORS['orange'], linewidth=2, label='IRF')\n",
    "axes[1, 1].fill_between(range(21), \n",
    "                        irf.irfs[:, 1, 1] - 1.96*irf.stderr()[:, 1, 1],\n",
    "                        irf.irfs[:, 1, 1] + 1.96*irf.stderr()[:, 1, 1], \n",
    "                        alpha=0.2, color=COLORS['orange'], label='95% CI')\n",
    "axes[1, 1].axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "axes[1, 1].set_title('Inflation → Inflation', fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Horizon (months)')\n",
    "axes[1, 1].legend(loc='upper right', frameon=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"IRF Interpretation:\")\n",
    "print(\"- Own shocks have immediate impact, then decay\")\n",
    "print(\"- Cross shocks show spillover effects\")\n",
    "print(\"- All responses converge to 0 (stable VAR)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## 7. Forecast Error Variance Decomposition (FEVD)\n",
    "\n",
    "**FEVD** decomposes the variance of forecast errors into contributions from each shock.\n",
    "\n",
    "$$\\text{FEVD}_{ij}(h) = \\frac{\\text{Variance of } Y_i \\text{ due to shock } j}{\\text{Total variance of } Y_i}$$\n",
    "\n",
    "### Interpretation\n",
    "- Shows relative importance of each shock\n",
    "- At h=0: own shock explains 100%\n",
    "- As h increases: shows long-run importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": "# Compute FEVD\nfevd = results.fevd(20)\n\n# Get the number of periods and variables\nn_periods = fevd.periods + 1  # +1 because it includes period 0\nn_vars = len(data.columns)\nhorizons = range(n_periods)\n\n# Extract FEVD data properly - fevd.decomp shape is (periods, neqs, neqs)\n# fevd.decomp[h, i, j] = fraction of variance of variable i explained by shock j at horizon h\n\n# Plot FEVD\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# FEVD for GDP Growth (variable 0)\ngdp_by_gdp = [fevd.decomp[h, 0, 0] * 100 for h in range(n_periods)]\ngdp_by_infl = [fevd.decomp[h, 0, 1] * 100 for h in range(n_periods)]\n\naxes[0].stackplot(horizons, gdp_by_gdp, gdp_by_infl,\n                  labels=['GDP shock', 'Inflation shock'],\n                  colors=[COLORS['blue'], COLORS['orange']], alpha=0.7)\naxes[0].set_title('FEVD of GDP Growth', fontweight='bold')\naxes[0].set_xlabel('Horizon (quarters)')\naxes[0].set_ylabel('Percent')\naxes[0].legend(loc='center right', frameon=False)\naxes[0].set_ylim(0, 100)\n\n# FEVD for Inflation (variable 1)\ninfl_by_gdp = [fevd.decomp[h, 1, 0] * 100 for h in range(n_periods)]\ninfl_by_infl = [fevd.decomp[h, 1, 1] * 100 for h in range(n_periods)]\n\naxes[1].stackplot(horizons, infl_by_gdp, infl_by_infl,\n                  labels=['GDP shock', 'Inflation shock'],\n                  colors=[COLORS['blue'], COLORS['orange']], alpha=0.7)\naxes[1].set_title('FEVD of Inflation', fontweight='bold')\naxes[1].set_xlabel('Horizon (quarters)')\naxes[1].set_ylabel('Percent')\naxes[1].legend(loc='center right', frameon=False)\naxes[1].set_ylim(0, 100)\n\nplt.tight_layout()\nplt.show()\n\n# Print table\nprint(\"\\nFEVD Table (%)\")\nprint(\"=\"*70)\nprint(f\"{'Horizon':<10} {'GDP by GDP':>12} {'GDP by Infl':>12} {'Infl by GDP':>12} {'Infl by Infl':>12}\")\nprint(\"-\"*70)\nfor h in [1, 5, 10, min(20, n_periods-1)]:\n    if h < n_periods:\n        print(f\"{h:<10} {fevd.decomp[h, 0, 0]*100:>12.1f} {fevd.decomp[h, 0, 1]*100:>12.1f} \"\n              f\"{fevd.decomp[h, 1, 0]*100:>12.1f} {fevd.decomp[h, 1, 1]*100:>12.1f}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "## 8. VAR Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate forecasts\n",
    "forecast_steps = 12\n",
    "lag_order = results.k_ar\n",
    "\n",
    "forecast = results.forecast(data.values[-lag_order:], steps=forecast_steps)\n",
    "forecast_interval = results.forecast_interval(data.values[-lag_order:], steps=forecast_steps, alpha=0.05)\n",
    "\n",
    "# Create forecast dates\n",
    "forecast_dates = pd.date_range(start=data.index[-1] + pd.DateOffset(months=1), \n",
    "                               periods=forecast_steps, freq='ME')\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8), sharex=True)\n",
    "\n",
    "# GDP Growth\n",
    "axes[0].plot(data.index[-36:], data['GDP_Growth'].values[-36:], \n",
    "             color=COLORS['blue'], linewidth=1.5, label='Historical')\n",
    "axes[0].plot(forecast_dates, forecast[:, 0], \n",
    "             color=COLORS['red'], linewidth=2, linestyle='--', label='Forecast')\n",
    "axes[0].fill_between(forecast_dates, forecast_interval[1][:, 0], forecast_interval[2][:, 0],\n",
    "                     color=COLORS['red'], alpha=0.2, label='95% CI')\n",
    "axes[0].axvline(x=data.index[-1], color='black', linestyle='-', alpha=0.3)\n",
    "axes[0].set_title('GDP Growth Forecast', fontweight='bold')\n",
    "axes[0].set_ylabel('%')\n",
    "axes[0].legend(loc='upper right', frameon=False)\n",
    "\n",
    "# Inflation\n",
    "axes[1].plot(data.index[-36:], data['Inflation'].values[-36:], \n",
    "             color=COLORS['orange'], linewidth=1.5, label='Historical')\n",
    "axes[1].plot(forecast_dates, forecast[:, 1], \n",
    "             color=COLORS['red'], linewidth=2, linestyle='--', label='Forecast')\n",
    "axes[1].fill_between(forecast_dates, forecast_interval[1][:, 1], forecast_interval[2][:, 1],\n",
    "                     color=COLORS['red'], alpha=0.2, label='95% CI')\n",
    "axes[1].axvline(x=data.index[-1], color='black', linestyle='-', alpha=0.3)\n",
    "axes[1].set_title('Inflation Forecast', fontweight='bold')\n",
    "axes[1].set_ylabel('%')\n",
    "axes[1].set_xlabel('Date')\n",
    "axes[1].legend(loc='upper right', frameon=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Forecast table\n",
    "print(\"\\nForecast Summary:\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Date':<12} {'GDP':>10} {'GDP 95% CI':>20} {'Inflation':>10} {'Infl 95% CI':>20}\")\n",
    "print(\"-\"*70)\n",
    "for i in range(min(6, forecast_steps)):\n",
    "    print(f\"{str(forecast_dates[i].date()):<12} {forecast[i, 0]:>10.2f} \"\n",
    "          f\"[{forecast_interval[1][i, 0]:>6.2f}, {forecast_interval[2][i, 0]:>6.2f}] \"\n",
    "          f\"{forecast[i, 1]:>10.2f} [{forecast_interval[1][i, 1]:>6.2f}, {forecast_interval[2][i, 1]:>6.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "## 9. Model Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual diagnostics\n",
    "residuals = results.resid\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Residuals over time\n",
    "axes[0, 0].plot(residuals[:, 0], color=COLORS['blue'], alpha=0.7, linewidth=0.5, label='GDP residuals')\n",
    "axes[0, 0].plot(residuals[:, 1], color=COLORS['orange'], alpha=0.7, linewidth=0.5, label='Inflation residuals')\n",
    "axes[0, 0].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "axes[0, 0].set_title('Residuals Over Time', fontweight='bold')\n",
    "axes[0, 0].legend(loc='upper right', frameon=False)\n",
    "\n",
    "# Cross-correlation of residuals\n",
    "axes[0, 1].scatter(residuals[:, 0], residuals[:, 1], alpha=0.5, color=COLORS['blue'], s=20)\n",
    "axes[0, 1].set_xlabel('GDP Residuals')\n",
    "axes[0, 1].set_ylabel('Inflation Residuals')\n",
    "axes[0, 1].set_title('Residual Cross-Plot', fontweight='bold')\n",
    "corr = np.corrcoef(residuals[:, 0], residuals[:, 1])[0, 1]\n",
    "axes[0, 1].text(0.05, 0.95, f'Corr = {corr:.3f}', transform=axes[0, 1].transAxes, \n",
    "                fontsize=12, verticalalignment='top')\n",
    "\n",
    "# ACF of residuals\n",
    "plot_acf(residuals[:, 0], ax=axes[1, 0], lags=20, color=COLORS['blue'], title='ACF: GDP Residuals')\n",
    "axes[1, 0].set_title('ACF: GDP Residuals', fontweight='bold')\n",
    "\n",
    "plot_acf(residuals[:, 1], ax=axes[1, 1], lags=20, color=COLORS['orange'], title='ACF: Inflation Residuals')\n",
    "axes[1, 1].set_title('ACF: Inflation Residuals', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Portmanteau test\n",
    "print(\"\\nPortmanteau Test for Residual Autocorrelation:\")\n",
    "print(results.test_whiteness(nlags=12).summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-27",
   "metadata": {},
   "source": [
    "## 10. Cointegration and VECM\n",
    "\n",
    "When variables are **I(1)** (non-stationary) but share a long-run equilibrium, they are **cointegrated**.\n",
    "\n",
    "### Vector Error Correction Model (VECM)\n",
    "$$\\Delta \\mathbf{Y}_t = \\boldsymbol{\\Pi} \\mathbf{Y}_{t-1} + \\sum_{i=1}^{p-1} \\boldsymbol{\\Gamma}_i \\Delta \\mathbf{Y}_{t-i} + \\boldsymbol{\\varepsilon}_t$$\n",
    "\n",
    "where $\\boldsymbol{\\Pi} = \\boldsymbol{\\alpha} \\boldsymbol{\\beta}'$ contains:\n",
    "- $\\boldsymbol{\\beta}$: cointegrating vectors (long-run relationships)\n",
    "- $\\boldsymbol{\\alpha}$: adjustment speeds (error correction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-28",
   "metadata": {},
   "outputs": [],
   "source": "# Cointegration Example: US Interest Rates\n# Short-term (3-month T-bill) and Long-term (10-year Treasury) yields\n\nif HAS_PDR:\n    try:\n        # Fetch Treasury rates from FRED\n        # TB3MS = 3-Month Treasury Bill\n        # GS10 = 10-Year Treasury Constant Maturity Rate\n        \n        short_rate = web.DataReader('TB3MS', 'fred', '1990-01-01', '2024-12-31')\n        long_rate = web.DataReader('GS10', 'fred', '1990-01-01', '2024-12-31')\n        \n        # Align to monthly\n        coint_data = pd.DataFrame({\n            'ShortRate': short_rate['TB3MS'],\n            'LongRate': long_rate['GS10']\n        }).dropna()\n        \n        print(f\"✓ Real Interest Rate Data: {len(coint_data)} monthly observations\")\n        COINT_SOURCE = \"FRED Treasury Rates\"\n        \n    except Exception as e:\n        print(f\"Could not fetch rate data: {e}\")\n        HAS_PDR = False\n\nif not HAS_PDR:\n    # Fallback: Simulated cointegrated data\n    np.random.seed(123)\n    n = 200\n    \n    x = np.cumsum(np.random.randn(n)) + 50\n    y = 2 * x + np.random.randn(n) * 2 + 10\n    \n    coint_data = pd.DataFrame({'ShortRate': x, 'LongRate': y})\n    COINT_SOURCE = \"Simulated (fallback)\"\n\n# Plot\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\naxes[0].plot(coint_data.index, coint_data['ShortRate'], color=COLORS['blue'], \n             label='3-Month T-Bill', linewidth=1)\naxes[0].plot(coint_data.index, coint_data['LongRate'], color=COLORS['orange'], \n             label='10-Year Treasury', linewidth=1)\naxes[0].set_title(f'US Interest Rates - {COINT_SOURCE}', fontweight='bold')\naxes[0].set_ylabel('Interest Rate (%)')\naxes[0].legend(loc='upper right', frameon=False)\n\n# Spread (term spread)\nspread = coint_data['LongRate'] - coint_data['ShortRate']\naxes[1].plot(spread.index, spread, color=COLORS['green'], linewidth=1)\naxes[1].axhline(y=spread.mean(), color='red', linestyle='--', alpha=0.5, \n                label=f'Mean: {spread.mean():.2f}%')\naxes[1].axhline(y=0, color='black', linestyle='-', alpha=0.3)\naxes[1].set_title('Term Spread: Long Rate - Short Rate', fontweight='bold')\naxes[1].set_ylabel('Spread (%)')\naxes[1].legend(loc='upper right', frameon=False)\n\nplt.tight_layout()\nplt.show()\n\n# ADF tests\nprint(\"\\nUnit Root Tests (ADF):\")\nprint(\"=\"*60)\nfor col in ['ShortRate', 'LongRate']:\n    result = adfuller(coint_data[col].dropna())\n    status = \"Stationary\" if result[1] < 0.05 else \"Non-stationary (I(1))\"\n    print(f\"{col:>12}: ADF = {result[0]:>7.3f}, p-value = {result[1]:.4f} → {status}\")\n\nresult = adfuller(spread.dropna())\nstatus = \"Stationary\" if result[1] < 0.05 else \"Non-stationary\"\nprint(f\"{'Spread':>12}: ADF = {result[0]:>7.3f}, p-value = {result[1]:.4f} → {status}\")\n\nprint(\"\\nIf rates are I(1) but spread is I(0), the rates are cointegrated!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Johansen cointegration test\n",
    "print(\"\\nJohansen Cointegration Test:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "johansen_result = coint_johansen(coint_data, det_order=0, k_ar_diff=1)\n",
    "\n",
    "print(\"\\nTrace Statistics:\")\n",
    "print(f\"{'Rank':>6} {'Trace Stat':>12} {'Crit 95%':>12} {'Crit 99%':>12}\")\n",
    "print(\"-\"*50)\n",
    "for i in range(2):\n",
    "    sig = \" **\" if johansen_result.lr1[i] > johansen_result.cvt[i, 1] else \"\"\n",
    "    print(f\"{i:>6} {johansen_result.lr1[i]:>12.2f} {johansen_result.cvt[i, 1]:>12.2f} \"\n",
    "          f\"{johansen_result.cvt[i, 2]:>12.2f}{sig}\")\n",
    "\n",
    "print(\"\\nConclusion: Reject rank=0, cannot reject rank=1\")\n",
    "print(\"→ There is 1 cointegrating relationship\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit VECM\n",
    "vecm = VECM(coint_data, k_ar_diff=1, coint_rank=1, deterministic='ci')\n",
    "vecm_results = vecm.fit()\n",
    "\n",
    "print(\"\\nVECM Estimation Results:\")\n",
    "print(\"=\"*60)\n",
    "print(vecm_results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-31",
   "metadata": {},
   "source": [
    "## 11. Cross-Correlation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-correlation between GDP and Inflation\n",
    "from scipy import signal\n",
    "\n",
    "# Compute CCF\n",
    "x = data['GDP_Growth'].values\n",
    "y = data['Inflation'].values\n",
    "\n",
    "# Normalize\n",
    "x_norm = (x - np.mean(x)) / np.std(x)\n",
    "y_norm = (y - np.mean(y)) / np.std(y)\n",
    "\n",
    "# Cross-correlation\n",
    "ccf_values = np.correlate(x_norm, y_norm, mode='full') / len(x)\n",
    "lags = np.arange(-len(x)+1, len(x))\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "# Only show lags -20 to 20\n",
    "mask = (lags >= -20) & (lags <= 20)\n",
    "ax.stem(lags[mask], ccf_values[mask], linefmt=COLORS['blue'], markerfmt='o', basefmt=' ')\n",
    "ax.axhline(y=0, color='black', linestyle='-')\n",
    "ax.axhline(y=1.96/np.sqrt(len(x)), color='red', linestyle='--', alpha=0.5)\n",
    "ax.axhline(y=-1.96/np.sqrt(len(x)), color='red', linestyle='--', alpha=0.5)\n",
    "ax.axvline(x=0, color='gray', linestyle=':', alpha=0.5)\n",
    "\n",
    "ax.set_xlabel('Lag (k)')\n",
    "ax.set_ylabel('Cross-Correlation')\n",
    "ax.set_title('Cross-Correlation: GDP Growth and Inflation', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Interpretation:\")\n",
    "print(\"- Positive lag k: GDP leads Inflation by k periods\")\n",
    "print(\"- Negative lag k: Inflation leads GDP by k periods\")\n",
    "print(\"- Peak correlation shows dominant lead-lag relationship\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-33",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **VAR models** capture dynamic interdependencies between multiple time series\n",
    "   - Each variable depends on its own lags AND lags of other variables\n",
    "   - OLS estimation is efficient with identical regressors\n",
    "\n",
    "2. **Stability** requires all eigenvalues inside the unit circle\n",
    "   - Ensures stationarity and convergent impulse responses\n",
    "\n",
    "3. **Granger causality** tests predictive content, not true causation\n",
    "   - Useful for understanding lead-lag relationships\n",
    "   - Sensitive to lag selection and omitted variables\n",
    "\n",
    "4. **Impulse Response Functions** trace shock propagation\n",
    "   - Requires identification (Cholesky, structural restrictions)\n",
    "   - Shows dynamic multipliers over time\n",
    "\n",
    "5. **FEVD** decomposes forecast variance by shock source\n",
    "   - Shows relative importance of different shocks\n",
    "\n",
    "6. **Cointegration** exists when I(1) variables share long-run equilibrium\n",
    "   - Use VECM to model both short-run and long-run dynamics\n",
    "   - Johansen test for testing cointegration rank\n",
    "\n",
    "### Practical Workflow\n",
    "1. Check stationarity (unit root tests)\n",
    "2. Select lag order (information criteria)\n",
    "3. Estimate VAR or VECM\n",
    "4. Diagnostic checks (residual autocorrelation)\n",
    "5. Granger causality tests\n",
    "6. IRF and FEVD analysis\n",
    "7. Forecasting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}