{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/danpele/Time-Series-Analysis/blob/main/chapter2_seminar_notebook.ipynb)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2: Seminar - ARMA Models Exercises\n",
    "\n",
    "**Course:** Time Series Analysis and Forecasting  \n",
    "**Program:** Master in Statistics and Data Science  \n",
    "**Academic Year:** 2025-2026\n",
    "\n",
    "---\n",
    "\n",
    "## Seminar Objectives\n",
    "\n",
    "In this seminar, you will:\n",
    "1. Practice working with lag operators and backshift notation\n",
    "2. Calculate AR and MA process properties (mean, variance, autocovariance)\n",
    "3. Identify ARMA models from ACF/PACF patterns\n",
    "4. Fit and diagnose ARMA models in Python\n",
    "5. Apply the Box-Jenkins methodology to real data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import yfinance as yf\n",
    "from statsmodels.tsa.arima_process import ArmaProcess\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.stattools import adfuller, acf, pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from scipy import stats\n",
    "\n",
    "# Plotting style - clean, professional\n",
    "plt.rcParams['figure.figsize'] = (12, 5)\n",
    "plt.rcParams['axes.facecolor'] = 'none'  # Transparent background\n",
    "plt.rcParams['figure.facecolor'] = 'none'  # Transparent figure\n",
    "plt.rcParams['savefig.facecolor'] = 'none'\n",
    "plt.rcParams['axes.grid'] = False  # No grid\n",
    "plt.rcParams['axes.spines.top'] = False\n",
    "plt.rcParams['axes.spines.right'] = False\n",
    "\n",
    "# Colors\n",
    "BLUE = '#1A3A6E'\n",
    "RED = '#DC3545'\n",
    "GREEN = '#2E7D32'\n",
    "\n",
    "np.random.seed(42)\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 1: Multiple Choice Quiz\n",
    "\n",
    "Answer the following questions. Run the cell after each answer to check if you're correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz 1: Lag Operator\n",
    "\n",
    "**Question:** What is the result of applying $(1-L)^2$ to $X_t$?\n",
    "\n",
    "- A) $X_t - X_{t-1}$\n",
    "- B) $X_t - 2X_{t-1} + X_{t-2}$\n",
    "- C) $X_t + X_{t-1} + X_{t-2}$\n",
    "- D) $X_t - X_{t-2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your answer: 'A', 'B', 'C', or 'D'\n",
    "quiz1_answer = ''  # <-- Enter your answer here\n",
    "\n",
    "# Check answer\n",
    "if quiz1_answer.upper() == 'B':\n",
    "    print(\"CORRECT!\")\n",
    "    print(\"(1-L)^2 = 1 - 2L + L^2\")\n",
    "    print(\"Applied to X_t: X_t - 2X_{t-1} + X_{t-2}\")\n",
    "    print(\"This is the SECOND DIFFERENCE of X_t.\")\n",
    "elif quiz1_answer:\n",
    "    print(\"Incorrect. Try again!\")\n",
    "    print(\"Hint: Expand (1-L)^2 = (1-L)(1-L) using FOIL method.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz 2: AR(1) Stationarity\n",
    "\n",
    "**Question:** For which value of $\\phi$ is the AR(1) process $X_t = 0.5 + \\phi X_{t-1} + \\varepsilon_t$ stationary?\n",
    "\n",
    "- A) $\\phi = 1.2$\n",
    "- B) $\\phi = 1.0$\n",
    "- C) $\\phi = -0.8$\n",
    "- D) $\\phi = -1.5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your answer: 'A', 'B', 'C', or 'D'\n",
    "quiz2_answer = ''  # <-- Enter your answer here\n",
    "\n",
    "# Check answer\n",
    "if quiz2_answer.upper() == 'C':\n",
    "    print(\"CORRECT!\")\n",
    "    print(\"AR(1) is stationary if and only if |phi| < 1.\")\n",
    "    print()\n",
    "    print(\"Checking each option:\")\n",
    "    print(\"A. |1.2| = 1.2 > 1 -> Non-stationary (explosive)\")\n",
    "    print(\"B. |1.0| = 1.0 -> Non-stationary (unit root)\")\n",
    "    print(\"C. |-0.8| = 0.8 < 1 -> STATIONARY\")\n",
    "    print(\"D. |-1.5| = 1.5 > 1 -> Non-stationary (explosive)\")\n",
    "elif quiz2_answer:\n",
    "    print(\"Incorrect. Try again!\")\n",
    "    print(\"Hint: The stationarity condition for AR(1) requires |phi| < 1.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz 3: ACF/PACF Pattern\n",
    "\n",
    "**Question:** You observe the following pattern:\n",
    "- ACF: Significant spike at lag 1, then all within confidence bands\n",
    "- PACF: Gradual exponential decay\n",
    "\n",
    "What model is suggested?\n",
    "\n",
    "- A) AR(1)\n",
    "- B) MA(1)\n",
    "- C) ARMA(1,1)\n",
    "- D) White noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your answer: 'A', 'B', 'C', or 'D'\n",
    "quiz3_answer = ''  # <-- Enter your answer here\n",
    "\n",
    "# Check answer\n",
    "if quiz3_answer.upper() == 'B':\n",
    "    print(\"CORRECT!\")\n",
    "    print()\n",
    "    print(\"Model Identification Summary:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(\"Model    | ACF          | PACF\")\n",
    "    print(\"-\" * 40)\n",
    "    print(\"AR(p)    | Decays       | Cuts off at lag p\")\n",
    "    print(\"MA(q)    | Cuts off at q| Decays\")\n",
    "    print(\"ARMA     | Decays       | Decays\")\n",
    "    print(\"-\" * 40)\n",
    "    print()\n",
    "    print(\"ACF cuts off after 1 + PACF decays = MA(1)\")\n",
    "elif quiz3_answer:\n",
    "    print(\"Incorrect. Try again!\")\n",
    "    print(\"Hint: Which model has ACF that cuts off and PACF that decays?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz 4: MA(1) Invertibility\n",
    "\n",
    "**Question:** The MA(1) process $X_t = \\varepsilon_t + \\theta \\varepsilon_{t-1}$ is invertible when:\n",
    "\n",
    "- A) $|\\theta| > 1$\n",
    "- B) $|\\theta| < 1$\n",
    "- C) $\\theta > 0$\n",
    "- D) $\\theta < 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your answer: 'A', 'B', 'C', or 'D'\n",
    "quiz4_answer = ''  # <-- Enter your answer here\n",
    "\n",
    "# Check answer\n",
    "if quiz4_answer.upper() == 'B':\n",
    "    print(\"CORRECT!\")\n",
    "    print()\n",
    "    print(\"Invertibility condition for MA(1): |theta| < 1\")\n",
    "    print()\n",
    "    print(\"Why does it matter?\")\n",
    "    print(\"- Invertibility allows us to express the MA as an infinite AR\")\n",
    "    print(\"- It ensures uniqueness of the representation\")\n",
    "    print(\"- It makes estimation well-defined\")\n",
    "    print()\n",
    "    print(\"If invertible: X_t = sum_{j=0}^{inf} (-theta)^j X_{t-j} + epsilon_t\")\n",
    "elif quiz4_answer:\n",
    "    print(\"Incorrect. Try again!\")\n",
    "    print(\"Hint: Invertibility is similar to stationarity for AR - it requires roots outside unit circle.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz 5: Model Selection\n",
    "\n",
    "**Question:** Which criterion penalizes model complexity MORE strongly for large samples?\n",
    "\n",
    "- A) AIC (Akaike Information Criterion)\n",
    "- B) BIC (Bayesian Information Criterion)\n",
    "- C) Both penalize equally\n",
    "- D) Neither penalizes complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your answer: 'A', 'B', 'C', or 'D'\n",
    "quiz5_answer = ''  # <-- Enter your answer here\n",
    "\n",
    "# Check answer\n",
    "if quiz5_answer.upper() == 'B':\n",
    "    print(\"CORRECT!\")\n",
    "    print()\n",
    "    print(\"AIC = -2*log(L) + 2*k\")\n",
    "    print(\"BIC = -2*log(L) + k*log(n)\")\n",
    "    print()\n",
    "    print(\"For n > 8: log(n) > 2\")\n",
    "    print(\"So BIC penalizes additional parameters more heavily for larger samples.\")\n",
    "    print()\n",
    "    print(\"Rule of thumb:\")\n",
    "    print(\"- AIC: Better for prediction\")\n",
    "    print(\"- BIC: Better for identifying 'true' model\")\n",
    "elif quiz5_answer:\n",
    "    print(\"Incorrect. Try again!\")\n",
    "    print(\"Hint: Compare the penalty terms: 2k vs k*log(n). When is log(n) > 2?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz 6: Ljung-Box Test\n",
    "\n",
    "**Question:** You fit an ARMA(1,1) model and run the Ljung-Box test on residuals with 10 lags. The p-value is 0.02. What do you conclude?\n",
    "\n",
    "- A) The residuals are white noise; model is adequate\n",
    "- B) The residuals have significant autocorrelation; model needs improvement\n",
    "- C) The model is overfitting\n",
    "- D) The data is non-stationary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your answer: 'A', 'B', 'C', or 'D'\n",
    "quiz6_answer = ''  # <-- Enter your answer here\n",
    "\n",
    "# Check answer\n",
    "if quiz6_answer.upper() == 'B':\n",
    "    print(\"CORRECT!\")\n",
    "    print()\n",
    "    print(\"Ljung-Box Test:\")\n",
    "    print(\"  H0: Residuals are white noise (no autocorrelation up to lag h)\")\n",
    "    print(\"  H1: Residuals have significant autocorrelation\")\n",
    "    print()\n",
    "    print(\"With p-value = 0.02 < 0.05:\")\n",
    "    print(\"  We REJECT H0\")\n",
    "    print(\"  Residuals are NOT white noise\")\n",
    "    print(\"  Model is INADEQUATE - there's unexplained structure!\")\n",
    "    print()\n",
    "    print(\"Next steps: Try higher order ARMA or check for seasonal patterns.\")\n",
    "elif quiz6_answer:\n",
    "    print(\"Incorrect. Try again!\")\n",
    "    print(\"Hint: What does the null hypothesis of the Ljung-Box test state?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz 7: AR(2) Process\n",
    "\n",
    "**Question:** For the AR(2) process $X_t = 0.6X_{t-1} - 0.08X_{t-2} + \\varepsilon_t$, the characteristic equation is:\n",
    "\n",
    "- A) $1 - 0.6z - 0.08z^2 = 0$\n",
    "- B) $1 - 0.6z + 0.08z^2 = 0$\n",
    "- C) $z^2 - 0.6z + 0.08 = 0$\n",
    "- D) $z^2 - 0.6z - 0.08 = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your answer: 'A', 'B', 'C', or 'D'\n",
    "quiz7_answer = ''  # <-- Enter your answer here\n",
    "\n",
    "# Check answer\n",
    "if quiz7_answer.upper() == 'B':\n",
    "    print(\"CORRECT!\")\n",
    "    print()\n",
    "    print(\"AR(2): X_t = phi_1*X_{t-1} + phi_2*X_{t-2} + epsilon_t\")\n",
    "    print(\"Here: phi_1 = 0.6, phi_2 = -0.08\")\n",
    "    print()\n",
    "    print(\"Characteristic polynomial: phi(z) = 1 - phi_1*z - phi_2*z^2\")\n",
    "    print(\"                                  = 1 - 0.6z - (-0.08)z^2\")\n",
    "    print(\"                                  = 1 - 0.6z + 0.08z^2\")\n",
    "    print()\n",
    "    print(\"Stationarity requires all roots of phi(z)=0 to be OUTSIDE unit circle.\")\n",
    "elif quiz7_answer:\n",
    "    print(\"Incorrect. Try again!\")\n",
    "    print(\"Hint: The characteristic polynomial is phi(z) = 1 - phi_1*z - phi_2*z^2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz 8: Forecasting\n",
    "\n",
    "**Question:** For an AR(1) process with $\\phi = 0.8$ and unconditional mean $\\mu = 10$, what happens to forecasts as the horizon $h \\to \\infty$?\n",
    "\n",
    "- A) Forecasts diverge to infinity\n",
    "- B) Forecasts converge to the unconditional mean 10\n",
    "- C) Forecasts converge to 0\n",
    "- D) Forecasts oscillate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your answer: 'A', 'B', 'C', or 'D'\n",
    "quiz8_answer = ''  # <-- Enter your answer here\n",
    "\n",
    "# Check answer\n",
    "if quiz8_answer.upper() == 'B':\n",
    "    print(\"CORRECT!\")\n",
    "    print()\n",
    "    print(\"For stationary AR(1):\")\n",
    "    print(\"  X_hat_{t+h} = mu + phi^h * (X_t - mu)\")\n",
    "    print()\n",
    "    print(\"As h -> infinity:\")\n",
    "    print(\"  phi^h -> 0 (since |phi| < 1)\")\n",
    "    print(\"  X_hat_{t+h} -> mu\")\n",
    "    print()\n",
    "    print(\"Long-term forecasts revert to the unconditional mean.\")\n",
    "    print(\"This is called MEAN REVERSION.\")\n",
    "elif quiz8_answer:\n",
    "    print(\"Incorrect. Try again!\")\n",
    "    print(\"Hint: What happens to phi^h as h gets large when |phi| < 1?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 2: True/False Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer each statement with True or False\n",
    "tf_answers = {\n",
    "    1: None,  # \"The ACF of a stationary AR(1) decays exponentially.\"\n",
    "    2: None,  # \"An MA(q) process is always stationary.\"\n",
    "    3: None,  # \"The PACF of an MA(1) cuts off after lag 1.\"\n",
    "    4: None,  # \"ARMA(1,1) can produce both decaying ACF and PACF.\"\n",
    "    5: None,  # \"Lower AIC always means better out-of-sample prediction.\"\n",
    "    6: None,  # \"The Yule-Walker equations can estimate AR parameters.\"\n",
    "}\n",
    "\n",
    "# Enter your answers below (True or False)\n",
    "tf_answers[1] = None  # ACF of AR(1) decays exponentially\n",
    "tf_answers[2] = None  # MA(q) is always stationary\n",
    "tf_answers[3] = None  # PACF of MA(1) cuts off at lag 1\n",
    "tf_answers[4] = None  # ARMA(1,1) has decaying ACF and PACF\n",
    "tf_answers[5] = None  # Lower AIC = better out-of-sample\n",
    "tf_answers[6] = None  # Yule-Walker estimates AR parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check your answers\n",
    "correct_answers = {1: True, 2: True, 3: False, 4: True, 5: False, 6: True}\n",
    "explanations = {\n",
    "    1: \"TRUE: For AR(1), rho(h) = phi^h, which decays exponentially (|phi| < 1).\",\n",
    "    2: \"TRUE: MA(q) is always stationary since it's a finite weighted sum of WN.\",\n",
    "    3: \"FALSE: PACF of MA(q) DECAYS, it doesn't cut off. It's ACF that cuts off for MA.\",\n",
    "    4: \"TRUE: ARMA processes have both decaying ACF and PACF due to mixed AR/MA components.\",\n",
    "    5: \"FALSE: AIC is an IN-SAMPLE criterion. Lower AIC usually but not always means better prediction.\",\n",
    "    6: \"TRUE: Yule-Walker equations relate ACF to AR parameters: phi = R^{-1} * rho.\"\n",
    "}\n",
    "\n",
    "score = 0\n",
    "for q, correct in correct_answers.items():\n",
    "    user_ans = tf_answers[q]\n",
    "    if user_ans is None:\n",
    "        status = \"NOT ANSWERED\"\n",
    "    elif user_ans == correct:\n",
    "        status = \"CORRECT\"\n",
    "        score += 1\n",
    "    else:\n",
    "        status = \"INCORRECT\"\n",
    "    print(f\"Q{q}: {status}\")\n",
    "    if user_ans is not None:\n",
    "        print(f\"   {explanations[q]}\")\n",
    "    print()\n",
    "\n",
    "print(f\"\\nScore: {score}/6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 3: Calculation Exercises\n",
    "\n",
    "## Exercise 1: AR(1) Properties\n",
    "\n",
    "Consider the AR(1) process: $X_t = 2 + 0.7 X_{t-1} + \\varepsilon_t$ where $\\varepsilon_t \\sim WN(0, 9)$.\n",
    "\n",
    "Calculate:\n",
    "1. The unconditional mean $\\mu = E[X_t]$\n",
    "2. The variance $\\gamma(0) = Var(X_t)$\n",
    "3. The autocovariance $\\gamma(1)$ and $\\gamma(2)$\n",
    "4. The autocorrelation $\\rho(1)$ and $\\rho(2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given values\n",
    "c = 2        # constant\n",
    "phi = 0.7    # AR coefficient\n",
    "sigma_sq = 9 # Var(epsilon_t)\n",
    "\n",
    "# YOUR TASK: Calculate the following\n",
    "# Formula for AR(1):\n",
    "# mu = c / (1 - phi)\n",
    "# gamma(0) = sigma^2 / (1 - phi^2)\n",
    "# gamma(h) = phi * gamma(h-1)\n",
    "# rho(h) = phi^h\n",
    "\n",
    "mu = None  # <-- Calculate E[X_t]\n",
    "gamma_0 = None  # <-- Calculate Var(X_t)\n",
    "gamma_1 = None  # <-- Calculate gamma(1)\n",
    "gamma_2 = None  # <-- Calculate gamma(2)\n",
    "rho_1 = None  # <-- Calculate rho(1)\n",
    "rho_2 = None  # <-- Calculate rho(2)\n",
    "\n",
    "print(\"Your answers:\")\n",
    "print(f\"mu = E[X_t] = {mu}\")\n",
    "print(f\"gamma(0) = Var(X_t) = {gamma_0}\")\n",
    "print(f\"gamma(1) = {gamma_1}\")\n",
    "print(f\"gamma(2) = {gamma_2}\")\n",
    "print(f\"rho(1) = {rho_1}\")\n",
    "print(f\"rho(2) = {rho_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "print(\"SOLUTION:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "mu_sol = c / (1 - phi)\n",
    "print(f\"\\nmu = c/(1-phi) = {c}/(1-{phi}) = {c}/{1-phi:.1f} = {mu_sol:.4f}\")\n",
    "\n",
    "gamma_0_sol = sigma_sq / (1 - phi**2)\n",
    "print(f\"\\ngamma(0) = sigma^2/(1-phi^2) = {sigma_sq}/(1-{phi}^2) = {sigma_sq}/{1-phi**2:.2f} = {gamma_0_sol:.4f}\")\n",
    "\n",
    "gamma_1_sol = phi * gamma_0_sol\n",
    "print(f\"\\ngamma(1) = phi * gamma(0) = {phi} * {gamma_0_sol:.4f} = {gamma_1_sol:.4f}\")\n",
    "\n",
    "gamma_2_sol = phi * gamma_1_sol\n",
    "print(f\"\\ngamma(2) = phi * gamma(1) = {phi} * {gamma_1_sol:.4f} = {gamma_2_sol:.4f}\")\n",
    "\n",
    "rho_1_sol = phi\n",
    "print(f\"\\nrho(1) = phi = {rho_1_sol}\")\n",
    "\n",
    "rho_2_sol = phi**2\n",
    "print(f\"\\nrho(2) = phi^2 = {phi}^2 = {rho_2_sol}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: MA(1) Properties\n",
    "\n",
    "Consider the MA(1) process: $X_t = 3 + \\varepsilon_t + 0.5\\varepsilon_{t-1}$ where $\\varepsilon_t \\sim WN(0, 4)$.\n",
    "\n",
    "Calculate:\n",
    "1. The mean $\\mu = E[X_t]$\n",
    "2. The variance $\\gamma(0)$\n",
    "3. The autocovariance $\\gamma(1)$\n",
    "4. The autocovariance $\\gamma(2)$\n",
    "5. The autocorrelation $\\rho(1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given values\n",
    "mu_ma = 3          # constant (mean)\n",
    "theta = 0.5        # MA coefficient\n",
    "sigma_sq_ma = 4    # Var(epsilon_t)\n",
    "\n",
    "# YOUR TASK: Calculate the following\n",
    "# Formulas for MA(1):\n",
    "# E[X_t] = mu (the constant)\n",
    "# gamma(0) = (1 + theta^2) * sigma^2\n",
    "# gamma(1) = theta * sigma^2\n",
    "# gamma(h) = 0 for h >= 2\n",
    "# rho(1) = theta / (1 + theta^2)\n",
    "\n",
    "E_Xt = None  # <-- Calculate E[X_t]\n",
    "gamma_0_ma = None  # <-- Calculate gamma(0)\n",
    "gamma_1_ma = None  # <-- Calculate gamma(1)\n",
    "gamma_2_ma = None  # <-- Calculate gamma(2)\n",
    "rho_1_ma = None  # <-- Calculate rho(1)\n",
    "\n",
    "print(\"Your answers:\")\n",
    "print(f\"E[X_t] = {E_Xt}\")\n",
    "print(f\"gamma(0) = {gamma_0_ma}\")\n",
    "print(f\"gamma(1) = {gamma_1_ma}\")\n",
    "print(f\"gamma(2) = {gamma_2_ma}\")\n",
    "print(f\"rho(1) = {rho_1_ma}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "print(\"SOLUTION:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "E_Xt_sol = mu_ma\n",
    "print(f\"\\nE[X_t] = mu = {E_Xt_sol}\")\n",
    "print(f\"   (The constant term is the mean for MA processes)\")\n",
    "\n",
    "gamma_0_ma_sol = (1 + theta**2) * sigma_sq_ma\n",
    "print(f\"\\ngamma(0) = (1 + theta^2) * sigma^2\")\n",
    "print(f\"         = (1 + {theta}^2) * {sigma_sq_ma}\")\n",
    "print(f\"         = (1 + {theta**2}) * {sigma_sq_ma}\")\n",
    "print(f\"         = {1 + theta**2} * {sigma_sq_ma} = {gamma_0_ma_sol}\")\n",
    "\n",
    "gamma_1_ma_sol = theta * sigma_sq_ma\n",
    "print(f\"\\ngamma(1) = theta * sigma^2 = {theta} * {sigma_sq_ma} = {gamma_1_ma_sol}\")\n",
    "\n",
    "gamma_2_ma_sol = 0\n",
    "print(f\"\\ngamma(2) = 0\")\n",
    "print(f\"   (MA(1) has autocovariance = 0 for all lags >= 2)\")\n",
    "\n",
    "rho_1_ma_sol = theta / (1 + theta**2)\n",
    "print(f\"\\nrho(1) = theta / (1 + theta^2)\")\n",
    "print(f\"       = {theta} / (1 + {theta**2})\")\n",
    "print(f\"       = {theta} / {1 + theta**2}\")\n",
    "print(f\"       = {rho_1_ma_sol:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Characteristic Equation\n",
    "\n",
    "For the AR(2) process: $X_t = 1.5X_{t-1} - 0.56X_{t-2} + \\varepsilon_t$\n",
    "\n",
    "1. Write the characteristic equation\n",
    "2. Find the roots\n",
    "3. Determine if the process is stationary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given values\n",
    "phi1 = 1.5\n",
    "phi2 = -0.56\n",
    "\n",
    "# YOUR TASK:\n",
    "# 1. The characteristic polynomial is: 1 - phi1*z - phi2*z^2 = 0\n",
    "# 2. Rearrange to: phi2*z^2 + phi1*z - 1 = 0 and solve using quadratic formula\n",
    "#    Or equivalently: z^2 - (phi1/(-phi2))*z + 1/(-phi2) = 0\n",
    "\n",
    "# Calculate coefficients for numpy roots\n",
    "# We solve: 1 - phi1*z - phi2*z^2 = 0\n",
    "# Rewrite as: -phi2*z^2 - phi1*z + 1 = 0\n",
    "# Coefficients for np.roots: [a, b, c] where az^2 + bz + c = 0\n",
    "\n",
    "roots = np.roots([-phi2, -phi1, 1])  # This is already done for you\n",
    "\n",
    "# Calculate |roots| and check if > 1\n",
    "root_magnitudes = None  # <-- Calculate absolute values of roots\n",
    "is_stationary = None  # <-- True if ALL |roots| > 1\n",
    "\n",
    "print(\"Your answers:\")\n",
    "print(f\"Roots: {roots}\")\n",
    "print(f\"Magnitudes: {root_magnitudes}\")\n",
    "print(f\"Is stationary: {is_stationary}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "print(\"SOLUTION:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"\\n1. Characteristic equation:\")\n",
    "print(f\"   phi(z) = 1 - phi1*z - phi2*z^2 = 0\")\n",
    "print(f\"   phi(z) = 1 - {phi1}z - ({phi2})z^2 = 0\")\n",
    "print(f\"   phi(z) = 1 - {phi1}z + {-phi2}z^2 = 0\")\n",
    "\n",
    "# Solve characteristic equation\n",
    "roots_sol = np.roots([-phi2, -phi1, 1])\n",
    "print(f\"\\n2. Roots of characteristic equation:\")\n",
    "print(f\"   z1 = {roots_sol[0]:.4f}\")\n",
    "print(f\"   z2 = {roots_sol[1]:.4f}\")\n",
    "\n",
    "root_mags_sol = np.abs(roots_sol)\n",
    "print(f\"\\n3. Checking stationarity (need |roots| > 1):\")\n",
    "print(f\"   |z1| = {root_mags_sol[0]:.4f}\")\n",
    "print(f\"   |z2| = {root_mags_sol[1]:.4f}\")\n",
    "\n",
    "is_stat_sol = all(root_mags_sol > 1)\n",
    "print(f\"\\n   Both roots outside unit circle? {is_stat_sol}\")\n",
    "print(f\"   Process is {'STATIONARY' if is_stat_sol else 'NON-STATIONARY'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 4: Python Coding Exercises\n",
    "\n",
    "## Exercise 4: Simulate and Visualize AR(1) Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Simulate AR(1) processes with different phi values and compare\n",
    "\n",
    "n = 200\n",
    "phi_values = [0.9, 0.5, -0.5, -0.9]\n",
    "\n",
    "# Step 1: Simulate AR(1) for each phi value\n",
    "# Use ArmaProcess from statsmodels\n",
    "# ar = np.array([1, -phi])  # Note: negative sign!\n",
    "# ma = np.array([1])\n",
    "# process = ArmaProcess(ar, ma)\n",
    "# simulated = process.generate_sample(nsample=n)\n",
    "\n",
    "# YOUR CODE HERE - simulate and store in a dictionary\n",
    "\n",
    "\n",
    "# Step 2: Plot all four time series in a 2x2 grid\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "print(\"SOLUTION:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "np.random.seed(42)\n",
    "n = 200\n",
    "phi_values = [0.9, 0.5, -0.5, -0.9]\n",
    "\n",
    "# Simulate\n",
    "simulations = {}\n",
    "for phi in phi_values:\n",
    "    ar = np.array([1, -phi])  # AR polynomial: 1 - phi*L\n",
    "    ma = np.array([1])        # MA polynomial: 1\n",
    "    process = ArmaProcess(ar, ma)\n",
    "    simulations[phi] = process.generate_sample(nsample=n)\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, phi in enumerate(phi_values):\n",
    "    axes[idx].plot(simulations[phi], color=BLUE, linewidth=0.8)\n",
    "    axes[idx].axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "    axes[idx].set_title(f'AR(1) with $\\\\phi$ = {phi}', fontweight='bold')\n",
    "    axes[idx].set_xlabel('Time')\n",
    "    axes[idx].set_ylabel('$X_t$')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nObservations:\")\n",
    "print(\"- phi = 0.9: High persistence, slow mean reversion\")\n",
    "print(\"- phi = 0.5: Moderate persistence\")\n",
    "print(\"- phi = -0.5: Moderate oscillation around mean\")\n",
    "print(\"- phi = -0.9: Strong oscillation (alternating behavior)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: ACF and PACF Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Generate AR(2), MA(2), and ARMA(1,1) processes and compare ACF/PACF\n",
    "\n",
    "np.random.seed(123)\n",
    "n = 500\n",
    "\n",
    "# Step 1: Generate AR(2) with phi1=0.5, phi2=0.3\n",
    "# ar_ar2 = np.array([1, -0.5, -0.3])\n",
    "# ma_ar2 = np.array([1])\n",
    "\n",
    "# Step 2: Generate MA(2) with theta1=0.5, theta2=0.3\n",
    "# ar_ma2 = np.array([1])\n",
    "# ma_ma2 = np.array([1, 0.5, 0.3])\n",
    "\n",
    "# Step 3: Generate ARMA(1,1) with phi=0.7, theta=0.4\n",
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "# Step 4: Plot ACF and PACF for each (3x2 grid)\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "print(\"SOLUTION:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "np.random.seed(123)\n",
    "n = 500\n",
    "\n",
    "# AR(2)\n",
    "ar_ar2 = np.array([1, -0.5, -0.3])\n",
    "ma_ar2 = np.array([1])\n",
    "ar2_process = ArmaProcess(ar_ar2, ma_ar2)\n",
    "ar2_data = ar2_process.generate_sample(nsample=n)\n",
    "\n",
    "# MA(2)\n",
    "ar_ma2 = np.array([1])\n",
    "ma_ma2 = np.array([1, 0.5, 0.3])\n",
    "ma2_process = ArmaProcess(ar_ma2, ma_ma2)\n",
    "ma2_data = ma2_process.generate_sample(nsample=n)\n",
    "\n",
    "# ARMA(1,1)\n",
    "ar_arma = np.array([1, -0.7])\n",
    "ma_arma = np.array([1, 0.4])\n",
    "arma_process = ArmaProcess(ar_arma, ma_arma)\n",
    "arma_data = arma_process.generate_sample(nsample=n)\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(3, 2, figsize=(14, 12))\n",
    "\n",
    "models = [\n",
    "    ('AR(2): $\\\\phi_1=0.5, \\\\phi_2=0.3$', ar2_data),\n",
    "    ('MA(2): $\\\\theta_1=0.5, \\\\theta_2=0.3$', ma2_data),\n",
    "    ('ARMA(1,1): $\\\\phi=0.7, \\\\theta=0.4$', arma_data)\n",
    "]\n",
    "\n",
    "for i, (title, data) in enumerate(models):\n",
    "    # ACF\n",
    "    acf_vals = acf(data, nlags=20)\n",
    "    axes[i, 0].bar(range(len(acf_vals)), acf_vals, color=BLUE, width=0.3)\n",
    "    axes[i, 0].axhline(y=0, color='black', linewidth=0.5)\n",
    "    axes[i, 0].axhline(y=1.96/np.sqrt(n), color=RED, linestyle='--', alpha=0.7)\n",
    "    axes[i, 0].axhline(y=-1.96/np.sqrt(n), color=RED, linestyle='--', alpha=0.7)\n",
    "    axes[i, 0].set_title(f'{title} - ACF', fontweight='bold')\n",
    "    axes[i, 0].set_xlabel('Lag')\n",
    "    axes[i, 0].set_ylabel('ACF')\n",
    "    \n",
    "    # PACF\n",
    "    pacf_vals = pacf(data, nlags=20)\n",
    "    axes[i, 1].bar(range(len(pacf_vals)), pacf_vals, color=GREEN, width=0.3)\n",
    "    axes[i, 1].axhline(y=0, color='black', linewidth=0.5)\n",
    "    axes[i, 1].axhline(y=1.96/np.sqrt(n), color=RED, linestyle='--', alpha=0.7)\n",
    "    axes[i, 1].axhline(y=-1.96/np.sqrt(n), color=RED, linestyle='--', alpha=0.7)\n",
    "    axes[i, 1].set_title(f'{title} - PACF', fontweight='bold')\n",
    "    axes[i, 1].set_xlabel('Lag')\n",
    "    axes[i, 1].set_ylabel('PACF')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nModel Identification Summary:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"AR(2):    ACF decays, PACF cuts off after lag 2\")\n",
    "print(\"MA(2):    ACF cuts off after lag 2, PACF decays\")\n",
    "print(\"ARMA(1,1): Both ACF and PACF decay\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6: Model Fitting and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Fit multiple ARMA models to the AR(2) data and select the best one using AIC/BIC\n",
    "\n",
    "# We'll use the ar2_data from the previous exercise\n",
    "data_to_fit = ar2_data\n",
    "\n",
    "# Step 1: Fit ARMA(p,q) for p in [0,1,2,3] and q in [0,1,2,3]\n",
    "# Store results in a DataFrame with columns: p, q, AIC, BIC\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# results = []\n",
    "# for p in range(4):\n",
    "#     for q in range(4):\n",
    "#         try:\n",
    "#             model = ARIMA(data_to_fit, order=(p, 0, q))\n",
    "#             fitted = model.fit()\n",
    "#             results.append({'p': p, 'q': q, 'AIC': fitted.aic, 'BIC': fitted.bic})\n",
    "#         except:\n",
    "#             pass\n",
    "\n",
    "\n",
    "# Step 2: Find the best model according to AIC and BIC\n",
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "# Step 3: Fit the best model and print summary\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "print(\"SOLUTION:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Fit multiple models\n",
    "results = []\n",
    "for p in range(4):\n",
    "    for q in range(4):\n",
    "        if p == 0 and q == 0:\n",
    "            continue  # Skip trivial model\n",
    "        try:\n",
    "            model = ARIMA(ar2_data, order=(p, 0, q))\n",
    "            fitted = model.fit()\n",
    "            results.append({\n",
    "                'p': p, 'q': q, \n",
    "                'AIC': fitted.aic, \n",
    "                'BIC': fitted.bic,\n",
    "                'Log-Lik': fitted.llf\n",
    "            })\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nModel Comparison:\")\n",
    "print(results_df.sort_values('AIC').head(10).to_string(index=False))\n",
    "\n",
    "# Best models\n",
    "best_aic = results_df.loc[results_df['AIC'].idxmin()]\n",
    "best_bic = results_df.loc[results_df['BIC'].idxmin()]\n",
    "\n",
    "print(f\"\\nBest by AIC: ARMA({int(best_aic['p'])},{int(best_aic['q'])}) - AIC = {best_aic['AIC']:.2f}\")\n",
    "print(f\"Best by BIC: ARMA({int(best_bic['p'])},{int(best_bic['q'])}) - BIC = {best_bic['BIC']:.2f}\")\n",
    "\n",
    "# Fit best model\n",
    "best_model = ARIMA(ar2_data, order=(int(best_bic['p']), 0, int(best_bic['q'])))\n",
    "best_fit = best_model.fit()\n",
    "print(f\"\\n\" + \"=\"*50)\n",
    "print(f\"Best Model Summary (BIC selection):\")\n",
    "print(best_fit.summary().tables[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 7: Residual Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Perform residual diagnostics on the fitted model\n",
    "\n",
    "# Step 1: Extract residuals from best_fit\n",
    "# residuals = best_fit.resid\n",
    "\n",
    "# Step 2: Create a 2x2 diagnostic plot:\n",
    "#   - Residual time series\n",
    "#   - Histogram with normal curve\n",
    "#   - ACF of residuals\n",
    "#   - Q-Q plot\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "# Step 3: Perform Ljung-Box test\n",
    "# lb_test = acorr_ljungbox(residuals, lags=[10, 20], return_df=True)\n",
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "print(\"SOLUTION:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "residuals = best_fit.resid\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Residual time series\n",
    "axes[0, 0].plot(residuals, color=BLUE, linewidth=0.8)\n",
    "axes[0, 0].axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "axes[0, 0].set_title('Residuals over Time', fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Time')\n",
    "axes[0, 0].set_ylabel('Residual')\n",
    "\n",
    "# Histogram\n",
    "axes[0, 1].hist(residuals, bins=30, density=True, color=BLUE, alpha=0.7, edgecolor='white')\n",
    "x_range = np.linspace(residuals.min(), residuals.max(), 100)\n",
    "axes[0, 1].plot(x_range, stats.norm.pdf(x_range, residuals.mean(), residuals.std()), \n",
    "               color=RED, linewidth=2, label='Normal')\n",
    "axes[0, 1].set_title('Residual Distribution', fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Residual')\n",
    "axes[0, 1].set_ylabel('Density')\n",
    "axes[0, 1].legend(loc='upper center', bbox_to_anchor=(0.5, -0.12), ncol=1, frameon=False)\n",
    "\n",
    "# ACF of residuals\n",
    "acf_resid = acf(residuals, nlags=20)\n",
    "axes[1, 0].bar(range(len(acf_resid)), acf_resid, color=BLUE, width=0.3)\n",
    "axes[1, 0].axhline(y=0, color='black', linewidth=0.5)\n",
    "axes[1, 0].axhline(y=1.96/np.sqrt(len(residuals)), color=RED, linestyle='--', alpha=0.7)\n",
    "axes[1, 0].axhline(y=-1.96/np.sqrt(len(residuals)), color=RED, linestyle='--', alpha=0.7)\n",
    "axes[1, 0].set_title('ACF of Residuals', fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Lag')\n",
    "axes[1, 0].set_ylabel('ACF')\n",
    "\n",
    "# Q-Q plot with proper axis scaling\n",
    "osm, osr = stats.probplot(residuals, dist='norm', fit=True)[:2]\n",
    "slope, intercept, r = stats.linregress(osm, osr)[:3]\n",
    "\n",
    "axes[1, 1].scatter(osm, osr, color=BLUE, alpha=0.6, s=20)\n",
    "q_range = abs(osm).max() * 1.1\n",
    "x_line = np.array([-q_range, q_range])\n",
    "axes[1, 1].plot(x_line, slope * x_line + intercept, color=RED, linewidth=2, label='Reference line')\n",
    "axes[1, 1].set_xlim(-q_range, q_range)\n",
    "axes[1, 1].set_ylim(-q_range * slope + intercept - abs(intercept)*0.5, \n",
    "                    q_range * slope + intercept + abs(intercept)*0.5)\n",
    "axes[1, 1].set_title('Q-Q Plot', fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Theoretical Quantiles')\n",
    "axes[1, 1].set_ylabel('Sample Quantiles')\n",
    "axes[1, 1].legend(loc='upper center', bbox_to_anchor=(0.5, -0.12), ncol=1, frameon=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Ljung-Box test\n",
    "print(\"\\nLjung-Box Test for Residual Autocorrelation:\")\n",
    "lb_test = acorr_ljungbox(residuals, lags=[10, 15, 20], return_df=True)\n",
    "print(lb_test)\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "if all(lb_test['lb_pvalue'] > 0.05):\n",
    "    print(\"All p-values > 0.05: Residuals are WHITE NOISE.\")\n",
    "    print(\"Model is ADEQUATE.\")\n",
    "else:\n",
    "    print(\"Some p-values < 0.05: Residuals show autocorrelation.\")\n",
    "    print(\"Model may need improvement.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 8: Real Data Application - S&P 500 Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Apply Box-Jenkins methodology to S&P 500 returns\n",
    "\n",
    "# Step 1: Download S&P 500 data and compute returns\n",
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "# Step 2: Test for stationarity\n",
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "# Step 3: Plot ACF and PACF to identify model order\n",
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "# Step 4: Fit several candidate models and compare AIC/BIC\n",
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "# Step 5: Perform residual diagnostics on the best model\n",
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "# Step 6: Generate forecasts\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "print(\"SOLUTION: Box-Jenkins Methodology for S&P 500 Returns\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Step 1: Download data\n",
    "print(\"\\n1. DATA ACQUISITION\")\n",
    "sp500 = yf.download('^GSPC', start='2020-01-01', end='2025-01-01', progress=False)\n",
    "if isinstance(sp500.columns, pd.MultiIndex):\n",
    "    sp500.columns = sp500.columns.droplevel(1)\n",
    "\n",
    "returns = sp500['Close'].pct_change().dropna() * 100\n",
    "print(f\"Downloaded {len(returns)} daily returns\")\n",
    "\n",
    "# Step 2: Stationarity test\n",
    "print(\"\\n2. STATIONARITY TEST\")\n",
    "adf_result = adfuller(returns, autolag='AIC')\n",
    "print(f\"ADF Statistic: {adf_result[0]:.4f}\")\n",
    "print(f\"p-value: {adf_result[1]:.6f}\")\n",
    "print(f\"Conclusion: Returns are {'STATIONARY' if adf_result[1] < 0.05 else 'NON-STATIONARY'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: ACF/PACF\n",
    "print(\"\\n3. MODEL IDENTIFICATION (ACF/PACF)\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# ACF\n",
    "acf_vals = acf(returns, nlags=20)\n",
    "axes[0].bar(range(len(acf_vals)), acf_vals, color=BLUE, width=0.3)\n",
    "axes[0].axhline(y=0, color='black', linewidth=0.5)\n",
    "axes[0].axhline(y=1.96/np.sqrt(len(returns)), color=RED, linestyle='--', alpha=0.7, label='95% CI')\n",
    "axes[0].axhline(y=-1.96/np.sqrt(len(returns)), color=RED, linestyle='--', alpha=0.7)\n",
    "axes[0].set_title('ACF of S&P 500 Returns', fontweight='bold')\n",
    "axes[0].set_xlabel('Lag')\n",
    "axes[0].set_ylabel('ACF')\n",
    "axes[0].legend(loc='upper center', bbox_to_anchor=(0.5, -0.12), ncol=1, frameon=False)\n",
    "\n",
    "# PACF\n",
    "pacf_vals = pacf(returns, nlags=20)\n",
    "axes[1].bar(range(len(pacf_vals)), pacf_vals, color=GREEN, width=0.3)\n",
    "axes[1].axhline(y=0, color='black', linewidth=0.5)\n",
    "axes[1].axhline(y=1.96/np.sqrt(len(returns)), color=RED, linestyle='--', alpha=0.7, label='95% CI')\n",
    "axes[1].axhline(y=-1.96/np.sqrt(len(returns)), color=RED, linestyle='--', alpha=0.7)\n",
    "axes[1].set_title('PACF of S&P 500 Returns', fontweight='bold')\n",
    "axes[1].set_xlabel('Lag')\n",
    "axes[1].set_ylabel('PACF')\n",
    "axes[1].legend(loc='upper center', bbox_to_anchor=(0.5, -0.12), ncol=1, frameon=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Note: Returns typically show little autocorrelation (weak-form market efficiency)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Model selection\n",
    "print(\"\\n4. MODEL SELECTION\")\n",
    "\n",
    "model_results = []\n",
    "for p in range(4):\n",
    "    for q in range(4):\n",
    "        try:\n",
    "            model = ARIMA(returns, order=(p, 0, q))\n",
    "            fitted = model.fit()\n",
    "            model_results.append({\n",
    "                'p': p, 'q': q,\n",
    "                'AIC': fitted.aic,\n",
    "                'BIC': fitted.bic\n",
    "            })\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "model_df = pd.DataFrame(model_results)\n",
    "print(\"\\nTop 5 models by BIC:\")\n",
    "print(model_df.sort_values('BIC').head().to_string(index=False))\n",
    "\n",
    "best_p = int(model_df.loc[model_df['BIC'].idxmin(), 'p'])\n",
    "best_q = int(model_df.loc[model_df['BIC'].idxmin(), 'q'])\n",
    "print(f\"\\nBest model: ARMA({best_p},{best_q})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Fit best model and diagnostics\n",
    "print(\"\\n5. MODEL ESTIMATION AND DIAGNOSTICS\")\n",
    "\n",
    "final_model = ARIMA(returns, order=(best_p, 0, best_q))\n",
    "final_fit = final_model.fit()\n",
    "\n",
    "resid = final_fit.resid\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Residuals\n",
    "axes[0, 0].plot(resid, color=BLUE, linewidth=0.5)\n",
    "axes[0, 0].axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "axes[0, 0].set_title('Residuals', fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Time')\n",
    "\n",
    "# Histogram\n",
    "axes[0, 1].hist(resid, bins=50, density=True, color=BLUE, alpha=0.7, edgecolor='white')\n",
    "x_range = np.linspace(resid.min(), resid.max(), 100)\n",
    "axes[0, 1].plot(x_range, stats.norm.pdf(x_range, resid.mean(), resid.std()), \n",
    "               color=RED, linewidth=2, label='Normal')\n",
    "axes[0, 1].set_title('Residual Distribution', fontweight='bold')\n",
    "axes[0, 1].legend(loc='upper center', bbox_to_anchor=(0.5, -0.12), ncol=1, frameon=False)\n",
    "\n",
    "# ACF of residuals\n",
    "acf_resid = acf(resid, nlags=20)\n",
    "axes[1, 0].bar(range(len(acf_resid)), acf_resid, color=BLUE, width=0.3)\n",
    "axes[1, 0].axhline(y=0, color='black', linewidth=0.5)\n",
    "axes[1, 0].axhline(y=1.96/np.sqrt(len(resid)), color=RED, linestyle='--', alpha=0.7)\n",
    "axes[1, 0].axhline(y=-1.96/np.sqrt(len(resid)), color=RED, linestyle='--', alpha=0.7)\n",
    "axes[1, 0].set_title('ACF of Residuals', fontweight='bold')\n",
    "\n",
    "# Q-Q plot\n",
    "osm, osr = stats.probplot(resid, dist='norm', fit=True)[:2]\n",
    "slope, intercept, r = stats.linregress(osm, osr)[:3]\n",
    "axes[1, 1].scatter(osm, osr, color=BLUE, alpha=0.5, s=10)\n",
    "q_range = abs(osm).max() * 1.1\n",
    "x_line = np.array([-q_range, q_range])\n",
    "axes[1, 1].plot(x_line, slope * x_line + intercept, color=RED, linewidth=2)\n",
    "axes[1, 1].set_xlim(-q_range, q_range)\n",
    "axes[1, 1].set_ylim(-q_range * slope + intercept - abs(intercept)*0.5, \n",
    "                    q_range * slope + intercept + abs(intercept)*0.5)\n",
    "axes[1, 1].set_title('Q-Q Plot', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Ljung-Box\n",
    "print(\"\\nLjung-Box Test:\")\n",
    "lb = acorr_ljungbox(resid, lags=[10, 20], return_df=True)\n",
    "print(lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Forecasting\n",
    "print(\"\\n6. FORECASTING\")\n",
    "\n",
    "# Generate forecasts\n",
    "forecast_steps = 20\n",
    "forecast = final_fit.get_forecast(steps=forecast_steps)\n",
    "forecast_mean = forecast.predicted_mean\n",
    "conf_int = forecast.conf_int()\n",
    "\n",
    "# Create forecast index\n",
    "last_date = returns.index[-1]\n",
    "forecast_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=forecast_steps, freq='B')\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "# Last 100 observations + forecast\n",
    "ax.plot(returns.index[-100:], returns.values[-100:], color=BLUE, linewidth=1, label='Observed')\n",
    "ax.plot(forecast_dates, forecast_mean.values, color=RED, linewidth=2, label='Forecast')\n",
    "ax.fill_between(forecast_dates, conf_int.iloc[:, 0], conf_int.iloc[:, 1], \n",
    "                color=RED, alpha=0.2, label='95% CI')\n",
    "ax.axvline(x=last_date, color='gray', linestyle='--', alpha=0.5)\n",
    "ax.set_title('S&P 500 Returns: Forecast', fontweight='bold')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Return (%)')\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.12), ncol=3, frameon=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nForecast for next {forecast_steps} trading days:\")\n",
    "print(f\"Mean forecast: {forecast_mean.mean():.4f}%\")\n",
    "print(f\"Forecasts converge to unconditional mean (mean reversion)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 5: Discussion Questions\n",
    "\n",
    "Write your answers in the markdown cells below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion 1\n",
    "\n",
    "**Scenario:** You fit an ARMA(2,1) model to a financial return series. The estimated parameters are:\n",
    "- $\\hat{\\phi}_1 = 0.3$, $\\hat{\\phi}_2 = 0.4$, $\\hat{\\theta}_1 = -0.2$\n",
    "\n",
    "The Ljung-Box test on residuals gives p-value = 0.08.\n",
    "\n",
    "**Questions:**\n",
    "1. Check if the AR part is stationary (hint: check if $\\phi_1 + \\phi_2 < 1$ and $\\phi_2 - \\phi_1 < 1$ and $|\\phi_2| < 1$).\n",
    "2. Is the MA part invertible?\n",
    "3. Based on the Ljung-Box test, is the model adequate at the 5% significance level?\n",
    "\n",
    "**Your Answer:**\n",
    "\n",
    "*Write your answer here...*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion 2\n",
    "\n",
    "**Scenario:** Your colleague says: \"I always use AIC to select models because it gives me better forecasts. BIC is too conservative.\"\n",
    "\n",
    "**Questions:**\n",
    "1. What is the key difference between AIC and BIC in terms of the penalty term?\n",
    "2. Under what conditions might BIC be preferred over AIC?\n",
    "3. Is your colleague's statement always correct? Why or why not?\n",
    "\n",
    "**Your Answer:**\n",
    "\n",
    "*Write your answer here...*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Summary\n",
    "\n",
    "## Key Takeaways from Today's Seminar\n",
    "\n",
    "1. **Lag Operator** - $(1-L)X_t = X_t - X_{t-1}$ (first difference)\n",
    "\n",
    "2. **Stationarity & Invertibility**:\n",
    "   - AR stationarity: roots of $\\phi(z)=0$ outside unit circle\n",
    "   - MA invertibility: roots of $\\theta(z)=0$ outside unit circle\n",
    "\n",
    "3. **Model Identification**:\n",
    "   - AR(p): ACF decays, PACF cuts off at lag p\n",
    "   - MA(q): ACF cuts off at lag q, PACF decays\n",
    "   - ARMA: Both decay\n",
    "\n",
    "4. **Model Selection**:\n",
    "   - AIC = -2log(L) + 2k (better for prediction)\n",
    "   - BIC = -2log(L) + k*log(n) (better for true model)\n",
    "\n",
    "5. **Diagnostics**:\n",
    "   - Ljung-Box test: H0 = residuals are white noise\n",
    "   - Check ACF of residuals (should be within confidence bands)\n",
    "   - Q-Q plot for normality\n",
    "\n",
    "6. **Forecasting**:\n",
    "   - Stationary ARMA forecasts revert to unconditional mean\n",
    "   - Confidence intervals widen with horizon\n",
    "\n",
    "## Next Seminar\n",
    "ARIMA models, seasonal ARIMA (SARIMA), and advanced forecasting techniques"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
